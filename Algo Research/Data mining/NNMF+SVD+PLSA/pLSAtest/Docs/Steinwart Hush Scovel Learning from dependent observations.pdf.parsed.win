
arXiv:0707.0303v1 [stat.ML] 2 Jul 2007 Learning from dependent observations Ingo Steinwart?,Don Hush, and Clint Scovel Modeling, Algorithms and Informatics Group, CCS-3 MS B256 Los Alamos National Laboratory Los Alamos, New Mexico 87545, USA Tel.: 001-505-665-7914 Fax.: 001-505-667-1126 {ingo,dhush,jcs}@lanl.gov February 1, 2008 Abstract In most papers establishing consistency for learning algorithms it is assumed that the observations used for training are realizations of an i.i.d. process. In this paper we go far beyond this classical framework by showing that support vector machines (SVMs) essentially only require that the data-generating process satisfies a certain law of large numbers. We then consider the learnability of SVMs for ?-mixing (not necessarily stationary) processes for both classification and regression, where for the latter we explicitly allow unbounded noise. Keywords: Support vector machine, Consistency, Non-stationary mixing process, Classification, Regression 1 Introduction In recent years Support Vector Machines (SVMs) have become one of the most widely used algorithms for classification and regression problems. Besides their good performance in practical applications they also enjoy a good theoretical justification in terms of both universal consistency (see [1, 2, 3, 4]) and learning rates (see [5, 6, 7, 8, 9]) if the training samples come from an i.i.d. process. However, often this i.i.d. assumption cannot be strictly justified in real-world problems. For example, many machine learning applications such as market prediction, system diagnosis, and speech recognition are inherently temporal in nature, and consequently not i.i.d. processes. Moreover, samples are often gathered from different sources and hence it seems unlikely that they are identically distributed. Although SVMs have no theoretical justification in such non-i.i.d. scenarios they are often applied successfully. One of the goals of this work is explain this success by establishing consistency results for SVMs under somewhat minimal assumptions on the data generating process. Namely, we show that for any data-generating process that satisfies certain laws of large numbers there exists a sequence of regularization parameters such that the corresponding SVM is consistent. By general negative results (see [10]) on universal consistency for stationary ergodic processes this sequence of regularization parameters must depend on the stochastic properties of ?Corresponding author 1
the data-generating process and cannot be adaptively chosen. However, we show that if the process satisfies certain mixing properties such as polynomially decaying ?-mixing coefficients (see the definitions in the following sections) then a suitable regularization sequence can be chosen a-priori. In addition, a side-effect of our analysis is that it provides consistency for SVMs using Gaussian kernels even if the common compactness assumption of the input space is violated. Consequently, our consistency results for ?-mixing processes generalizes earlier consistency results of [1, 2, 3] with respect to both the compactness assumption on X and the i.i.d. assumption on the data-generating process. Relaxations of the independence assumption have been considered for quite a while in both the machine learning and the statistical literature. For example PAC-learning for stationary ? ?-mixing processes has been investigated in [11], and more recently, consistency of regularized boosting for classification was established for such processes. For a larger class of processes, namely ?-mixing but not necessarily stationary processes, consistency of kernel density estimators was shown in [12]. For bounded, stationary processes with exponentially decaying ??-mixing coefficients a consistent method for one-step-ahead prediction (also known as "static autoregressive forecasting", see [13]) was presented in [14]. Moreover, for this prediction problem [15] establishes consistency for a certain structural risk minimization approach under the assumption that the process is stationary and has polynomially decaying ? ?-mixing rates. For further results and references we refer to [16, 17]. Relaxations of the stationarity of the process are less common. In fact, to our best knowledge [12] is the only work which deals with such processes. One of the reasons for this lack of literature may be the fact that for non identically distributed observations there is no obvious way to define a reasonable risk functional which resembles the idea of "average future error". On the other hand, it seems obvious that learning methods based on a modified empirical risk minimization procedure require at least that the process satisfies certain laws of large numbers. Interestingly, we will show that for processes satisfying such laws of large numbers there is always a "limit" distribution which can be used to define a reasonable risk functional. Moreover, for many interesting classes of processes the existence of such a limit distribution turns out to be equivalent to a law of large numbers. The rest of this work is organized as follows: In Section 2 we will define the notions "laws of large numbers" and "limit" distributions for stochastic processes. We then discuss the relationship between these concepts and consider specific classes of stochastic processes that satisfy these definitions. We then recall some basic classes of loss functions and define consistency of learning algorithms for stochastic processes satisfying certain laws of large numbers. Finally, we show that SVMs can be made consistent for such processes. In Section 3 we then recall various mixing coefficients for stochastic processes. These coefficient are then used to establish consistency results for SVMs with a-priori chosen regularization sequence. Finally, the proofs of our results can be found in Section 4. 2 Consistency for Processes satisfying a Law of Large Numbers The aim of this section is to show that SVMs can be made consistent whenever the data-generating process satisfies a certain type of law of large numbers (LLNs). To this end we first recall some notions for stochastic processes and introduce these laws of large numbers in Subsection 2.1. Some examples of processes satisfying LLNs are then presented in Subsection 2.2. In Subsection 2.3 we then recall some important notions for loss functions and risks. We also define consistency of learning algorithms for data-generating processes that satisfy a law of large numbers. Finally, we present and discuss our consistency results for SVMs in Subsection 2.4. 2
2.1 Law of Large Numbers for Stochastic Processes In this subsection we mainly introduce laws of large numbers for general, not necessarily stationary stochastic processes. The concepts we will present seem to be quite natural and elementary, and therefore one would expect that they have already been introduced elsewhere. Surprisingly, however, we were not able to find any exposition that covers major parts of the material of this section, and thus we discuss the following notions in some detail. Let us begin with some notations. Given a measurable space Z we write L0(Z) for the set of all measurable functions f : Z > R, and L?(Z) for the set of all bounded measurable functions f : Z > R. Moreover, for a set B ? Z we write 1B for its indicator function, i.e. 1B : Z > {0, 1} with 1B(z) = 1 if and only if z ? B. Let us now assume that we also have a probability space (,A, ?) and a measurable map T : > Z. Then ?(T) denotes the smallest ?-algebra on for which T is measurable. Moreover, ?T denotes the T-image measure of ?, which is defined by ?T (B) := ?(T?1(B)), B ? Z measurable. Again, let (,A, ?) be a probability space and (Z,B) be a measurable space. Recall that for a stochastic process Z := (Zi)i?1, i.e. a sequence of measurable maps Zi : > Z, i ? 1, the map Z : > ZN defined by ? 7> (Zi(?))i is (A,BN)-measurable. Consequently, Z has an image measure ?Z which is given by ?Z(B) := ?(Z?1(B)) for all B ? BN. Furthermore, recall that Z is called identically distributed if ?Zi = ?Zj for all i, j ? 1, and stationary in the wide sense if ?(Zi1+i,Zi2+i) = ?(Zi1 ,Zi2) for all i1, i2, i ? 1. Moreover, Z is said to be stationary if ?(Zi1+i,...,Zin+i) = ?(Zi1 ,...,Zin) for all n, i, i1, . . . , in ? 1. As we will see later we are not interested in the data-generating process Z := (Zi) itself, but only in processes of the form g * Z := (g * Zi)i?1 for g : Z > Z' measurable. In the following we call g * Z an image of the process Z, and Z itself a hidden process. The following definition introduces laws of large numbers for stochastic processes by considering real-valued image processes: Definition 2.1 Let (,A, ?) be a probability space, Z be a measurable space, and Z := (Zi)i?1 be a Z-valued stochastic process on . We say that Z satisfies the weak law of large numbers for events (WLLNE) if for all measurable B ? Z there exists a constant cB ? R such that for all ? > 0 we have lim n>??n? ? :1nXn i=1 1B * Zi(?) ? cB> ?o= 0 . (1) Moreover, we say that Z satisfies the strong law of large numbers for events (SLLNE) if for all measurable B ? Z there exists a constant cB ? R with lim n>? 1n Xn i=1 1B * Zi(?) = cB (2) for ?-almost all ? ? . It is obvious that Z satisfies the WLLNE if and only if the sequences ( 1n Pni=1 1B * Zi) converge in probability ? for all measurable B ? Z. Consequently, the SLLNE implies the WLLNE but in general the converse implication does not hold. Moreover, if Z satisfies the WLLNE then the constants cB in (1) must obviously satisfy cB ? [0, 1] for all measurable B ? Z. Finally, if Z satisfies the WLLNE or SLLNE then it is a trivial exercise to check that every image g * Z also satisfies the WLLNE or SLLNE, respectively. It is well known that i.i.d. processes generated by P satisfy the P?-SLLNE with cB = P(B) for all measurable B ? Z, but these processes are by far not the only ones (see Subsection 2.2 for some other examples). For the following development it is instructive to observe that for 3
i.i.d. processes the map B 7> cB defines a probability measure on Z. Our next goal is to show that this remains true for general processes satisfying a WLLNE. To this end we first consider the averages 1n Pni=1 E?1B * Zi of the probabilities of the event B: Definition 2.2 Let (,A, ?) be a probability space, Z be a measurable space, and Z := (Zi)i?1 be a Z-valued stochastic process on . We say that Z is asymptotically mean stationary (AMS) if P(B) := lim n>? 1nXn i=1 E?1B * Zi (3) exists for all measurable B ? Z. The notion "asymptotically mean stationary" was first introduced for dynamical systems by Grey and Kieffer in [18]. We are unaware of any work that introduces this notion for general stochastic processes, though a similar idea already appears as assumption (S1) in [12]. Using the simple formula 1B *g = 1g?1(B) it is obvious that every image g *Z of an AMS process Z is again AMS. Moreover, identically distributed-and hence stationary-processes are obviously AMS. Moreover, for such processes we also have P(B) = ?Z1(B) for all measurable B ? Z, and consequently, (3) defines a probability measure on Z. The following lemma whose proof can be found in Section 4 shows that the latter observation remains true for general AMS processes. Lemma 2.3 Let (,A, ?) be a probability space, Z be a measurable space, and Z := (Zi)i?1 be a Z-valued stochastic process on which is AMS. Then P defined by (3) is a probability measure on Z. We call P the stationary mean of (Z, ?). It it well-known that not every stationary process satisfies a (weak, strong) law of large numbers for events. Consequently, we see that in general AMS processes do not satisfy a law of large numbers. However, the following theorem proved in Section 4 shows that the converse implication is true. In addition, it shows that the constants cB in (1) define the stationary mean distribution: Theorem 2.4 Let (,A, ?) be a probability space, Z be a measurable space, and Z := (Zi)i?1 be a Z-valued stochastic process on satisfying the WLLNE. Then Z is AMS and the stationary mean P of (Z, ?) satisfies lim n>??n? ? : 1n Xn i=1 1B * Zi(?) ? P(B)> ?o= 0 (4) for all measurable B ? Z and all ? > 0. Moreover, if Z satisfies the SLLNE then lim n>0 1n Xn i=1 1B * Zi(?) = P(B) holds for ?-almost all ? ? . Equation (4) shows that the stationary mean P describes with high probability our average observations from Z. Given a loss function L (see Subsection 2.3 for definitions) it seems therefore natural to approximate the empirical L-risk of a function by the corresponding L-risk defined by P.1 However, in order to make this ansatz rigorous we have to extend (4) to function classes larger 1For i.i.d. observations one typically argues the other way around. However, for general stochastic processes the learning goal should be to minimize the future average loss. This loss is an empirical L-risk which can be approximated by the L-risk defined by P. In the training phase of empirical risk minimizers the latter L-risk is then approximated by the empirical L-risk of the already observed training samples. In this way P and the corresponding convergence rates in (3) and (4) tell us how well we can generalize from the past to the future. 4
than the set of indicator functions. We begin with the following result that shows that a law of large numbers for events implies a corresponding law of large numbers of bounded functions: Lemma 2.5 Let (,A, ?) be a probability space, Z be a measurable space, and Z := (Zi)i?1 be a Z-valued stochastic process on satisfying the WLLNE. Furthermore, let P be the asymptotic mean of (Z, ?). Then for all f ? L?(Z) we have EP f = lim n>? 1nXn i=1 f * Zi (5) in probability ? and EP f = lim n>? 1n Xn i=1 E?f * Zi . (6) Moreover, if Z actually satisfies the SLLNE then the convergence in (5) holds ?-almost surely. For classification problems we usually can restrict our considerations to bounded functions, and hence Lemma 2.5 is all that we need. However, for regression problems with unbounded noise we have to consider integrable functions, instead. The following definition serves this purpose: Definition 2.6 Let (,A, ?) be a probability space, Z be a measurable space, and Z := (Zi)i?1 be a Z-valued stochastic process on . Assume that Z is AMS and let P be the asymptotic mean of (Z, ?). We say that Z satisfies the weak law of large numbers (WLLN) if for all f ? L1(P) and all ? > 0 we have lim n>??n? ? : 1n Xn i=1 f * Zi(?) ? EP f> ?o= 0 . (7) Moreover, we say that Z satisfies the strong law of large numbers (SLLN) if for all f ? L1(P) we have lim n>? 1n Xn i=1 f * Zi(?) = EP f (8) for ?-almost all ? ? . 2.2 Examples of Processes Satisfying a Law of Large Numbers In this subsection we recall several examples of stochastic processes satisfying a law of large numbers. In particular, we consider independent processes, dynamical systems, and Markov chains. 2.2.1 Uncorrelated and independent processes Recall that two real-valued random variables ? and ? are called uncorrelated if they satisfy E?? = E? E?. The following proposition proved in Section 4 shows that AMS, mutually uncorrelated processes satisfy a WLLNE: Proposition 2.7 Let (,A, ?) be a probability space, Z be a measurable space, and Z := (Zi)i?1 be a Z-valued stochastic process on . Assume that the random variables 1B * Zi and 1B * Zj are uncorrelated for all measurable B ? Z and all i, j ? 1 with i 6= j. Then the following statements are equivalent: i) Z is AMS. 5
ii) Z satisfies the WLLNE. Considering the proof of the above proposition it is immediately clear that the proposition remains true if the process is not uncorrelated but only satisfies lim n>?E?1 n2Xn i=1??1B * Zi ? E?1B * Zi2 = 0 (9) for all measurable B ? Z. Processes satisfying such a weaker assumption are introduced and discussed in Subsection 3.1. It is obvious that Proposition 2.7 holds for processes for which the image processes (1B * Zi)i?1 are independent. However, by applying [19, Theorem 2.7.1] we have the following stronger result: Proposition 2.8 Let (,A, ?) be a probability space, Z be a measurable space, and Z := (Zi)i?1 be a Z-valued stochastic process on . Assume that 1B * Z1, 1B * Z2, . . . are independent for all fixed measurable B ? Z. Then the following statements are equivalent: i) Z is AMS. ii) Z satisfies the SLLNE. Note that the independence assumption in Theorem 2.8 is weaker than assuming that the process is independent. By Kolmogorov's well-known strong law of large numbers it is obvious that every process Z whose R-valued images g * Z are i.i.d. processes satisfies a SLLN. Moreover, a result by Etemadi [20] shows that the independence assumption can be relaxed to pairwise independence. Finally, the following result whose proof can again be found in Section 4 generalizes Kolmogorov's law of large numbers to a certain type of martingale: Proposition 2.9 Let (,A, ?) be a probability space, Z be a measurable space, and Z := (Zi)i?1 be a Z-valued stochastic process on . Assume that for all f ? L1(?Z1) and Fn := ?(f *Zi : i ? n), n ? 1, we have Ti?1 Fi = {?,} and E1n Xn i=1 f * Zi Fn+1= 1 n + 1 nX+1 i=1 f * Zi . (10) Then Z satisfies the SLLN and ?Z1 is the asymptotic mean of (Z, ?). 2.2.2 Ergodic processes In this section we recall the basic notions and results for dynamical systems. To this end let Z be a measurable space and S : ZN > ZN be the shift operator defined by (zi) 7> (zi+1). A set B ? ZN is called invariant if S?1(B) = B. Moreover, let (,A, ?) be a probability space and Z := (Zi)i?1 be a Z-valued stochastic process on . Then Z is called ergodic if we have ?Z(B) ? {0, 1} for all measurable invariant subsets B ? ZN. It is not hard to see that every image of an ergodic process is again an ergodic process. In the following we are mainly interested in stationary ergodic processes. To this end let us now assume that (Z,B, ?) is a probability space and T : Z > Z is a measurable map. Then the stochastic process Z := (Ti?1)i?1 is called a dynamical system, and it is called an invariant dynamical system if the T-image ?T of ? satisfies ? = ?T . Recall that an invariant dynamical system Z := (Ti?1)i?1 6
on a probability space (Z,B, ?) is ergodic if and only if ? satisfies ?(B) ? {0, 1} for all measurable B ? Z with T?1(B) = B. Moreover, recall that every stationary process is the image of a hidden invariant dynamical system. Conversely, every invariant dynamical system is stationary and hence AMS. In addition recall that Birkhoff's theorem (see e.g. [21, p. 82ff]): Theorem 2.10 Let Z := (Ti?1)i?1 be an invariant dynamical system on a probability space (Z,B, ?). Then the following statements are equivalent: i) Z satisfies the SLLNE. ii) Z satisfies the SLLN. iii) Z is ergodic. With the help of the above theorem one can show (see e.g. [22, p. 26f]) that every stationary ergodic process Z satisfies the SLLN. Moreover, by a theorem by Gray and Kieffer (see e.g. [22, p. 33]) we know that a dynamical system Z := (Ti?1)i?1 is AMS if and only if limn>? 1n Pni=1 f * T?1 exists ?-almost surely for all f ? L?(Z). Note that Birkhoff's theorem shows that the corresponding limit is a constant function if and only if the dynamical system is ergodic. Finally, it is interesting to note that for stationary, ergodic processes the limit relation (9) holds (see e.g. [23, Thm. 2.19, p. 61]). Let us now recall a notion related to ergodicity. To this end let (Z,B, ?) be a probability space and Z := (Ti?1)i?1 be an invariant dynamical system on Z. Then Z is said to be weakly mixing if lim n>? 1n nX?1 i=0 ???T?i(A) ? B? ?(A)?(B)= 0 , A,B ? B. It is well-known that weak mixing implies ergodicity, and that that the converse implication does not hold in general (see e.g. [24, p. 41ff]). Moreover, one can also introduce mixing conditions for general stationary ergodic processes. For example, if (,A, ?) is a probability space, Z is a measurable space, and Z := (Zi)i?1 is a Z-valued stochastic process on , then Z is called mixing if lim n>??Z??S?n(A) ? B= ?Z(A)?Z(B) (11) holds for all measurable A,B ? ZN. One can show (see e.g. [23, Prop. 2.8, p. 50]) that for invariant dynamical systems this definition coincides with the above mixing definition. Moreover, recall that i.i.d. processes are invariant and weakly mixing (see [24, p. 58]). The weak mixing is important because it allows us to establish the ergodicity of products of dynamical systems. This leads to our last example: Proposition 2.11 Let ? be a probability measure on Rd and Z be an invariant ergodic dynamical system on (Rd, ?). Furthermore, let (,A, ?) be a probability space and E be an i.i.d. sequence of random variables ?i : > Rd. Then the process Z + E defined on (Rn ? , ? ? ?) satisfies the SLLN. 2.2.3 Markov chains In this subsection we briefly discuss a law of large numbers for Markov chains. To this end let us fix a probability space (Z,B, ?). Furthermore, let p : B ? Z > [0, 1] be a stochastic transition function, i.e. a Markov kernel. Let us define a probability measure P on (ZN,BN) by P(B1 ? - - - ? Bn) := Z 1B1?---?Bn(z1, . . . , zn)p(dzn, zn?1) . . . p(dz2, z1)?(dz1) , (12) 7
where n runs over all integers and B1, . . . ,Bn run over all measurable subsets of Z. A Z-valued stochastic process Z defined on a probability space (,A, ?) is called homogeneous2 Markov chain with transition function p and initial distribution ? if it satisfies ?Z = P, where P is determined by (12). Obviously, the sequence (?i)i?1 of coordinate projections ?i : ZN > Z, (zj ) 7> zi is a canonical model of such a Markov chain if ZN is equipped with the distribution P. Moreover, if the homogeneous Markov chain is stationary then ? satisfies ?Zi = ? for all i ? 1. The transition function describes the probability of Zn+1 given the state of the process at time n. For larger steps ahead one can iteratively compute the corresponding transition probabilities by p(1)(B, z) = p(B, z) p(n+1)(B, z) = Z pn(B, z')p(dz', z) . Let us now assume that there exists a finite measure Q on B with Q(Z) > 0, an integer n ? 1, and a real number ? > 0 such that for all measurable B ? Z we have Q(B) ? ? =? p(n)(B, z) ? 1 ? ? for all z ? Z . (13) This assumption taken from [25, p. 192] is often called the "Doeblin condition" (see e.g. [25, p. 197] or [26, p. 156]). If Z is a finite set, then (13) is automatically satisfied (see e.g. [25, p. 192]). Moreover, if Z ? Rd is a set of finite Lebesgue measure and the distributions p( . z), z ? Z are absolutely continuous with uniformly bounded transition densities then (13) also holds (see e.g. [25, p. 193]). For some similar conditions we finally refer to [26] and the references therein). Now, the following theorem which can be found in [25, p. 219] gives a simple condition ensuring a SLLN for Markov chains: Theorem 2.12 Let (Z,B, ?) be a probability space, p : B ? Z > [0, 1] be a stochastic transition function and Z = (Zi)i?1 be a stationary homogeneous Markov chain with transition function p and initial distribution ?. If Z satisfies (13) then Z satisfies the SLLN. The above theorem can be generalized to non-homogeneous, not identically distributed Markov chains. Since these generalizations are out of the scope of the paper we refer to [19, p. 129-135] for details. Finally, we would also like to mention without explaining the details that if Z is a countable set then an irreducible, positive recurrent, homogeneous Markov chain satisfies the SLLNE (see e.g. [27, Thm. 1.10.2]). 2.3 Loss functions, Risks, and Consistency In this section we recall some basic notions for loss functions and their associated risks. We then introduce consistency notions for learning algorithms for stochastic processes satisfying a law of large numbers. In the following X is always a measurable space if not mentioned otherwise and Y ? R is always a closed subset. Moreover, metric spaces are always equipped with the Borel ?-algebra, and products of measurable spaces are always equipped with the corresponding product ?-algebra. Finally, Lp(?) stands for the standard space of p-integrable functions with respect to the measure ? on X. Definition 2.13 A function L : X ? Y ? R > [0,?] is called a loss function if it is measurable. In this case L is called: 2Since we only deal with homogeneous Markov chains we often omit the adjective "homogeneous". 8
i) convex if L(x, y, . ) : R > [0,?] is convex for all x ? X, y ? Y . ii) continuous if L(x, y, . ) : R > [0,?] is continuous for all x ? X, y ? Y . Moreover, for a probability measure P on X ? Y and an f ? L0(X) the L-risk of f is defined by RL,P (f) := Z X?Y L??x, y, f(x)dP(x, y) = ZX ZY L??x, y, f(x)dP(y|x) dPX(x). Finally, the Bayes L-risk is R?L,P := inf{RL,P (f) : f ? L0(X)}. Note that the integral defining the L-risk always exists since L is non-negative and measurable. In addition it is obvious that the risk of a convex loss is convex on L0(X). However, in general the risk of a continuous loss is not continuous. In order to ensure this continuity and several other, more sophisticated properties we need the following definition: Definition 2.14 We call a loss function L : X ?Y ?R > [0,?] a Nemitski loss function if there exist a measurable function b : X ?Y > [0,?) and an increasing function h : [0,?) > [0,?) with L(x, y, t) ? b(x, y) + h??|t|, (x, y, t) ? X ? Y ? R. (14) Furthermore, we say that L is a Nemitski loss of order p ? (0,?), if there exists a constant c > 0 with h(t) = c tp for all t ? 0. Finally, if P is a distribution on X ? Y with b ? L1(P) we say that L is a P-integrable Nemitski loss. Note that P-integrable Nemitski loss functions L satisfy RL,P (f) < ? for all f ? L?(PX), and consequently we also have RL,P (0) < ? and R?L,P < ?. For our further investigations we also need the following additional properties which are satisfied by basically all commonly used loss functions: Definition 2.15 Let L : X ? Y ? R > [0,?) be a loss function. We say that L is: i) locally bounded if for all bounded A ? R the restriction L|X?Y ?A of L is a bounded function. ii) locally Lipschitz continuous if for all a > 0 we have |L|a,1 := sup t,t'?[?a,a] t6=t' sup x?X y?Y L(x, y, t) ? L(x, y, t')|t ? t'| < ?. (15) iii) Lipschitz continuous if we have |L|1 := supa>0 |L|a,1 < ?. Note that if Y ? R is a finite subset and L : Y ? R > [0,?) is a convex loss function then L is a locally Lipschitz continuous loss function. Moreover, a locally Lipschitz continuous loss function L is a Nemitski loss since (15) yields L(x, y, t) ? L(x, y, 0) + |L||t|,1|t| , (x, y, t) ? X ? Y ? R. (16) In particular, a locally Lipschitz continuous loss L is a P-integrable Nemitski loss if and only if RL,P (0) < ?. Moreover, if L is Lipschitz continuous then L is a Nemitski loss of order 1. The following examples recall that (locally) Lipschitz continuous losses are often used in learning algorithms for classification and regression problems: 9
Example 2.16 A loss L : Y ? R > [0,?) of the form L(y, t) = ?(yt) for a suitable function ? : R > R and all y ? Y := {?1, 1} and t ? R, is called margin-based. Recall that margin-based losses such as the (squared) hinge loss, the AdaBoost loss, the logistic loss and the least squares loss are used in many classification algorithms. Obviously, L is convex, continuous, or (locally) Lipschitz continuous if and only if ? is. In addition, convexity of L implies local Lipschitz continuity of L. Moreover, L is always a P-integrable Nemitski loss since we have L(y, t) ? max{?(?t), ?(t)} (17) for all y ? Y and all t ? R. In particular, this estimate shows that every convex margin-based loss is locally bounded. Moreover, from (17) we can easily derive a characterization for L being a P-integrable Nemitski loss of order p. Example 2.17 A loss L : Y ? R > [0,?) of the form L(y, t) = ?(y ? t) for a suitable function ? : R > R and all y ? Y := R and t ? R, is called distance-based. Distance-based losses such as the least squares loss, Huber's insensitive loss, the logistic loss, or the o-insensitive loss are usually used for regression. It is easy to see that L is convex, continuous, or Lipschitz continuous if and only if ? is. Let us say that L is of upper growth p ? [1,?) if there is a c > 0 with ?(r) ? c ??|r|p + 1, r ? R. Analogously, L is said to be of lower growth p ? [1,?) if there is a c > 0 with ?(r) ? c ??|r|p ? 1, r ? R. Recall that most of the commonly used distance-based loss functions including the above examples are of the same upper and lower growth type. Then it is obvious that L is of upper growth type 1 if it is Lipschitz continuous, and if L is convex the converse implication also holds. Moreover, non-trivial convex L are always of lower growth type 1. In addition, a distance-based loss function of upper growth type p ? [1,?) is a Nemitski loss of order p, and if the distribution P satisfies the moment condition |P|p := ??E(x,y)P |y|p1/p := ZX?R |y|p dP(x, y)1/p < ? (18) it is also P-integrable. If our observations are realizations of a sequence Z of random variables (Xi, Yi) : > X ? Y satisfying a law of large numbers then the following lemma proved in Section 4 shows that the risk with respect to the asymptotic mean distribution P actually describes the average future loss. Lemma 2.18 Let (,A, ?) be a probability space, X be a measurable space, Y ? R be a closed subset, and Z := ((Xi, Yi))i?1 be a X ? Y -valued stochastic process on satisfying the WLLNE. Furthermore, let P be the asymptotic mean of (Z, ?) and L : X?Y ?R > [0,?) be a loss function. If L is locally bounded then for all f ? L?(X) and all n0 ? 0 we have RL,P (f) = lim n>? 1 n ? n0 Xn i=n0+1L??Xi, Yi, f(Xi), (19) where the limit is with respect to the convergence in probability ?. Moreover, if Z actually satisfies the SLLNE then (19) holds ?-almost surely. Finally, the same conclusions hold if L is a P-integrable Nemitski loss and Z satisfies the WLLN or SLLN. With the help of the above lemma we can now introduce some reasonable concepts describing the asymptotic learning ability of learning algorithms. To this end recall that a method L that provides to every training set T := ((x1, y1), . . . , (xn, yn)) ? (X ? Y )n a (measurable) function fT : X > R is called a learning method. The following definition introduces an asymptotic way to describe whether a learning method can learn from samples: 10
Definition 2.19 Let (,A, ?) be a probability space, X be a measurable space, Y ? R be a closed subset, and Z := ((Xi, Yi))i?1 be a X ? Y -valued stochastic process on satisfying the WLLNE. Furthermore, let P be the asymptotic mean of (Z, ?) and L : X?Y ?R > [0,?) be a loss function. We say that a learning method L is L-consistent for Z if lim n>?RL,P (fTn) = R?L,P (20) holds in probability ?, where Tn := ((X1, Y1), . . . , (Xn, Yn)) and R?L,P is the Bayes risk defined in Definition 2.13. Moreover, we say that L is strongly L-consistent for Z if (20) holds ?-almost surely. 2.4 Consistency of SVMs In this subsection we present some results showing that support vector machines (SVMs) can learn whenever the data-generating process satisfies a law of large numbers. Let us begin by recalling the definition of SVMs. To this end let L : X ? Y ? R > [0,?) be a convex loss function and H be a reproducing kernel Hilbert space (RKHS) over X (see e.g. [28]). Then for all ? > 0 and all observations T := ((x1, y1), . . . , (xn, yn)) ? X ? Y there exists exactly one element fT,? H withfT,? argmin f?H ?kfk2H + 1nXn i=1 L??xi, yi, f(xi). (21) Given a null-sequence (?n) of strictly positive real numbers we call the learning method which provides to every training set T ? (X ? Y )n the decision function fT,n an (?n)-SVM based on H and L. For more information on SVMs we refer to [29, 30]. Moreover, given a distribution P on X ? Y we say that the RKHS H is (L, P)-rich if we have R?L,P,H := inf f?H RL,P (f) = R?L,P , i.e. if the Bayes risk can be approximated by functions from H. Note that the condition R?L,P,H = R?L,P is satisfied (see [31]) whenever, the kernel of H is universal in the sense of [32], i.e. X is a compact metric space and H is dense in the space C(X) of continuous functions. Less restrictive assumptions on H and X have been recently found in [31]. In particular, it was shown in [31] that the RKHSs H, ? > 0, of the Gaussian RBF kernels k(x, x') := exp????2kx ? x'k22 , x, x' ? Rd are (L, P)-rich for all distributions P on Rd ? Y and all continuous, P-integrable Nemitski losses L of order p ? [1,?). Finally, one can also find some necessary and sufficient conditions for (L, P)-richness on countable spaces X in [31]. In order to present our first main result let us recall that a Polish space is separable topological space with a countable dense subset whose topology can be described by a complete metric. It is well known that e.g. closed and open subset of Rd and compact metric spaces are Polish. Now our first theorem shows that for every process satisfying a law of large numbers for events there exists an SVM which is consistent for this process: Theorem 2.20 Let X be a Polish space, Y ? R be a closed subset and L : X ? Y ? R > [0,?) be a convex, locally Lipschitz continuous, and locally bounded loss function. Moreover, let (,A, ?) 11
be a probability space, Z := ((Xi, Yi))i?1 be an X ?Y -valued stochastic process on satisfying the WLLNE, and P be the asymptotic mean of (Z, ?). Finally, let H be an (L, P)-rich RKHS over X with continuous kernel. Then there exists a null-sequence (?n) of strictly positive real numbers such that the (?n)-SVM based on H and L is L-consistent for Z. In addition, if Z satisfies the SLLNE then (?n) can be chosen such that the (?n)-SVM is strongly L-consistent for Z. The next theorem establishes a similar result for distance-based loss functions (see Example 2.17) which, in general, are not locally bounded. Theorem 2.21 Let X be a Polish space, Y ? R be a closed subset and L : Y ? R > [0,?) be a convex, distance-based loss function of upper growth-type p ? [1,?). Moreover, let (,A, ?) be a probability space, Z := ((Xi, Yi))i?1 be an X ? Y -valued stochastic process on satisfying the WLLN, and P be the asymptotic mean of (Z, ?). We assume |P|p < ?. Finally, let H be the (L, P)-rich RKHS of a continuous kernel on X. Then there exists a null-sequence (?n) of strictly positive real numbers such that the (?n)-SVM based on H and L is L-consistent for Z. In addition, if Z satisfies the SLLN then (?n) can be chosen such that the (?n)-SVM is strongly L-consistent for Z. The techniques used in the proofs of Theorem 2.20 and 2.21 are based on a (hidden) skeleton argument in the proof of Lemma 4.5. A more general though standard skeleton argument can be used to derive results similar to Theorem 2.20 and 2.21 for other empirical risk minimization methods using hypothesis sets with reasonably controllable complexity. Due to space constraints we omit the details. Let us now assume for a moment that X is a subset of Rd, L is a loss function in the sense of either Theorem 2.20 or 2.21, and H is the RKHS of a Gaussian RBF kernel. Then the above theorems together with the richness results from [31] show that for all data-generating processes Z satisfying a law of large numbers there exist suitable regularization sequences (?n) that allows us to build a consistent SVM. However, the sequences of Theorem 2.20 or 2.21 depend on Z, and consequently, it would be desirable to have either a universal sequence (?n), i.e. a sequence that guarantees consistency for all Z, or a consistent method that finds suitable values for ? from the observations. Unfortunately, the following theorem due to Nobel, [10], together with Birkhoff's ergodic theorem shows that neither of these alternatives is possible:3 Theorem 2.22 There is no learning method which is Llsquares-consistent for all stationary ergodic processes (Xi, Yi) with values in [0, 1] ? [0, 1], where Llsquares denotes the usual least square loss Llsquares(y, t) := (y ? t)2, y, t ? R. Moreover, there is no learning method which is Lclass-consistent for all stationary ergodic processes (Xi, Yi) with values in [0, 1] ? {?1, 1}, where Lclass denotes the classification loss Lclass(y, t) := 1(??,0](y sign t), y = ±1, t ? R. Roughly speaking the impossibility of finding a universal sequence (?n) is related to the fact that there is no uniform convergence speed in the LLNs for general processes. More precisely, if Z := ((Xi, Yi))i?1 is a stochastic process which satisfies a law of large numbers then for all ? > 0, n ? 1, and all suitable functions f : X ? Y > R there exists a ?(?, f, n) > 0 with ?n? ? :1nXn i=1 f * (Xi, Yi)(?) ? EP f> ?o? ?(?, f, n) (22) 3Recall that binary classification is the "easiest" non-parametric learning problem in the sense that negative results for this learning problem can typically be translated into negative results for almost all learning problems defined by loss functions (cf. p.118f in [33] for some examples in this direction and the proof of the below theorem in [10] for the least squares loss). 12
and limn>? ?(?, f, n) = 0. Now, the proofs of Theorem 2.20 and Theorem 2.21 (essentially) show that we can determine a sequence (?n) whenever we know such ?(?, f, n) for all ? > 0, n ? 1, and a suitably large class of functions f. However, since there exists no universal sequence (?n) by Theorem 2.22 we consequently see that there exists no values ?(?, f, n) such that (22) holds for all (stationary) processes satisfying a law of large numbers. This discussion shows that in order to build consistent SVMs for interesting classes of processes one has to find quantitative versions of laws of large numbers. For i.i.d. processes such laws have been established in recent years by several authors. In the following section we will present a simple yet powerful method for establishing quantitative versions of laws of large numbers for mixing processes. 3 Consistency for Mixing Processes In this section we derive consistency results for SVMs under the assumption that the data-generating process satisfies certain mixing conditions. These mixing conditions generally quantify how much a process fails to be independent. In the first subsection we recall some commonly used mixing conditions. In the second subsection we then present our consistency results and compare them with known consistency results for other learning algorithms. 3.1 A Brief Introduction to Mixing Coefficients for Processes In this subsection we recall some standard mixing coefficients and their basic properties (see e.g. [23] and [17] for thorough treatment). To this end let be a set, A and B be two ?-algebras on , and ? be a probability measure on ?(A ? B). Furthermore, let H be a Hilbert space and Lp(A, ?,H) be the space of all A-measurable H-valued functions that are p-integrable with respect to ?. Using the convention 00 := 0 we define the following mixing coefficients for the pair (A,B): ?(A,B, ?) := sup A?A B?B?(A ? B) ? ?(A)?(B)?(A,B, ?) := 12 sup?Xi=1 ?Xj=1?(Ai ? Bj) ? ?(Ai)?(Bj): (Ai) ? A and (Bj) ? B partitions?(A,B, ?) := sup A?A B?B?(A ? B) ? ?(A)?(B) ?(A) ?sym(A,B, ?) := p?(A,B, ?) - ?(B,A, ?) RHp (A,B, ?) := sup f?Lp(A,?,H) g?Lp(B,?,H)E?hf, gi ? hE?f,E?gi kfkp kgkp , p ? [2,?]. It is obvious from the definitions that all mixing coefficients equal 0 if A and B are independent. Furthermore, besides ? they are all symmetric in A and B. Moreover, we have ?(A,B, ?) ? [0, 1/4] and ?(A,B, ?),?(A,B, ?),?sym(A,B, ?),RHp (A,B, ?) ? [0, 1]. In addition, they satisfy the relations (see e.g. [23, Section 1] and the references therein): 2?(A,B, ?) ? ?(A,B, ?) ? ?(A,B, ?) 4?(A,B, ?) ? RRp (A,B, ?) ? 2?sym(A,B, ?) , p ? [2,?]. Moreover, the coefficients RHp (A,B, ?) are essentially equivalent to the coefficients RRp (A,B, ?) for the scalar case since [34, Thm. 4.1] shows that for all p ? [2,?] there exists a constant cp > 0 such 13
that for all Hilbert spaces H we have RRp (A,B, ?) ? RHp (A,B, ?) ? cp RRp (A,B, ?) . (23) Note that for p = 2 we actually have cp = 1 and for p = ? we may choose the famous Grothendieck constant (see the proof of Lemma 2.2 in [35]). Moreover, it is obvious from the definition that RHp (A,B, ?) is decreasing in p, i.e. RHp (A,B, ?) ? RHq (A,B, ?) , q ? p. In particular this yields RH?(A,B, ?) ? RHp (A,B, ?) ? RH2 (A,B, ?) for all p ? [2,?]. Finally, Theorem 4.13 in [36] gives the highly non-trivial relation RRp (A,B, ?) ? 2? ?1?2p (A,B, ?)?2p sym(A,B, ?) , p ? [2,?]. (24) In view of our consistency results we are mainly interested in the coefficients RHp . Note that with the help of the above inequalities these coefficients can be estimated by the typically more accessible coefficients ? and ?. The coefficient ?, which can often (see [36, Prop. 3.22] for an exact statement) be computed by ?(A,B, ?) = E? sup B?B?(B) ? E?(B|A), is mainly mentioned because it was used in earlier works (see e.g. [11, 37]) on learning from dependent observations. Let us now consider mixing coefficients and corresponding mixing notion for stochastic processes: Definition 3.1 Let (,A, ?) be a probability space, Z be a measurable space, and Z := (Zi)i?1 be a Z-valued stochastic process on . Furthermore, let ? be one of the above mixing coefficients. For i, j ? 1 we define the ?-bi-mixing coefficient of Z by ?(Z, ?, i, j) := ????(Zi), ?(Zj), ?, where ?(Zi) denotes the ?-algebra generated by Zi. Furthermore, for n ? 1 the ?-mixing and ??-mixing coefficients of Z are defined by ?(Z, ?, n) := sup i?1 ?(Z, ?, i, i + n) ??(Z, ?, n) := sup i?1 ????(Z1, . . . ,Zi), ?(Zi+n,Zi+1+n, . . . ), ?, respectively. In addition, we say that the process Z is: i) ?-mixing with respect to ? if the ?-mixing coefficients tend to 0, i.e. lim n>??(Z, ?, n) = 0 . ii) weakly ?-mixing with respect to ? if the ?-mixing coefficients tend to 0 on average, i.e. lim n>? 1nXn k=1 ?(Z, ?, k) = 0 . 14
iii) weakly ?-bi-mixing with respect to ? if the ?-bi-mixing coefficients tend to 0 on average, i.e. lim n>? 1 n2Xn i=1 Xi?1 j=1 ?(Z, ?, i, j) = 0 . (25) Finally, we define mixing notions analogous to i) and ii) for ??. It is immediately clear that ?(Z, ?, n) ? ??(Z, ?, n), and consequently, every upper bound on ??(Z, ?, n) translates into an upper bound on ?(Z, ?, n). This trivial observation is interesting since the literature typically deals with ??(Z, ?, n), whereas the consistency results which we will present in the following subsection only require bounds on ?(Z, ?, n) or ?(Z, ?, i, j). Finally, it is interesting to note that for stationary, homogeneous Markov chains Z we actually have ?(Z, ?, n) = ??(Z, ?, n) for all n ? 1 and ? 6= ?sym. Obviously, every ?-mixing process is weakly ?-mixing, and since a simple induction over n ? N shows Xn i=1 Xi?1 j=1 ?(Z, ?, i, j) = nX?1 k=1 nX?k m=1 ?(Z, ?,m + k,m) , n ? 1, we also see that every weakly ?-mixing process is weakly ?-bi-mixing. Moreover, if the process Z is ?-stationary in the wide sense then an elementary proof (see e.g. [36, Prop. 3.6]) shows ?(Z, ?, i, j) = ?(Z, ?, i+k, j+k) for all i, j, k ? 1. Since this implies ?(Z, ?, i, j) = ?(Z, ?, i?j+1) for i ? j ? 1 we then find Xn i=1 Xi?1 j=1 ?(Z, ?, i, j) = nX?1 k=1 nX?k m=1 ?(Z, ?,m + k,m) = nX?1 k=1(n ? k) ?(Z, ?, k + 1) (26) for all n ? 1. Consequently, every stationary weakly ?-bi-mixing process is actually weakly ?-mixing. Moreover, if the process Z is stationary and mixing in the sense of (11), then [23, Theorem 4.1] shows that ? ?(Z, ?, n0) < 1 or ? ?(Z, ?, n0) < 1 for some n0 ? 1 implies ? ?-mixing or ? ?-mixing, respectively. Finally, it is discussed on [23, p. 124] that stationary processes Z with ? ?(Z, ?, n0) < 1/2 for some n0 ? 1 are ??-mixing. Examples of ??-mixing, and in particular ??-mixing processes including certain Markov, ARMA, MA(?), and GARCH processes can be found in [38, Sect. 2.6.1] and [36, p. 405ff]. Moreover, mixing properties of Gaussian processes are considered in [36, Chapter 9]. In particular, [36, Theorem 9.5] shows ??(Z, ?, n) ? ?RR2 (Z, ?, n) ? 2???(Z, ?, n), n ? 1, for stationary Gaussian processes. Finally, [39, Theorem 26.5] together with [36, Proposition 3.18] shows that for all continuous, strictly decreasing functions g : [0,?) > (0, 1/24) for which x 7> log g(x) is convex there exists a stationary process Z with g(n)/4 ? ??(Z, ?, n) ? ??(Z, ?, n) ? 4g(n) for all n ? 1. Note that this result in particular shows that in general the ??-mixing rates can be arbitrarily slow. A brief survey of these and other results together with various references is given in [23]. For Markov chains there are quite a few results on mixing coefficients (see e.g. [23], [36, Chapter 7], and [40, Chapter 21]). Here we only recall the most important ones: [36, Theorem 7.5] (see also [23, Theorem 3.3]) shows that if a homogeneous Markov chain Z satisfies RR2 (Z, ?, n0) < 1 or ?(Z, ?, n0) < 1/2 for some n0 ? 1 then RR2 (Z, ?, n) or ?(Z, ?, n) tend at least exponentially fast to 0, and by considering the proof it is also possible to derive explicit bounds for this convergence. Moreover, if the Markov chain is also stationary, ergodic and aperiodic then ?(Z, ?, n0) < 1 suffices to obtain exponential ?-mixing rates. In contrast, for stationary Markov chains there are no similar results possible for ?-mixing coefficients (see e.g. [40, Theorem 21.3]) or ?-mixing coefficients (see 15
e.g. [36, Ex. 7.11]). Because of this lack previous learning results based on ?-mixing required rather strong additional assumptions on (stationary) Markov chains such as certain variants of geometric mixing conditions (see e.g. [11, p. 100ff] and compare with [23, Theorem 3.7] which shows that such geometric mixing conditions are equivalent to exponentially fast ?-mixing). Moreover, [23, Theorem 3.4] shows that stationary, ergodic, and aperiodic Markov chains Z with ?(Z, ?, n0) < 1/4 for some n0 ? 1 are automatically ?-mixing. Similarly, [23, Corollary 3.6] shows that stationary, aperiodic Markov chains are ?-mixing if and only if they are irreducible or Harris recurrent. Finally, stationary Markov processes Z satisfying Doeblin's condition (13) satisfy ?(Z, ?, n0) < 1 for some n0 ? 1 (see e.g. [23, p. 121]). Further information on mixing properties of Markov chains can be found in [40, Chapter 21]. Now let (Z,B, ?) be a probability space and Z := (Ti?1)i?1 be an invariant dynamical system on Z. For i ? j ? 1 we then have ?(Zi) = ?(Ti?1) ? ?(Tj?1) = ?(Zj ) and hence we obtain ?(Z, ?, i, j) ? sup A?(Zi)?(A ? A) ? ?(A)?(A)= sup B?B ?(B)??1 ? ?(B). Consequently, Z is not weakly ?-bi-mixing if B is not ?-trivial. However, note that images of dynamical systems can even be strongly ?-mixing. Indeed, every i.i.d. sequence is the image of an invariant dynamical system and the independence implies that all ?-coefficients are equal to 0. For more information on ergodic mixing and its relation to ?-mixing we refer to [39, Chapter 22] and [23]. Let us finally discuss some laws of large numbers for mixing processes. We begin with the following simple result which shows that asymptotically mean stationary, weakly bi-mixing processes satisfy the WLLNE: Proposition 3.2 Let (,A, ?) be a probability space, Z be a measurable space, and Z := (Zi)i?1 be a Z-valued stochastic process on which is weakly ?-bi-mixing with respect to ?. Then the following statements are equivalent: i) Z is AMS. ii) Z satisfies the WLLNE. For the quite simple proof of this proposition we refer to Section 4. Moreover, using [19, Thm. 8.2.1] it is easy to see that for ??-mixing processes AMS is actually equivalent to SLLNE. Finally, [41, Cor. 8.2.2] shows that identically distributed processes Z with ?Xn=1p? ?(Z, ?, 2n) < ? (27) satisfy the SLLN. Note that in the above summability condition only a "few" ??-coefficients are considered. In particular, (27) is satisfied whenever there are constants c > 0 and ? > 2 with ? ?(Z, ?, n) ? c (ln n)?for all n ? 2. 3.2 Consistency of SVMs for Mixing Processes In this subsection we establish consistency results for data-generating processes with known upper bounds on the weakly ?-bi-mixing rate. Unlike in the case of general processes satisfying a law of large numbers these new consistency results give explicit conditions on the regularization sequences guaranteeing consistency. 16
In order to formulate these results we have to introduce a new quantity. To this end let k be a bounded kernel over some set X. Then the supremum norm of k is defined by kkk? := sup x?Xpk(x, x) . Note that the boundedness of k implies kkk? < ?. Moreover, for the Gaussian kernels kwe have kkk? = 1. Now we can present our first consistency result which deals with locally Lipschitz-continuous loss functions: Theorem 3.3 Let X be a separable metric space, Y ? R be a closed subset and L : X ? Y ? R > [0,?) be a convex, locally Lipschitz continuous loss function with kL(., ., 0)k? ? c. Moreover, let (,A, ?) be a probability space, Z := ((Xi, Yi))i?1 be an X ? Y -valued, AMS stochastic process on , and P be the asymptotic mean of (Z, ?). In addition, let H be an (L, P)-rich RKHS over X with bounded continuous kernel k. We write B:= kkk?c?1/2 , ? > 0. Finally, assume that there are constants C ? (0,?) and ? ? (0, 1] with 1nXn i=1 E?f * Zi ? EP f? Ckfk?n?(28) 1 n2 Xn i=1 Xi?1 j=1 ?(Z, ?, i, j) ? Cn?(29) for all f ? L?(Z) and all n ? 1. Then for all null-sequence (?n) of strictly positive real numbers with |L|4Bn,1 ?2nn> 0 (30) the corresponding (?n)-SVM based on H and L is L-consistent for Z. The above result is of particular interest for binary classification problems. Indeed, recall that the standard SVM for classification uses the hinge loss defined by L(y, t) := max{0, 1 ? yt} , y ? Y := {?1, 1}, t ? R. Obviously, this loss function is convex and Lipschitz continuous with |L|1 = 1 and L(y, 0) = 1 for y ? Y . For X := Rd and Hbeing the RKHS of a Gaussian RBF kernel with fixed width ? we consequently obtain L-consistency for the corresponding (?n)-SVM whenever ?n > 0 and ?2nn> ?, where ? is the exponent satisfying (28) and (29). Since L-consistency implies binary classification consistency (see e.g. [3, 42]) we hence see that the above SVM is classification consistent. In particular, this consistency generalizes earlier consistency results of [1, 2, 3] with respect to both the compactness assumption on X and the i.i.d. assumption on the data-generating process. In the case of ? = 1 the SVMs using the hinge loss L and an (L, P)-rich RKHS is consistent if ?n > 0 and n?2n > ?. Since this is exactly the condition ensuring consistency in the i.i.d. case we see that such an SVM is quite robust against violations of the i.i.d. assumption. If quantitative approximation properties of H in terms of convergence rates for RL,P (fP,) > R?L,P are known, the proof Theorem 3.3 also provides learning rates. However, we conjecture that 17
these rates are usually overly conservative in terms of the confidence since we only employ Markov's inequality. Therefore we do not discuss these convergence rates in further detail. Instead we would like to compare our consistency result with the consistency result for regularized boosting algorithms derived in [37]. To this end we first observe that for (in the wide sense) stationary processes (28) is automatically satisfied and (29) is equivalent to 1nXn i=1 ?(Z, ?, i) ? Cn?, n ? 1, by (26). Obviously, the latter is satisfied if Z is algebraically ??-mixing with exponent ?, i.e. if it satisfies ??(Z, ?, n) ? Cn?for all n ? 1. Consequently, Theorem 3.3 implies consistency results for stationary, algebraically ??-mixing processes with known lower bound on the mixing rate. Compared to this [37] only establishes a consistency result for stationary, algebraically ? ?-mixing processes with known lower bound on the mixing rate. Since in general ??-mixing is strictly weaker assumption than ? ?-mixing we see that Theorem 3.3 substantially weakens the assumptions of [37]. Finally, note that our restriction to polynomial rates in (28) and (29) is by no means necessary. For example, if we replace n?by (log n)?in (28) and (29) then the corresponding condition on (?n) for the SVM using the hinge loss becomes ?2n(log n)> ?. In particular, note that such an SVM is consistent for all stationary, algebraically ?-mixing processes!4 In this direction it is interesting to recall that in [12] consistency was established for kernel estimators and algebraically ?-mixing, not necessarily stationary processes. To our best knowledge this is the consistency result that is closest in its assumptions on Z to Theorem 3.3. The proof of Theorem 3.3 is based on a stability argument together with a simple Markovtype concentration inequality for Hilbert space valued random variables. In principle, one could also employ exponential type inequalities for sums of R-valued random variables in the sense of e.g. [17, Chapter 1.4] together with a skeleton argument based on e.g. covering numbers. However, our preliminary considerations showed that the resulting conditions on (?n) were substantially stronger, and hence we do not discuss this approach in further detail. The next theorem establishes a result similar to Theorem 3.3 for distance-based loss functions of some growth type p: Theorem 3.4 Let L : R?R > [0,?) be a convex distance-based loss function of upper growth type p ? [1, 2]. Furthermore, let X be a separable metric space and H be an (L, P)-rich RKHS over X with bounded continuous kernel k. Moreover, let (,A, ?) be a probability space, Z := ((Xi, Yi))i?1 be an X?R-valued, AMS stochastic process on , and P be the asymptotic mean of (Z, ?). Assume that we have sup i?1 |?(Xi,Yi)|q < ? (31) for some q ? [p,?], where |.|q is defined by (18). Furthermore assume that there are constants C > 0 and ?, ? ? (0, 1] with 1n Xn i=1 E?f * Zi ? EP f? CkfkL1(P) n?(32) 1 n2 Xn i=1 Xi?1 j=1 ?1?2p?2 q (Z, ?, i, j)?2p?2 q sym (Z, ?, i, j) ? Cn?(33) 4 However, for such (n) the SVM typically deals too conservatively with the stochastic part of the learning process, so that the approximation behaviour is poor. As a consequence this result does not seem to have any practical relevance. 18
for all f ? L1(P) ? T?i=1 L1(?(Xi,Yi)). Then for all null-sequences (?n) of strictly positive real numbers with ?pnn2> ? (34) ?2p n n> ? (35) the corresponding (?n)-SVM based on H and L is L-consistent for Z. Since distance based loss functions are typically used for regression problems we see that the above theorem is mainly interesting for these learning scenarios. For Lipschitz continuous losses such as the absolute distance loss L(y, t) := |y?t|, the o-insensitive loss L(y, t) := max{0, |y?t|?o}, the logistic loss or Huber's robust loss we obviously have p = 1 and hence (33) reduces to (29). Moreover, for Lipschitz continuous losses we can choose q = 1 in (31). Consequently, it is easy to see that all remarks made for the classification SVM using the hinge loss, remain true for regression SVMs using one of the above losses. In contrast to this the least squares SVM which uses the standard least squares loss L(y, t) := (y?t) requires p = 2 in the above theorem. For processes with uniformly bounded noise, i.e. q = ?, we again see that (33) reduces to (29). Moreover, for q ? (2,?) we have 1 n2Xn i=1 Xi?1 j=1 ?1?2q (Z, ?, i, j)?2q sym(Z, ?, i, j) ? 1 n2 Xn i=1 Xi?1 j=1 ?(Z, ?, i, j)1?2q so that (29) implies (33) for ? := ?(1 ? 2/q). However, for q = 2 we have 1 ? 2p?2 q = 0, and consequently we only obtain consistency results for weakly ?sym-bi-mixing processes. Theorem 3.4 generalizes the only known consistency result (see [4]) for regression SVMs dealing with unbounded noise with respect to both the compactness assumption on X and the i.i.d. assumption on the data-generating process. In particular, Theorem 3.4 shows that such SVMs are rather robust against violations of these assumptions, and consequently it gives a strong justification of using such SVMs in rather general situations. Finally, we like to mention that condition (31) can be replaced by a weaker assumption describing the average behaviour of the sequence (|?(Xi ,Yi)|q)i?1. However, the resulting conditions on (?n) are more complicated and hence we omit the details. 4 Proofs 4.1 Proofs from Subsection 2.1 Proof of Lemma 2.3: Let B be the ?-algebra of Z. We write Pn(B) := 1n Pni=1 ?(Zi ? B) for B ? B and n ? 1. Then Pn is obviously a probability measure on B for all n ? 1. Now the theorem of Vitali-Hahn-Saks (see e.g. [43, p. 158-160]) ensures that P(B) := limn>? Pn(B), B ? B, defines a probability measure on B. Proof of Theorem 2.4: Recall that the convergence in probability ? can be described by the metric d(f, g) := Zmin1, |f ? g|d? , f, g ? L0(). Moreover, for measurable B ? Z let cB be the constant satisfying (1). The WLLNE and the above metric then shows lim n>?Z1n Xn i=1 1B * Zi ? cBd? = 0 . 19
Since k.kL1(?) is continuous on L1(?) we hence find lim n>? 1nXn i=1 E?1B * Zi = lim n>?Z1n Xn i=1 1B * Zid? = lim n>?Z1n Xn i=1 1B * Zid? = E?|cB| = cB , where the existence of the right limit implies the existence of the left limit. Consequently, Z is AMS and we have P(B) = cB. Obviously, the latter together with (1) immediately gives (4). Finally, if Z satisfies the SLLNE then we obtain the almost sure convergence in (4) from (2). Proof of Lemma 2.5: Let us begin by showing the assertion for the strong law. To this end we fix an ? > 0. By the approximation lemma for bounded measurable functions there exists a step function g : X > R with kf ? gk? ? ?. Now, the linearity of the limit shows EP g = lim n>? 1n Xn i=1 g * Zi(?) for ?-almost all ? ? , and consequently, [44, Lemma 20.6] gives an n0 ? 1 with ?sup n?n01n Xn i=1 g * Zi ? EP g? ?? 1 ? ? . (36) Moreover, for ? ? we have sup n?n01n Xn i=1 f * Zi(?) ? EP f? sup n?n01n Xn i=1 f * Zi(?) ? 1n Xn i=1 g * Zi(?)+ 1n Xn i=1 g * Zi(?) ? EP g+ EP g ? EP f? 2? + sup n?n01n Xn i=1 g * Zi(?) ? EP g, and hence we obtain ?sup n?n01n Xn i=1 f * Zi ? EP f? 3?? 1 ? ? . This shows the ?-almost sure convergence in (5). Using that the functions 1n Pni=1 f * Zi, n ? 1, are uniformly bounded Lebesgue's theorem then yields EP f = ZEP f d? = Zlim n>? 1n Xn i=1 f * Zid? = lim n>?Z1n Xn i=1 f * Zid? = lim n>? 1n Xn i=1 E?f * Zi , and hence we have found (6). Finally, if Z satisfies the WLLNE then pulling the supremum out of ? in (36) and adjusting the rest of the proof accordingly shows (5) with convergence in probability ?. Moreover, in this case (6) can be shown analogously to the argument used in the proof Theorem 2.4. 20
4.2 Proofs from Subsection 2.2 Proof of Proposition 2.7: ii) ? i). Follows from Theorem 2.4. i) ? ii). Let P be the stationary mean of (Z, ?). Then there exists an n0 ? 1 such that 1nXn i=1 E?1B * Zi ? P(B)< ?2 , n ? n0. For n ? n0 Markov's inequality then yields ?n? ? : 1n Xn i=1 1B * Zi(?) ? P(B)? ?o? ?n? ? : 1n Xn i=1 1B * Zi(?) ? 1n Xn i=1 E?1B * Zi? ?2o? 4??2n?2E?Xn i=1??1B * Zi ? E?1B * Zi2 . Let us write hi := 1B * Zi ? E?1B * Zi, i ? 1. Then we have E?hi = 0 and hi(?) ? [?1, 1] for all i ? 1 and all ? ? . Moreover, for i 6= j we have Ehihj = 0 since we assume that 1B * Zi and 1B * Zj are uncorrelated. Consequently, we obtain E?Xn i=1??1B * Zi ? E?1B * Zi2 ? n , from which we easily obtain the assertion. Proof of Proposition 2.9: Let us define Y := f *Z1 and Xn := 1n Pni=1 f *Zi, n ? 1. Then (10) states E(Xn?1 |Fn) = Xn for all n ? 2, and hence we obtain Xn = E(Xn?1 |Fn) = E??E(Xn?2 |Fn?1) |Fn= E(Xn?2 |Fn) = . . . = E(X1 |Fn) = E(Y |Fn) for all n ? 2. Moreover, X1 is F1-measurable and hence we also have X1 = E(X1 |F1) = E(Y |F1). Now, [45, Theorem 6.6.3] shows that limn>?Xn = EY almost surely. Furthermore, from Xn = E(Y |Fn), n ? 1, we also conclude E?Xn = E?Y = E?f *Z1, and hence ?Z1 is the asymptotic mean of (Z, ?). Combining these results then gives the assertion. Proof of Proposition 2.11: Without loss of generality we may assume that E is of canonical form, i.e. ?i = ?1 * Si?1, i ? 1, where ?1 : (Rd)N > Rd is the first coordinate projection, S is the shift operator on (Rd)N, and ? is a product measure, i.e. ? = (?')N for a suitable measure ?' on Rd. Then S := (Si?1)i?1 is weakly mixing, and consequently [24, p. 65] shows that Z ? S is ? ? ?-ergodic. By Theorem 2.10 we can then conclude that Z ? S satisfies the ? ? ?-SLLN. Moreover, we have Tn?1+?n = Tn?1+?1 *Sn?1 and hence Z +E is an image of the process Z ?S. From this we easily conclude that Z + E satisfies the ? ? ?-SLLN. 4.3 Proofs from Subsection 2.3 Before we prove Lemma 2.18 we first have to recall the following elementary lemma whose proof is omitted: 21
Lemma 4.1 Let (ai) be a sequence of real numbers and a ? R such that lim n>? 1nXn i=1 ai = a . Then for all n0 ? 0 we have lim n>? 1 n ? n0 Xn i=n0+1 ai = a . Proof of Lemma 2.18: Let us first assume that L is locally bounded. By Lemma 4.1 it then suffices to consider the case n0 = 0. Now observe that the function g(x, y) := L(x, y, f(x)), (x, y) ? X ? Y , is a bounded, measurable function since f is assumed to be bounded, and L is locally bounded. Applying Lemma 2.5 to the function g then gives the assertion. Let us now assume that L is a P-integrable Nemitski loss. Then there exists an b ? L1(P) and an increasing function h : [0,?) > [0,?) with g(x, y) ? b(x, y) + h??kfk?, (x, y) ? X ? Y. This shows g ? L1(P), and hence the assertion follows from Definition 2.6. 4.4 Proofs from Section 2.4 For the proof of Theorem 2.20 we need some preparations. Let us begin with the following result on the existence and uniqueness of infinite sample SVMs which is a slight extension of similar results established in [46, 4]: Theorem 4.2 Let L : X ? Y ? R > [0,?) be a convex loss function and P be a distribution on X ? Y such that L is a P-integrable Nemitski loss. Furthermore, let H be a RKHS of a bounded measurable kernel over X. Then for all ? > 0 there exists exactly one element fP,? H such that ?kfP,k2H + RL,P (fP,) = inf f?H ?kfk2H + RL,P (f) . (37) Furthermore, we have kfP,kH ? qRL,P (0) . The following two results describe the stability of the empirical SVM solutions. The first result was (essentially) shown in [46, 4]: Theorem 4.3 Let X be a separable metric space, L : X ? Y ? R > [0,?) be a convex, locally Lipschitz continuous loss function, and P be a distribution on X ? Y with RL,P (0) < ?. Furthermore, let H be the RKHS of a bounded, continuous kernel k over X with canonical feature map : X > H. We define B:= kkk?RL,P (0) ? 1/2 , ? > 0. Then for all ? > 0 there exists a bounded, measurable function h: X ? Y > R with khk? ? |L|B,1 (38) and fP,? fT,H ? 1?EP h? ET hH (39) for all training sets T = ((x1, y1), . . . , (xn, yn)) ? (X ? Y )n, where ET denotes the expectation operator with respect to the empirical measure associated to T, i.e. ET g := 1n Pni=1 g(xi, yi). 22
Recall that convex distance-based loss functions are in general not locally Lipschitz continuous. Nevertheless SVM using these losses still enjoy stability as the following result shows: Theorem 4.4 Let X be a separable metric space, L : R ? R > [0,?) be a convex, distance-based loss function of upper growth type p ? 1 and P a distribution on X ? R with |P|q < ? for some q ? [p,?]. Furthermore, let H be a RKHS of a bounded, continuous kernel over X with canonical feature map : X > H. Then there exists a constant cL > 0 depending only on L such that for all ? > 0 there exists a measurable function h: X ? Y > R with khkLs( ? P) ? 8pcL ??1 + | ? P|p?1 q + kfP,kp?1 ? (40) fP,? fT,H ? 1?EP h? ET hH (41) for s := q p?1 , all distributions ? P on X ? R with | ? P|q < ? and all training sets T ? (X ? Y )n. Finally, if L is also of lower growth type p then we additionally have khkLs(P) ? 16pcL ??1 + |P|p?1 q 1 + kfP,kq?p s ? . (42) Proof: By taking care in the constants in the proof of [4, Theorem 13] we obtain a measurable function h: X ? Y > R satisfying (41) and |h(x, y)| ? 4p cL max1, |y ? fP,(x)|p?1, (x, y) ? X ? Y, where cL is a suitable constant depending only on the loss function L. For q = ? we then easily find the assertion, and hence let us assume q ? [p,?). In this case, the above inequality yields h(x, y)s ? 4pscsL max1, |y ? fP,(x)|q? 4ps2q?1csL1 + |y|q + |fP,(x)|q. (43) Since q?1 s ? p and s ? 1 we then obtain (40). Moreover, if ? is the function satisfying L(y, t) = ?(y ? t), y, t ? R, we have EP |fP,|p ? 2p?1 ZX?Yy ? fP,(x)p + |y|p dP(x, y) ? 2p?1 ZX?Y c(1) L ???y ? fP,(x)+ 1 + |y|p dP(x, y) = 2p?1c(1) L RL,P (fP,) + 1 + |P|pp ? 2p?1c(1) L RL,P (0) + 1 + |P|pp ? 2p?1c(2) L ??1 + |P|pp + 1 + |P|pp ? 2pc(3) L ??1 + |P|pp , where c(1) L , c(2) L ? 1, and c(3) L ? 1 are suitable constants depending only on the loss function L. Combining the estimate on EP |fP,|p with (43) then gives khkLs(P) ? 4p 2q?1 s cL1 + |P|p?1 q + kfP,kq?p s ? ??EP |fP,|p1s ? 4p 2q?1 s cL1 + |P|p?1 q + kfP,kq?p s ? ??2pc(3) L (1 + |P|pp)1s ? 4p 2p+q s ??c(4) L 1+1s ??1 + |P|ps p + |P|p?1 q ??1 + kfP,kq?p s ? , 23
where c(4) L ? 1 is another suitable constant depending only on the loss function L. Now note that we have p+q s = ( pq + 1)(p ? 1) ? 2(p ? 1) and 1 + 1s ? 2. These estimates together with |P|ps p ? |P|ps q = |P|p(p?1) q q ? 1 + |P|p?1 q then yield (42). The next lemma establishes Hilbert space valued laws of large numbers which are later used to bound the term EP h? EThH. Lemma 4.5 Let (,A, ?) be a probability space, Z be a Polish space, and Z := (Zi)i?1 be a Zvalued stochastic process on . Assume that Z satisfies the WLLNE and let P be the asymptotic mean of (Z, ?). Furthermore, let H be a Hilbert space, and : Z > H be a continuous and bounded map. Then for all h ? L?(P) we have lim n>? 1nXn i=1(h) * Zi = EP h, (44) where the convergence is in probability ?. Moreover, if Z actually satisfies the WLLN then (44) holds for all f ? L1(P). Finally, the convergence holds ?-almost surely for all f ? L?(P) or f ? L1(P) if Z satisfies the SLLNE or SLLN, respectively. Proof: Let us first show (44) for f ? L1(P) when Z satisfies the SLLN. To this end we first make the additional assumption that there exists a compact subset K ? Z with h(z) = 0 for all z 6? K. Now recall that is continuous and hence (K) ? H is compact. Moreover, recall that H as a Hilbert space has the approximation property (see e.g. [47, p. 30ff] for details on this concept). For a fixed ? > 0 there consequently exists a bounded linear operator S : H > H with m := rank S < ? and kS(z) ? (z)kH ? ? , z ? K. Let e1, . . . , em be an ONB of the image SH of H under S. Since hej , Si : Z > R, j = 1, . . . ,m, are bounded measurable functions we then find that hej , hSi = hhej , Si , j = 1, . . . ,m, are P-integrable. Consequently, they satisfy the limit relation (8), and by a well-known reformulation of almost sure convergence (see e.g. [44, Lem. 20.6]) there hence exists an n" such that with probability not less than 1 ? ? we have both sup n?n" sup j=1,...,m1n Xn i=1ej , hS* Zi(?) ? EP hej , hSi? ?m?1/2 and sup n?n"1n Xn i=1 |h| * Zi(?) ? EP |h|? ? . 24
Let us fix an n ? n" and an ? ? which satisfies these two inequalities. Using h(z) = 0 for all z ? Z\K we then have 1nXn i=1(h) * Zi(?) ? 1n Xn i=1(hS) * Zi(?)H ? 1n Xn i=1 |h| * Zi(?) - k* Zi(?) ? S* Zi(?)kH ? ?n Xn i=1 |h| * Zi(?) ? ???? + EP |h|? ? + ?EP |h| . Moreover, n and ? also satisfy 1n Xn i=1(hS) * Zi(?) ? EP hSH = Xm j=1Dej , 1n Xn i=1(hS) * Zi(?) ? EP hSE21/2 ? vm sup j=1,...,m1n Xn i=1ej , hS* Zi(?) ? EP hej , hSi? ? . In addition, h(z) = 0 for all z ? Z\K implies EP hS? EP hH ? ZK |h(z)| - kS(z) ? (z)kH dP(z) ? ?EP |h| , and consequently we can conclude 1n Xn i=1(h) * Zi(?) ? EP hH ? 1n Xn i=1(h) * Zi(?) ? 1n Xn i=1(hS) * Zi(?)H +1n Xn i=1(hS) * Zi(?) ? EP hSH + EP hS?EP hH ? 2???1 + EP |h|. This shows?? ? : sup n?n"1n Xn i=1(h) * Zi(?) ? EP hH ? 2???1 + EP |h|? 1 ? ? , and hence [44, Lemma 20.6] yields the assertion for our special case. Let us now prove the assertion for general h ? L1(P). To this end we may assume without loss of generality that k(z)k ? 1 for all z ? Z. Let us fix an ? > 0. Since Z is Polish the measures P and |h|P are regular and hence there then exists a compact subset K ? Z with P(Z\K) ? ? and ZZ\K |h| dP ? ? . Now g := 1Kh is a P-integrable function that vanishes outside the compact set K. Our preliminary considerations and the SLLN consequently show that there exists an n" ? 1 such that with probability not less than 1 ? ? we have both sup n?n"1n Xn i=1(g) * Zi(?) ? EP gH ? ? 25
and sup n?n"1nXn i=1??1Z\K|h|* Zi(?) ? EP 1Z\K|h|? ? Let us fix an n ? n" and an ? ? which satisfies these two inequalities. Using h?g = 1Z\Kh and k(z)k ? 1 for all z ? Z we then obtain 1n Xn i=1(h) * Zi(?) ? EP hH ? 1n Xn i=1(h) * Zi(?) ? 1n Xn i=1(g) * Zi(?)H +1n Xn i=1(g) * Zi(?) ? EP gH + EP g? EP hH ? 1n Xn i=1??1Z\K|h|* Zi(?) + ? + EP 1Z\K|h| ? ? + EP 1Z\K|h| + ? + EP 1Z\K|h| ? 4? . Therefore we obtain ?? ? : sup n?n"1n Xn i=1(h) * Zi(?) ? EP hH ? 4?? 1 ? ? , and hence we obtain the assertion by another application of [44, Lemma 20.6]. Finally, if Z only satisfies the WLLN then we obtain the assertion by omitting the terms supn?n" in the above proof. Moreover, for processes satisfying only a law of large numbers for events we have to use Lemma 2.5 instead of Definition 2.6. In order to prove Theorem 2.20 we finally need the following technical lemma: Lemma 4.6 Let F : (0,?) ? N > [0,?) be a function with limn>? F(?, n) = 0 for all ? > 0. Then there exists a sequence (?n) ? (0, 1] with lim n>??n = 0 and lim n>?F(?n, n) = 0 . Proof: For k ? 1 there exists an nk ? 1 such that for all n ? nk we have F(k?1, n) < k?1 . (45) Obviously, we may assume without loss of generality that nk < nk+1 for all k ? 1. For n ? 1 we write ?n := (1 if 1 ? n < n1 k?1 if nk ? n < nk+1 . Now let ? > 0. Then there exists an integer k ? 1 with k?1 ? ?. Let us fix an n ? nk. Then there exists an i ? k with ni ? n < ni+1, and consequently we have ?n = i?1. This gives ?n = i?1 ? k?1 ? ? , 26
and since (45) together with ni ? n yields F(i?1, n) ? i?1 we also find F(?n, n) = F(i?1, n) ? i?1 ? ? . These estimates show the assertion. Proof of Theorem 2.20: We only show the assertion in the case of Z satisfying the SLLNE. Since L is locally bounded, the function L(., ., 0) is bounded and hence we may assume without loss of generality that RL,Q(0) ? 1 for all distributions Q on X ? Y . By a standard argument this assumption leads to kfQ,kH ? ??1/2 for all distributions Q on X?Y and all ? > 0. Moreover, we may assume without loss of generality that kkk? ? 1, so that we have kfk? ? kfkH for all f ? H. Now, let us fix an ? > 0. Since a simple argument shows that lim>0 RL,P (fP,) = R?L,P,H = R?L,P we then find RL,P (fTn(!),) ? R?L,P? RL,P (fTn(!),) ? RL,P (fP,)+RL,P (fP,) ? R?L,P? |L|?1/2,1 kfTn(!),? fP,k? + ? ? |L|?1/2,1 ? ETn(!)h? EP hH + ? for all n ? 1, ? ? , and all sufficiently small ? > 0, where h: X ? Y > R is the function according to Theorem 4.3, and ETn(!) denotes the expectation operator with respect to the empirical distribution associated to the training set Tn(?) = ((X1(?), Y1(?)), . . . , (Xn(?), Yn(?))), i.e. ETn(!)g = 1n Pni=1 g(Xi(?), Yi(?)). Furthermore, for all ? ? (0, ?] and n ? 1 we have ?n? ? : sup m?n |L|?1/2,1 ? ETm(!)h? EP hH ? ?o? ?n? ? : sup m?nETm(!)h? EP hH ? ?2 |L|?1/2,1o=: F(?, n) . Moreover, by Theorem 4.3 we know that his a bounded function for all ? > 0 and consequently, Lemma 4.5 yields limn>? F(?, n) = 0 for all ? ? (0, ?]. Now Lemma 4.6 shows that there exists a sequence (?n) with ?n > 0 and F(?n, n) > 0. For fixed ? > 0 there consequently exists an n0 ? 1 such that for all n ? n0 we have |RL,P (fP,n) ? R?L,P | ? ?, ?n ? ?, and F(?n, n) ? ?. For such n our previous considerations then show ?n? ? : sup m?nRL,P (fTm(!),m) ? R?L,P? 2?o? ?n? ? : sup m?n |L|?1/2 m ,1 ?m ETm(!)hm? EP hmH ? ?o? F(?n, n) ? ? . This shows the assertion. 27
Proof of Theorem 2.21: Again, we only show the assertion in the case of Z satisfying the SLLN. Obviously, we may assume without loss of generality that kkk? ? 1, so that we have kfk? ? kfkH for all f ? H. Moreover, since |P|p < ? we may additionally assume without loss of generality that both |P|p ? 1 and RL,P (0) ? 1. Note that the latter assumption immediately yields kfP,kH ? ??1/2 for all ? > 0. Let ? : R > [0,?) be the function satisfying L(y, t) = ?(y ? t), y, t ? R. The assumption |P|p < ? then guarantees ? ? L1(P) and hence the SLLN shows lim n>?RL,Tn(!)(0) = lim n>?ETn(!)? = EP? = RL,P (0) (46) for ?-almost all ? ? . Moreover, we have ?kfTn(!),k2H ? RL,Tn(!)(0) for all n ? 1, ? > 0, and ? ? , and consequently the "local Lipschitz continuity" of the L-risk established in [4, Lemma 25] together with Theorem 4.4 yields RL,P (fTn(!),) ? RL,P (fP,)? cp|P|p?1 + kfTn(!),kp?1 ? + kfP,kp?1 ? + 1kfTn(!),? fP,k? ? cp ? 2 + RL,Tn(!)(0) ? p?1 2 + ??p?1 2 kETn(!)h? EP hkH for all n ? 1, ? > 0, and ? ? . Let us fix an ? > 0. For ? ? (0, ?] and n ? 1 we then obtain ?n? ? : sup m?nRL,P (fTm(!),) ? RL,P (fP,)? ?o? ?? ? : sup m?n2 + RL,Tm(!)(0) ? p?1 2 + ??p?1 2 kETm(!)h? EP hkH ? ?2 cp =: F(?, n) . Moreover, Theorem 4.4 ensures h? L1(P) for all ? > 0 and hence Lemma 4.5 together with (46) shows limn>? F(?, n) = 0 for all ? ? (0, ?]. Now the rest of the proof is analogous to the proof of Theorem 2.20. 4.5 Proofs from Subsection 3.1 Proof of Proposition 3.2: ii) ? i). Follows from Theorem 2.4. i) ? ii). Let P be the stationary mean of (Z, ?). As in the proof of Proposition 2.7 we then find an n0 ? 1 such that for all n ? n0 we have ?n? ? :1nXn i=1 1B * Zi(?) ? P(B)? ?o? 4??2n?2E?Xn i=1??1B * Zi ? E?1B * Zi2 . Let us write hi := 1B * Zi ? E?1B * Zi, i ? 1. Then we have E?hi = 0 and hi(?) ? [?1, 1] for all i ? 1 and all ? ? . Consequently, (24) gives RR?(Z, ?, i, j) ? 2??(Z, ?, i, j), i, j ? 1, and hence we obtain E?Xn i=1??1B * Zi ? E?1B * Zi2 = E? Xn i=1 h2i+ 2E? Xn i=1 Xi?1 j=1 hihj ? n + 4? Xn i=1 Xi?1 j=1 ?(Z, ?, i, j) . Combining the estimates then yields the assertion. 28
4.6 Proofs from Subsection 3.2 Proof of of Theorem 3.3: Let B be the ?-algebra of Z. We write Pn(B) := 1n Pni=1 ?(Zi ? B) for B ? B and n ? 1. Then Pn is obviously a probability measure on B for all n ? 1. Let us first show that lim n>?RL,P (fPn,n) = R?L,P . (47) To this end we first observe that the assumption (28) yields RL,P (fPn,n) ? ?nkfPn,nk2H + RL,Pn(fPn,n) + CkL * fPn,nk?n?? ?nkfP,nk2H + RL,Pn(fP,n) + CkL * fPn,nk?n?? ?nkfP,nk2H + RL,P (fP,n) + Cn???kL * fP,nk? + kL * fPn,nk?(48) for all n ? 1. Now R?L,P,H = R?L,P together with ?n > 0 yields ?nkfP,nk2H +RL,P (fP,n) > R?L,P . Moreover, for every distribution Q on Z we have kL * fQ,k? ? c + |L|kfQ,k?,1kfQ,k? ? c + |L|B,1Bby (16) and Theorem 4.2. In addition, (|L|Bn,1) is a non-decreasing sequence and the sequence (Bn) is dominated by the sequence (??1/2 n ). Consequently, (30) implies n?|L|Bn,1Bn > 0 and hence we find (47). Let us now fix an ? > 0. Then Theorem 4.3 and Markov's inequality yield ?n? ? :RL,P (fTn(!),n) ? RL,P (fPn,n)? ?o? ?n? ? : |L|Bn,1 kfTn(!),n ? fPn,nk? ? ?o? ?n? ? : kkk?|L|Bn,1 ETn(!)hn? EPnhnH ? ??no? kkk2?|L|2Bn,1 ?2?2n E!??ETn(!)hn? EPnhn2H where hn is the function according to Theorem 4.3 for the distribution Pn and the regularization parameter ?n. Let us definegn,i := (hn) * (Xi, Yi) ? E?(hn) * (Xi, Yi) for n ? 1 and i = 1, . . . , n. Then we have E?gn,i = 0 and Theorem 4.3 yields kgn,ik? ? 2 sup !?k(hn) * (Xi, Yi)(?)kH ? 2 khnk? kkk? ? 2 kkk?|L|Bn,1 . 29
Consequently, (24) and (23) show that there exists a universal constant c ? 1 such that E!??ETn(!)hn? EPnhn2H = n?2 E!??Xn i=1(hn) * (Xi, Yi)(?) ? E?(hn) * (Xi, Yi)2H = n?2 Xn i=1 E?hgn,i, gn,ii + 2n?2 Xn i=1 Xi?1 j=1 E?hgn,i, gn,ji ? n?2 Xn i=1 kgn,ik2? + 2n?2 Xn i=1 Xi?1 j=1 RH?(Z, ?, i, j)kgn,ik?kgn,jk? ? 4n?1kkk2?|L|2Bn,1 + c kkk2?|L|2Bn,1n?2 Xn i=1 Xi?1 j=1 ?(Z, ?, i, j) for all n ? 1. By combining all estimates and using (30) we then obtain the assertion. Proof of Theorem 3.4: Without loss of generality we assume kkk? ? 1 and |?(Xi,Yi)|q ? 1 for all i ? 1. In addition, we can obviously, also assume ?n ? (0, 1] for all n ? 1. Now, we define Pn(B) := 1n Pni=1 ?(Zi ? B) for measurable B ? X ? R and n ? 1. For r ? [1, q] a simple calculation then shows |Pn|rr= ZX?R |y|rdPn(x, y) = 1n Xn i=1 ZX?R |y|rd?(Xi,Yi)(x, y) = 1n Xn i=1 |?(Xi,Yi)|rr ? 1 . (49) Moreover, [44, Thm. 23.8] together with Fatou's lemma yields |P|rr= Z ? 0 P??{(x, y) ? X ? R : |y|r ? t}dt = Z ? 0 lim n>? 1n Xn i=1 ???{? ? : |Yi(?)|r ? t}dt ? liminf n>? Z ? 0 1n Xn i=1 ???{? ? : |Yi(?)|r ? t}dt ? liminf n>? 1n Xn i=1 |?(Xi,Yi)|rr ? 1 . Having finished these preparations we can now begin with the actual proof. To this end first observe that we obtain RL,P (fPn,n) ? ?nkfP,nk2H +RL,P (fP,n) + Cn???kL * fP,nkL1(P) + kL * fPn,nkL1(P)as in (48). Moreover, we obviously have kL * fP,nkL1(P) = RL,P (fP,n) ? RL,P (0) ? c for some 30
constant c independent of n. In addition, (49) yields kL * fPn,nkL1(P) = ZX?Y ???y ? fPn,n(x)dP(x, y) ? ?cp ZX?Y 1 + |y|p + |fPn,n(x)|pdP(x, y) ? 2?cp + ?cpkfPn,nkp? ? 2?cp + ?cpkkkp?RL,Pn(0) ?n p2 ? 2cp + cp??p2 n , where ?cp and cp are constants only depending on L and p. Combining these estimates with lim>0 RL,P (fP,) = R?L,P,H = R?L,P and (34) we then obtain limn>?RL,P (fPn,n) = R?L,P . Now let us assume that we have an ? ? and an n ? 1 with kfTn(!),n ? fPn,nkH ? 1. For p > 1 a simple calculation using [4, Lemma 25] and ?n ? 1 then shows RL,P (fPn,n) ? RL,P (fTn(!),n )? Cp |P|p?1 p?1 + kfPn,nkp?1 ? + kfTn(!),nkp?1 ? + 1kfPn,n ? fTn(!),nk? ? Cp 2 + 2kfPn,nkp?1 ? + kfTn(!),n ? fPn,nkp?1 ? kfPn,n ? fTn(!),nkH ? Cp  3 + 2RL,Pn(0) ?n p?1 2 !kfPn,n ? fTn(!),nkH ? ? Cp ??p?1 2 n kfPn,n ? fTn(!),nkH ? ? Cp ??p+1 2 n ETn(!)hn? EPnhnH , where Cp ? 1 and ? Cp ? 1 are constants only depending on p and L, and hn is the function according to Theorem 4.3 for the distribution Pn and the regularization parameter ?n. Moreover, for p = 1 we see that L is Lipschitz continuous by [4, Lemma 4] and hence the above estimate is also true in this case. Let us now definegn,i := (hn) * (Xi, Yi) ? E?(hn) * (Xi, Yi) for n ? 1 and i = 1, . . . , n. Then we have E?gn,i = 0 and for s := q p?1 we find kgn,ikLs(?) ? 2khnkLs(?(Xi,Yi)) ? 128cL ??1 + |?(Xi,Yi)|p?1 q + kfPn,nkp?1 ? ? 128cL  2 + RL,Pn(0) ?n p?1 2 ! ? CL,p ??p?1 2 n , where CL,p > 0 is a constant only depending on L and p. For ? > 0 Markov's inequality together 31
with s ? 2, (24) and (23) thus yields ?n? ? :ETn(!)hn? EPnhnH ? ?o? 1 ?2n2Xn i=1 E?hgn,i, gn,ii + 2 Xn i=1 Xi?1 j=1 E?hgn,i, gn,ji? 1 ?2n2Xn i=1 kgn,ik2Ls(?) + 2 Xn i=1 Xi?1 j=1 RHs (Z, ?, i, j)kgn,ikLs(?)kgn,jkLs(?)? ? CL,p ?2?p?1 n n + ? CL,p ?2?p?1 n n2 Xn i=1 Xi?1 j=1 ?1?2p?2 q (Z, ?, i, j)?2p?2 q sym (Z, ?, i, j) ? (1 + C) ? CL,p ?2?p?1 n n, where ? CL,p > 0 is another constant only depending on L and p. Let us now fix an ? ? (0, 1]. For ? ? and n ? 1 with ETn(!)hn? EPnhnH < ??(p+1)/2 n? Cp we then have kfTn(!),n ? fPn,nkH < "(p?1)/2 n ? Cp ? 1, and consequently we can conclude ?n? ? : RL,P (fPn,n) ? RL,P (fTn(!),n )< ?o? ?n? ? : ETn(!)hn? EPnhnH < ??(p+1)/2 n? Cp o? 1 ? (1 + C) ? CL,p ? C2p ?2?2p n n. Using (35) then yields the assertion. References [1] I. Steinwart. Support vector machines are universally consistent. J. Complexity, 18:768-791, 2002. [2] T. Zhang. Statistical behaviour and consistency of classification methods based on convex risk minimization. Ann. Statist., 32:56-134, 2004. [3] I. Steinwart. Consistency of support vector machines and other regularized kernel machines. IEEE Trans. Inform. Theory, 51:128-142, 2005. [4] A. Christmann and I. Steinwart. Consistency and robustness of kernel based regression. Bernoulli, to appear, 2007. http://www.c3.lanl.gov/ml/pubs/2005_regression/paper.pdf. [5] D.R. Chen, Q. Wu, Y.M. Ying, and D.X. Zhou. Support vector machine soft margin classifiers: Error analysis. Journal of Machine Learning Research, 5:1143-1175, 2004. [6] I. Steinwart and C. Scovel. Fast rates for support vector machines. In Proceedings of the 18th Annual Conference on Learning Theory, COLT 2005, pages 279-294. Springer, 2005. [7] G. Blanchard, O. Bousquet, and P. Massart. Statistical performance of support vector machines. Ann. Statist., submitted, 2004. 32
[8] V. Koltchinskii and O. Beznosova. Exponential convergence rates in classification. In Proceedings of the 18th Annual Conference on Learning Theory, COLT 2005, pages 295-307. Springer, 2005. [9] I. Steinwart and C. Scovel. Fast rates for support vector machines using Gaussian kernels. Ann. Statist., 35:to appear, 2007. [10] A.B. Nobel. Limits to classification and regression estimation from ergodic processes. Ann. Statist., 27:262-273, 1999. [11] M. Vidyasagar. A Theory of Learning and Generalization: With Applications to Neural Networks and Control Systems. Springer, London, 2nd edition, 2002. [12] A. Irle. On consistency in nonparametric estimation under mixing conditions. J. Multivariate Anal., 60:123-147, 1997. [13] L. Gy?orfi, M. Kohler, A. Krzy?zak, and H. Walk. A Distribution-free Theory of Nonparametric Regression. Springer, New York, 2002. [14] D.S. Modha and E. Masry. Memory-universal prediction of stationary random processes. IEEE Trans. Inform. Theory, 44:117-133, 1998. [15] R. Meir. Nonparametric time series prediction through adaptive model selection. Machine learning, 39:5-34, 2000. [16] L. Gy?orfi, W. H?ardle, P. Sarda, and P. Vieu. Nonparametric Curve Estimation from Time Series. Springer, Berlin, 1989. [17] D. Bosq. Nonparametric Statistics for Stochastic Processes. Springer, New York, 2nd edition, 1998. [18] R.M. Gray and J.C Kieffer. Asymptotically mean stationary measures. Ann. Probab., 8:962-973, 1980. [19] P. R?ev?esz. The Laws of Large Numbers. Academic Press, New York, 1968. [20] N. Etemadi. An elementary proof of the strong law of large numbers. Z. Wahrsch. Verw. Gebiete, 55:119-122, 1981. [21] M. Brin and G. Stuck. Dynamical Systems. Cambridge University Press, 2002. [22] U. Krengel. Ergodic Theorems. de Gruyter, Berlin, 1985. [23] R.C. Bradley. Basic properties of strong mixing conditions. A survey and some open questions. Probability Surveys, 2:107-144, 2005. [24] K. Petersen. Ergodic Theory. Cambridge University Press, paperback edition, 1989. [25] J.L. Doob. Stochastic Processes. Wiley, New York, 1953. [26] R. Bhattacharya and E.C. Waymire. Iterated random maps and some classes of markov processes. In D.N. Shanbhag and C.R. Rao, editors, Handbook of Statistics 19, pages 145-170. North-Holland, 2001. [27] J.R. Norris. Markov Chains. Cambridge University Press, 1997. [28] N. Aronszajn. Theory of reproducing kernels. Trans. Amer. Math. Soc., 68:337-404, 1950. [29] N. Cristianini and J. Shawe-Taylor. An Introduction to Support Vector Machines. Cambridge University Press, 2000. [30] B. Sch?olkopf and A.J. Smola. Learning with Kernels. MIT Press, 2002. [31] I. Steinwart, D. Hush, and C. Scovel. Function classes that approximate the Bayes risk. In Proceedings of the 19th Annual Conference on Learning Theory, COLT 2006, pages 79-93. Springer, 2006. [32] I. Steinwart. On the influence of the kernel on the consistency of support vector machines. J. Mach. Learn. Res., 2:67-93, 2001. [33] L. Devroye, L. Gy?orfi, and G. Lugosi. A Probabilistic Theory of Pattern Recognition. Springer, New York, 1996. 33
[34] R.C. Bradley, W. Bryc, and S. Janson. Remarks on the foundations of measures of dependence. In M.L. Puri, J.P. Vilaplana, andW.Wertz, editors, New Perspectives in Theoretical and Applied Statistics, pages 421-437. Wiley, 1987. [35] H. Dehling and W. Philipp. Almost sure invariance principles for weakly dependent vector-valued random variables. Ann. Probab., 10:689-701, 1982. [36] R.C. Bradley. Introduction to Strong Mixing Conditions, volume 1. Technical Report, Department of Mathematics, Indiana University, Bloomington, Custom Publishing of I.U., Bloomington, 2005. [37] A.C. Lozano, S.R. Kulkarni, and R.E. Schapire. Convergence and consistency of regularized boosting algorithms with stationary ?-mixing observations. In Y. Weiss, B. Sch?olkopf, and J. Platt, editors, Advances in Neural Information Processing Systems 18. MIT Press, Cambridge, MA, 2006. [38] J. Fan and Q. Yao. Nonlinear Time Series. Springer, New York, 2003. [39] R.C. Bradley. Introduction to Strong Mixing Conditions, volume 3. Technical Report, Department of Mathematics, Indiana University, Bloomington, Custom Publishing of I.U., Bloomington, 2005. [40] R.C. Bradley. Introduction to Strong Mixing Conditions, volume 2. Technical Report, Department of Mathematics, Indiana University, Bloomington, Custom Publishing of I.U., Bloomington, 2005. [41] L. Zhengyan and L. Chuanrong. Limit Theory for Mixing Dependent Random Variables. Science Press and Kluwer, New York and Dordrecht, 1996. [42] P.L. Bartlett, M.I. Jordan, and J.D. McAuliffe. Convexity, classification, and risk bounds. J. Amer. Statist. Assoc., 101:138-156, 2006. [43] N. Dunford and J.T. Schwartz. Linear Operators, Part I: General Theory. Wiley, New York, Wiley Classics Library edition, 1988. [44] H. Bauer. Measure and Integration Theory. De Gruyter, Berlin, 2001. [45] R.B Ash and C.A. Dol?eans-Dade. Probability & Measure Theory. Academic Press, San Diego, 2nd edition, 2000. [46] E. DeVito, L. Rosasco, A. Caponnetto, M. Piana, and A. Verri. Some properties of regularized kernel methods. J. Mach. Learn. Res., 5:1363-1390, 2004. [47] J. Lindenstrauss and L. Tzafriri. Classical Banach spaces I. Springer, Berlin, 1977. 34