1.4. Теоретическая база прикладной статистики	В настоящем разделе собраны основные математико-статистические утверждения, постоянно используемые при математическом обосновании методов прикладной статистики. Эти утверждения отнюдь не всегда легко найти в литературе по теории вероятностей и математической статистике. Например, такие рассматриваемые далее теоремы и методы, как многомерная центральная предельная теорема, теоремы о наследовании сходимости и метод линеаризации, даже не включены в энциклопедию "Вероятность и математическая статистика" [1] - наиболее полный свод знаний по этой тематике. Последний факт наглядно демонстрирует разрыв между математической дисциплиной "теория вероятностей и математическая статистика" и потребностями прикладной статистики. 1.4.1. Законы больших чисел	Законы больших чисел позволяют описать поведение сумм случайных величин. Примером является следующий результат, обобщающий полученный ранее в подразделе 1.2.2. Там было доказано следующее утверждение.	Теорема Чебышёва. Пусть случайные величины Х1, Х2,., Хk попарно независимы и существует число С такое, что D(Xi)<C при всех i = 1, 2, ., k. Тогда для любого положительного ? выполнено неравенство   (1)	Частным случаем теоремы Чебышева является теорема Бернулли - первый в истории вариант закона больших чисел. 	Теорема Бернулли. Пусть m - число наступлений события А в k независимых (попарно) испытаниях, и р есть вероятность наступления события А в каждом из испытаний. Тогда при любом  справедливо неравенство   (2)Ясно, что при росте k выражения в правых частях формул (1) и (2) стремятся к 0. Таким образом, среднее арифметическое попарно независимых случайных величин сближается со средним арифметическим их математических ожиданий.	Напомним, что в разделе 1.2 шла речь лишь о пространствах элементарных событий из конечного числа элементов. Однако приведенные теоремы верны и в общем случае, для произвольных пространств элементарных событий. Однако в условие закона больших чисел необходимо добавить требование существования дисперсий. Легко видеть, что если существуют дисперсии, то существуют и математические ожидания. Закон больших чисел в форме Чебышёва приобретает следующий вид.	Теорема Чебышева [2, с.147]. Если Х1, Х2,., Хk ,. - последовательность попарно независимых случайных величин, имеющих конечные дисперсии, ограниченные одной и той же постоянной, D(X1)<C, D(X2)<C,. D(лi)<C,.то, каково бы ни было постоянное ? > 0,  (3)	С точки зрения прикладной статистики ограниченность дисперсий вполне естественна. Она вытекает, например, из ограниченности диапазона изменения практически всех величин, используемых при реальных расчетах. 	В 1923 г. А.Я. Хинчин показал, что если случайные величины не только независимы, но и одинаково распределены, то существование у них математического ожидания является необходимым и достаточным условием для применимости закона больших чисел [2, с.150].  	Теорема [2, с.150-151]. Для того чтобы для последовательности Х1, Х2,., Хk ,.(как угодно зависимых) случайных величин при любом положительном ? выполнялось соотношение (3), необходимо и достаточно, чтобы при n > ?	Законы больших чисел для случайных величин служат основой для аналогичных утверждений для случайных элементов в пространствах более сложной природы. В частности, в пространствах произвольной природы (см. подраздел 2.1.5 далее). Однако здесь мы ограничимся классическими формулировками, служащими основой для современной прикладной статистики.	Смысл классических законов больших чисел состоит в том, что выборочное среднее арифметическое независимых одинаково распределенных случайных величин  приближается (сходится ) к математическому ожиданию этих величин. Другими словами, выборочные средние сходятся к теоретическому среднему. 	Это утверждение справедливо и для других видов средних. Например, выборочная медиана сходится к теоретической медиане. Это утверждение - тоже закон больших чисел, но не классический. 	Существенным продвижением в теории вероятностей во второй половине ХХ в. явилось введение средних величин в пространствах произвольной природы и получение для них законов больших чисел, т.е. утверждений, состоящих в том, что эмпирические (т.е. выборочные )средние сходятся к теоретическим средним. Эти результаты будут рассмотрены в подразделе 2.1.5 ниже.1.4.2. Центральные предельные теоремы	В разделе 1.2. уже был приведен простейший вариант Центральной предельной теоремы (ЦПТ) теории вероятностей.	Центральная предельная теорема (для одинаково распределенных слагаемых). Пусть X1, X2,., Xn, .- независимые одинаково распределенные случайные величины с математическими ожиданиями M(Xi) = m и дисперсиями D(Xi) = , i = 1, 2,., n,. Тогда для любого действительного числа х существует предел где Ф(х) - функция стандартного нормального распределения.	Эту теорему иногда называют теоремой Линдеберга-Леви [3, с.122].	В ряде прикладных задач не выполнено условие одинаковой распределенности. В таких случаях центральная предельная теорема обычно остается справедливой, однако на последовательность случайных величин приходится накладывать те или иные условия. Суть этих условий состоит в том, что ни одно слагаемое не должно быть доминирующим, вклад каждого слагаемого в среднее арифметическое должен быть пренебрежимо мал по сравнению с итоговой суммой. Наиболее часто используется теорема Ляпунова.	Центральная предельная теорема (для разнораспределенных слагаемых) - теорема Ляпунова. Пусть X1, X2,., Xn, .- независимые   случайные величины с математическими ожиданиями M(Xi) = mi и дисперсиями D(Xi) = , i = 1, 2,., n,. Пусть при некотором ?>0 у всех рассматриваемых случайных величин существуют центральные моменты порядка 2+? и безгранично убывает "дробь Ляпунова":гдеТогда для любого действительного числа х существует предел   (1)где Ф(х) - функция стандартного нормального распределения.	В случае одинаково распределенных случайных слагаемых и теорема Ляпунова переходит в теорему Линдеберга-Леви. 	История получения центральных предельных теорем для случайных величин растянулась на два века - от первых работ Муавра в 30-х годах 18-го века для необходимых и достаточных условий, полученных Линдебергом и Феллером в 30-х годах 20-го века. 	Теорема Линдеберга-Феллера. Пусть X1, X2,., Xn, .- независимые   случайные величины с математическими ожиданиями M(Xi) = mi и дисперсиями D(Xi) = , i = 1, 2,., n,. Предельное соотношение (1), т.е. центральная предельная теорема, выполнено тогда и только тогда, когда при любом ?>0где Fk(x) обозначает функцию распределения случайной величины Xk.	Доказательства перечисленных в настоящем подразделе центральных предельных теорем для случайных величин можно найти в классическом курсе теории вероятностей [2].	Для прикладной статистики большое значение имеет многомерная центральная предельная теорема. В ней речь идет не о сумме случайных величин, а о сумме случайных векторов.	 Необходимое и достаточное условие многомерной сходимости [3, с.124]. Пусть Fn обозначает совместную функцию распределения k-мерного случайного вектора , n = 1,2,., и F?n - функция распределения линейной комбинации . Необходимое и достаточное условие для сходимости Fn  к некоторой k-мерной функции распределения F состоит в том, что F?n имеет предел для любого вектора ?.	Приведенная теорема ценна тем, что сходимость векторов сводит к сходимости линейных комбинаций их координат, т.е. к сходимости обычных случайных величин, рассмотренных ранее. Однако она не дает возможности непосредственно указать предельное распределение. Это можно сделать с помощью следующей теоремы.	Теорема о многомерной сходимости. Пусть Fn и F?n - те же, что в предыдущей теореме. Пусть F - совместная функция распределения k-мерного случайного вектора . Если функция распределения F?n сходится при росте объема выборки к функции распределения F? для любого вектора ?, где F? - функция распределения линейной комбинации , то Fn сходится к F. 	Здесь сходимость Fn к F означает, что для любого k-мерного вектора  такого, что функция распределения F непрерывна в , числовая последовательность Fn сходится при росте n к числу F. Другими словами, сходимость функций распределения понимается ровно также, как при обсуждении  предельных теорем для случайных величин выше. Приведем многомерный аналог этих теорем.	Многомерная центральная предельная теорема [3]. Рассмотрим независимые одинаково распределенные  k-мерные случайные векторагде штрих обозначает операцию транспонирования вектора. Предположим, что случайные вектора Un имеют моменты первого и второго порядка, т.е. М(Un) = ?, D(Un) = ?,где  ? - вектор математических ожиданий координат случайного вектора, ? - его ковариационная матрица. Введем последовательность средних арифметических случайных векторов:Тогда случайный вектор  имеет асимптотическое k-мерное нормальное распределение , т.е. он асимптотически распределен так же, как k-мерная нормальная величина с нулевым математическим ожиданием, ковариационной ? и плотностьюЗдесь |?| - определитель матрицы ?. Другими словами, распределение случайного вектора  сходится к k-мерному нормальному распределению с нулевым математическим ожиданием и ковариационной матрицей ?.	Напомним, что многомерным нормальным распределением с математическим ожиданием ? и ковариационной матрицей ? называется распределение, имеющее плотность 	Многомерная центральная предельная теорема показывает, что распределения сумм независимых одинаково распределенных случайных векторов при большом числе слагаемых хорошо приближаются с помощью нормальных распределений, имеющих такие же первые два момента (вектор математических ожиданий координат случайного вектора и его корреляционную матрицу), как и исходные вектора. От одинаковой распределенности можно отказаться, но это потребует некоторого усложнения символики. В целом из теоремы о многомерной сходимости вытекает, что многомерный случай ничем принципиально не отличается от одномерного. 	Пример. Пусть X1, . Xn ,.- независимые одинаково распределенные случайные величины. Рассмотрим k-мерные независимые одинаково распределенные случайные вектораИх математическое ожидание - вектор теоретических начальных моментов, а ковариационная матрица составлена из соответствующих центральных моментов. Тогда - вектор выборочных центральных моментов. Многомерная центральная предельная теорема утверждает, что  имеет асимптотически нормальное распределение. Как вытекает из теорем о наследовании сходимости и о линеаризации (см. ниже), из распределения  можно вывести распределения различных функций от выборочных начальных моментов. А поскольку центральные моменты выражаются через начальные моменты, то аналогичное утверждение верно и для них. 1.4.3. Теоремы о наследовании сходимости	Суть проблемы наследования сходимости. Пусть распределения случайных величин Xn при n > ? стремятся к распределению случайной величины Х. При каких функциях f можно утверждать, что распределения случайных величин f(Xn) сходятся к распределению f(X), т.е. наследуется сходимость? 	Хорошо известно, что для непрерывных функций f сходимость наследуется [3]. Однако в прикладной статистике используются различные обобщения этого утверждения. Необходимость обобщений связана с тремя обстоятельствами.	1) Статистические данные могут моделироваться не только случайными величинами, но и случайными векторами, случайными множествами, случайными элементами произвольной природы (т.е. функциями на вероятностном пространстве со значениями в произвольном множестве).	2) Переход к пределу должен рассматриваться не только для случая безграничного возрастания объема выборки, но и в более общих случаях. Например, если в постановке статистической задачи участвуют несколько выборок объемов n(1), n(2), . , n(k), то вполне обычным является предположение о безграничном росте всех этих объемов (что можно описать и как min {n(1), n(2), . , n(k)} > ?). 	3) Функция f не обязательно является непрерывной. Она может иметь разрывы. Кроме того, она может зависеть от параметров, по которым происходит переход к пределу. Например, может зависеть от объемов выборок. Например, в главе 3.1 понадобится рассмотреть функцию f = f(n(1), n(2), . , n(k)).	Расстояние Прохорова и сходимость по направленному множеству. Введем необходимые для дальнейшего изложения понятия.	Расстояние (метрика) Прохорова. Пусть С - некоторое пространство, А - его подмножество, d - метрика в С. Введем понятие ?-окрестности множества А в метрике d:S(A,?) = {x С: d(A,x) < ?}.Таким образом, ?-окрестность множества А - это совокупность всех точек пространства С, отстоящих от А не более чем на положительное число ?. При этом расстояние от точки х до множества А - это точная нижняя грань расстояний от х до точек множества А, т.е. d(A,x) = inf{d(x,y): yA}.	Пусть P1 и P2 - две вероятностные меры на С (т.е. распределения двух случайных элементов со значениями в С). Пусть D12 - множество чисел ? > 0 таких, чтоP1(A) < P2(S(A,?)+?для любого замкнутого подмножества А пространства С. Пусть D21 - множество чисел ? > 0 таких, что P2(A) < P1(S(A,?)+?для любого замкнутого подмножества А пространства С. Расстояние Прохорова L(P1,P2) между вероятностными мерами (его можно рассматривать и как расстояние между случайными элементами с распределениями P1 и P2 соответственно) вводится формулойL(P1,P2) = max (inf D12, inf D21).С помощью метрики Прохорова формализуется понятие сходимости распределений случайных элементов в произвольном пространстве.	Расстояние L(P1,P2) введено академиком РАН Юрием Васильевичем Прохоровым в середине ХХ в. и широко используется в современной теории вероятностей.	Сходимость по направленному множеству [4, с.95-96]. Бинарное отношение > (упорядочение), заданное на множестве В, называется направлением на нем, если В не пусто и 	(а) если m, n и p - такие элементы множества В, что m > n и n > p, то m > p;	(б) m > m для любого m из B;	(в) если m и n принадлежат B, то найдется элемент p из B такой, что p > m и p > n. 	Направленное множество - это пара (В, >), где > - направление на множестве В. Направленностью (или "последовательностью по направленному множеству") называется пара (f, >), где f - функция, > - направление на ее области определения. Пусть f: B > Y, где Y - топологическое пространство. Направленность (f, >) сходится в топологическом пространстве Y к точке y0, если для любой окрестности U точки y0 найдется p из B такое, что f(q)U при любом q > p. В таком случае говорят также о сходимости по направленному множеству. 	Пусть В = {(n(1), n(2), . , n(k))} - совокупность векторов, каждый из которых составлен из объемов k выборок. Пусть(n(1), n(2), . , n(k)) > (n1(1), n1(2), . , n1(k))тогда и только тогда, когда n(i) > n1(i) при всех i = 1, 2, ., k. Тогда (В, >) - направленное множество, сходимость по которому эквивалентна сходимости при min {n(1), n(2), . , n(k)} > ?.	Чтобы охватить различные частные случаи, целесообразно предельные теоремы формулировать в терминах сходимости по направленному множеству. Будем писать B = {?}. Пусть запись ?>? обозначает переход к пределу по направленному множеству.	Формулировка проблемы наследования сходимости. Пусть случайные элементы X? со значениями в пространстве С сходятся при ?>? к случайному элементу Х, где через ?>? обозначен переход к пределу по направленному множеству. Сходимость случайных элементов означает, что L(X?, X) > 0 при ?>?, где L - метрика Прохорова в пространстве С. 	Пусть f?: C > Y - некоторые функции. Какие условия надо на них наложить, чтобы из L(X?, X) > 0 вытекало, что L1(f?(X?), f?(X)) > 0 при ?>?, где L1 - метрика Прохорова в пространстве Y? Другими словами, какие условия на функции f?: C > Y гарантируют наследование сходимости? 	В работах [5, 6] найдены необходимые и достаточные условия на функции f?: C > Y, гарантирующие наследование сходимости. Описанию этих условий посвящена оставшаяся часть подраздела. 	Приведем для полноты изложения строгие формулировки математических предположений (в дальнейшем никому, кроме профессиональных математиков, не понадобятся)	Математические предположения. Пусть С и У - полные сепарабельные метрические пространства, Пусть выполнены обычные предположения измеримости: Х? и Х - случайные элементы С, f?(Х?) и  f?(Х) - случайные элементы в У, рассматриваемые ниже подмножества пространств С и У лежат в соответствующих ?-алгебрах измеримых подмножеств, и т.д.	Понадобятся некоторые определения. Разбиение Тn = {C1n, C2n, . , Cnn} пространства С - это такой набор подмножеств Cj, j = 1, 2, . , n, этого пространства, что пересечение любых двух из них пусто, а объединение совпадает с С. Диаметром diam(A) подмножества А множества С называется точная верхняя грань расстояний между элементами А, т.е. diam(A) = sup {d(x,y), xA, yA},где d(x,y) - метрика в пространстве С. Обозначим ?А границу множества А, т.е. совокупность точек х таких, что любая их окрестность U(x) имеет непустое пересечение как с А, так и с C\А. Колебанием ?(f, B) функции f на множестве B называется ?(f, B) = sup {|f(x) - f(y)|, xB, yB}.	Достаточное условие для наследования сходимости. Пусть L(X?,X) > 0 при ? > ?. Пусть существует последовательность Тn разбиений пространства С такая, что Р(Х?А) = 0 для любого А из Тn и, основное условие, для любого ? > 0		(1)при n >? и ?>?, где сумма берется по всем тем А из Тn, для которых колебание функции f? на А больше ?, т.е. ?(f?, А) > ?. Тогда L1(f?(X?), f?(X)) > 0 при ?>?.	Необходимое условие для наследования сходимости. Пусть У - конечномерное линейное пространство, У = Rk. Пусть случайные элементы f?(X) асимптотически ограничены по вероятности при ?>?, т.е. для любого ? > 0 существуют число S(?) и элемент направленного множества ?(?) такие, что Р(||f?(X)||> S(?))<? при ? > ?(?), где ||f?(X)|| - норма (длина) вектора f?(X). Пусть существует последовательность Тn разбиений пространства С такая, что,т.е. последовательность Тn является безгранично измельчающейся. Самое существенное - пусть условие (1) не выполнено для последовательности Тn. Тогда существует последовательность случайных элементов X? такая, что L(X?,X) > 0 при ? > ?, но L1(f?(X?), f?(X)) не сходится к 0 при ? > ?.	Несколько огрубляя, можно сказать, что условие (1) является необходимым и достаточным для наследования сходимости. 	Пример 1. Пусть С и У - конечномерные линейные пространства, функции f? не зависят от ?, т.е. f? ? f, причем функция f ограничена. Тогда условие (1) эквивалентно требованию интегрируемости по Риману-Стилтьесу функции f по мере G(A) = P(XA). В частности, условие (1) выполнено для непрерывной функции f.	В конечномерных пространствах С вместо сходимости L(X?,X) > 0 при ? > ? можно говорить о слабой сходимости функций распределения случайных векторов X? к функции распределения случайного вектора X. Речь идет о "сходимости по распределению", т.е. о сходимости во всех точках непрерывности функции распределения случайного вектора X. В этом случае разбиения могут состоять из многомерных параллелепипедов [5, гл.2]. 	Пример 2. Полученные выше результаты дают обоснование для рассуждений типа следующего (ср., например, утверждения в главе 3.1 ниже). Пусть по двум независимым выборкам объемов m и n соответственно построены статистики Xm и Yn. Пусть известно, что распределения этих статистик сходятся при безграничном росте объемов выборок к стандартному нормальному распределению с математическим ожиданием 0 и дисперсией 1. Пусть a(m, n) и b(m, n) - некоторые коэффициенты. Тогда согласно результатам примера 1 распределение случайной величины Z(m, n) = a(m, n)Xm + b(m, n)Yn сближается с распределением нормально распределенной случайной величины с математическим ожиданием 0 и дисперсией a2(m, n) + b2(m, n). Если же a2(m, n) + b2(m, n) = 1, например,,то распределение Z(m, n) сходится при безграничном росте объемов выборок к стандартному нормальному распределению с математическим ожиданием 0 и дисперсией 1.1.4.4. Метод линеаризации	При разработке методов прикладной статистики часто возникает следующая задача [3, с.338]. Имеется последовательность k-мерных случайных векторов Xn = (X1n, X2n, . , Xkn), n = 1, 2, . , такая, что Xn > a = (a1, a2, . , ak) при n > ?, и последовательность функций fn: Rk > R1. Требуется найти распределение случайной величины fn(Xn). 	Основная идея - рассмотреть главный линейный член функции fn в окрестности точки а. Из математического анализа известно, что ,где остаточный член является бесконечно малой величиной более высокого порядка малости, чем линейный член. Таким образом, произвольная функция может быть заменена на линейную функцию от координат случайного вектора. Эта замена проводится с точностью до бесконечно малых более высокого порядка. Конечно, должны быть выполнены некоторые математические условия регулярности. Например, функции fn должны быть дважды непрерывно дифференцируемы в окрестности точки а. 	Если вектор Xn является асимптотически нормальным с математическим ожиданием а и ковариационной матрицей ?/n, где ? = ||?ij||, причем ?ij = nM(Xi - ai)(Xj - aj), то линейная функция от его координат также асимптотически нормальна. Следовательно, при очевидных условиях регулярности fn(Xn) - асимптотически нормальная случайная величина с математическим ожиданием fn(а) и дисперсией.	Для практического использования асимптотической нормальности fn(Xn) остается заменить неизвестные моменты а и ? на их оценки. Например, если Xn - это среднее арифметическое независимых одинаково распределенных случайных векторов, то а можно заменить на Xn, а ? - на выборочную ковариационную матрицу.	Пример. Пусть Y1, Y2, . , Yn - независимые одинаково распределенные случайные величины с математическим ожиданием а и дисперсией ?2. В качестве Xn (k = 1) рассмотрим выборочное среднее арифметическое .Как известно, в силу закона больших чисел  > а = М(У). Следовательно, для получения распределений функций от выборочного среднего арифметического можно использовать метод линеаризации. В качестве примера рассмотрим fn(y) = f(y) = y2. Тогда.Из этого соотношения следует, что с точностью до бесконечно малых более высокого порядка .Поскольку в соответствии с Центральной Предельной Теоремой выборочное среднее арифметическое является асимптотически нормальной случайной величиной с математическим ожиданием а и дисперсией ?2/n, то квадрат этой статистики является асимптотически нормальной случайной величиной с математическим ожиданием а2 и дисперсией 4а2?2/n. Для практического использования может оказаться полезной замена параметров (асимптотического нормального распределения) на их оценки, а именно, математического ожидания - на , а дисперсии - на , где s2 - выборочная дисперсия. 	Большое внимание (целая глава!) уделено методу линеаризации в классическом учебнике Е.С. Вентцель [7].1.4.5. Принцип инвариантности	Пусть Y1, Y2, . , Yn - независимые одинаково распределенные случайные величины с непрерывной функцией распределения F(x). Многие используемые в прикладной статистике функции от результатов наблюдений выражаются через эмпирическую функцию распределения Fn(x). К ним относятся статистики Колмогорова, Смирнова, омега-квадрат. Отметим, что и другие статистики выражаются через эмпирическую функцию распределения, например:.	Полезным является преобразование Н.В.Смирнова t = F(x). Тогда независимые случайные величины Zj = F(Yj), j = 1, 2, . , n, имеют равномерное распределение на отрезке [0; 1]. Рассмотрим построенную по ним эмпирическую функцию распределения Fn(t), 0 < t < 1. Эмпирическим процессом называется случайный процесс.	Рассмотрим критерии проверки согласия функции распределения выборки с фиксированной функцией распределения F(x). Статистика критерия Колмогорова записывается в видестатистика критерия Смирнова - этоа статистика критерия омега-квадрат (Крамера-Мизеса-Смирнова) имеет вид.	Случайный процесс ?n(t) имеет нулевое математическое ожидание и ковариационную функцию М?n(s)?n(t) = min (s,t) - st. Рассмотрим гауссовский случайный процесс ?(t) с такими же математическим ожиданием и ковариационной функцией. Он называется броуновским мостом. (Напомним, что гауссовским процесс именуется потому, что вектор (?(t1), ?(t2), . , ?(tk)) имеет многомерное нормальное распределение при любых наборах моментов времени t1, t2, . , tk.) 	Пусть f - функционал, определенный на множестве возможных траекторий случайных процессов. Принцип инвариантности [1] состоит в том, что последовательность распределений случайных величин f(?n) сходится при n > ? к распределению случайной величины f(?). Сходимость по распределению обозначим символом =>. Тогда принцип инвариантности кратко записывается так: f(?n) => f(?). В частности, согласно принципу инвариантности статистика Колмогорова и статистика омега квадрат сходятся по распределению к распределениям соответствующих функционалов от случайного процесса ?: => ,  => .Таким образом, от проблем прикладной статистики сделан переход к теории случайных процессов. Методами этой теории найдены распределения случайных величин ,  .Принцип инвариантности - инструмент получения предельных распределений функций от результатов наблюдений, используемых в прикладной статистике.	Обоснование принципу инвариантности может быть дано на основе теории сходимости вероятностных мер в функциональных пространствах [8]. Более простой подход, позволяющий к тому же получать необходимые и достаточные условия в предельной теории статистик интегрального типа (принцип инвариантности к ним нельзя применить), рассмотрен в главе 2.3. 	Почему "принцип инвариантности" так назван? Обратим внимание, что предельные распределения рассматриваемых статистик не зависят от их функции распределения F(x). Другими словами, предельное распределение инвариантно относительно выбора F(x). 	В более широком смысле термин "принцип инвариантности" применяют тогда, когда предельное распределение не зависит от тех или иных характеристик исходных распределений [1]. В этом смысле наиболее известный "принцип инвариантности" - это Центральная Предельная Теорема, поскольку предельное стандартное нормальное распределение - одно и то же для всех возможных распределений независимых одинаково распределенных слагаемых (лишь бы слагаемые имели конечные математическое ожидание и дисперсию).1.4.6. Нечеткие множества как проекции случайных множеств	Нечеткость и случайность. С самого начала появления современной теории нечеткости в 1960-е годы (см. главу 1.1) началось обсуждение ее взаимоотношений с теорией вероятностей. Дело в том, что функция принадлежности нечеткого множества напоминает распределение вероятностей. Отличие только в том, что сумма вероятностей по всем возможным значениям случайной величины (или интеграл, если множество возможных значений несчетно) всегда равна 1, а сумма S значений функции принадлежности (в непрерывном случае - интеграл от функции принадлежности) может быть любым неотрицательным числом. Возникает искушение пронормировать функцию принадлежности, т.е. разделить все ее значения на S (при S 0), чтобы свести ее к распределению вероятностей (или к плотности вероятности). Однако специалисты по нечеткости справедливо возражают против такого "примитивного" сведения, поскольку оно проводится отдельно для каждой размытости (нечеткого множества), и определения обычных операций над нечеткими множествами с ним согласовать нельзя. Последнее утверждение означает следующее. Пусть указанным образом преобразованы функции принадлежности нечетких множеств А и В. Как при этом преобразуются функции принадлежности ? Установить это невозможно в принципе. Последнее утверждение становится совершенно ясным после рассмотрения нескольких примеров пар нечетких множеств с одними и теми же суммами значений функций принадлежности, но различными результатами теоретико-множественных операций над ними. Причем и суммы значений соответствующих функций принадлежности для этих результатов теоретико-множественных операций, например, для пересечений множеств, также различны. 	В работах по нечетким множествам время от времени утверждается, что теория нечеткости является самостоятельным разделом прикладной математики и не имеет отношения к теории вероятностей (см., например, обзор литературы в монографиях [5,9]). Некоторые авторы, сравнивавшие теорию нечеткости и теорию вероятностей, подчеркивали различие между этими областями теоретических и прикладных исследований. Обычно сравнивают аксиоматику и сравнивают области приложений. Надо сразу отметить, что аргументы при втором типе сравнений не имеют доказательной силы, поскольку по поводу границ применимости даже такой давно выделившейся научной области, как вероятностно-статистические методы, имеются различные мнения. Напомним, что итог рассуждений одного из наиболее известных французских математиков Анри Лебега по поводу границ применимости арифметики таков: "Арифметика применима тогда, когда она применима" (см. его монографию [10, с.21-22]).	При сравнении различных аксиоматик теории нечеткости и теории вероятностей нетрудно увидеть, что списки аксиом различаются. Из этого, однако, отнюдь не следует, что между указанными теориями нельзя установить связь, типа известного сведения евклидовой геометрии на плоскости к арифметике (точнее к теории числовой системы  - см., например, монографию [11]). Напомним, что эти  две аксиоматики - евклидовой геометрии и арифметики - на первый взгляд весьма сильно различаются. 	Можно понять желание энтузиастов теории нечеткости подчеркнуть принципиальную новизну своего научного аппарата. Однако не менее важно установить связи этого подхода с ранее известными.	Проекция случайного множества. Как оказалось, теория нечетких множеств тесно связана с теорией случайных множеств. Еще в 1975 г. в работе [12] было показано, что нечеткие множества естественно рассматривать как "проекции" случайных множеств. Рассмотрим этот метод сведения теории нечетких множеств к теории случайных множеств. 	Определение 1. Пусть  - случайное подмножество конечного множества У. Нечеткое множество В, определенное на У, называется проекцией А и обозначается Proj A, если 	(1)при всех 	Очевидно, каждому случайному множеству А можно поставить в соответствие с помощью формулы (1) нечеткое множество В = Proj A. Оказывается, верно и обратное.	Теорема 1. Для любого нечеткого подмножества В конечного множества У существует случайное подмножество А множества У такое, что В = Proj A. 	Доказательство. Достаточно задать распределение случайного множества А. Пусть У1 -  носитель В (см. определение 1 в подразделе 1.1.4 выше). Без ограничения общности можно считать, что  при некотором m и элементы У1 занумерованы в таком порядке, чтоВведем множестваПоложимДля всех остальных подмножеств Х множества У положим Р(А=Х)=0. Поскольку элемент yt входит во множества Y(1), Y(2),., Y(t) и не входит во множества Y(t+1),., Y(m), то из приведенных выше формул следует, что Если  то, очевидно,  Теорема 1 доказана. 	Распределение случайного множества с независимыми элементами, как следует из рассмотрений главы 8 монографии [13], полностью определяется его проекцией. Для конечного случайного множества общего вида это не так. Для уточнения сказанного понадобится следующая теорема.	Теорема 2. Для случайного подмножества А множества У из конечного числа элементов наборы чисел  и  выражаются один через другой. 	Доказательство. Второй набор выражается через первый следующим образом:Элементы первого набора выразить через второй можно с помощью формулы включений и исключений из формальной логики, в соответствии с которойВ этой формуле в первой сумме у пробегает все элементы множества Y\X, во второй сумме переменные суммирования у1 и у2 не совпадают и также пробегают это множество, и т.д. Ссылка на формулу включений и исключений завершает доказательство теоремы 2. 	В соответствии с теоремой 2 случайное множество А можно характеризовать не только распределением, но и набором чисел  В этом наборе  а других связей типа равенств нет. В этот набор входят числа  следовательно, фиксация проекции случайного множества эквивалентна фиксации k = Card(Y) параметров из (2k-1) параметров, задающих распределение случайного множества А в общем случае.	Будет полезна следующая теорема.	Теорема 3. Если Proj A = B, то 	Для доказательства достаточно воспользоваться тождеством из теории случайных множеств , формулой для вероятности накрытия , определением отрицания нечеткого множества и тем, что сумма всех P(A=X) равна 1. При этом под формулой для вероятности накрытия имеется в виду следующее утверждение: чтобы найти вероятность накрытия фиксированного элемента q случайным подмножеством S конечного множества Q, достаточно вычислитьгде суммирование идет по всем подмножествам A множества Q, содержащим q.	Пересечения и произведения нечетких и случайных множеств. Выясним, как операции над случайными множествами соотносятся с операциями над их проекциями. В силу законов де Моргана (теорема 1 в подразделе 1.1.4) и теоремы 3 достаточно рассмотреть операцию пересечения случайных множеств.	Теорема 4. Если случайные подмножества А1 и А2 конечного множества У независимы, то нечеткое множество  является произведением нечетких множеств Proj A1 и Proj A2 .	Доказательство. Надо показать, что для любого 	(2)По формуле для вероятности накрытия точки случайным множеством (см. выше)	(3)Легко проверить, что распределение пересечения случайных множеств  можно выразить через их совместное распределение следующим образом:	(4)Из соотношений (3) и (4) следует, что вероятность накрытия для пересечения случайных множеств можно представить в виде двойной суммы	(5)Заметим теперь, что правую часть формулы (5) можно переписать следующим образом:	(6)Действительно, формула (5) отличается от формулы (6) лишь тем, что в ней сгруппированы члены, в которых пересечение переменных суммирования  принимает постоянное значение. Воспользовавшись определением независимости случайных множеств и правилом перемножения сумм, получаем, что из (5) и (6) вытекает равенствоДля завершения доказательства теоремы 4 достаточно еще раз сослаться на формулу для вероятности накрытия точки случайным множеством.	Определение 2. Носителем случайного множества С называется совокупность всех тех элементов  для которых 	Теорема 5. Равенство верно тогда и только тогда, когда пересечение носителей случайных множеств  и  пусто.	Доказательство. Необходимо выяснить условия, при которых	(7)ПоложимТогда равенство (7) сводится к условию	(8)Ясно, что соотношение (8) выполнено тогда и только тогда, когда р2р3 = 0 при всех  т.е. не существует ни одного элемента  такого, что одновременно  и , а это эквивалентно пустоте пересечения носителей случайных множеств  и . Теорема 5 доказана.	Сведение последовательности операций над нечеткими множествами к последовательности операций над случайными множествами. Выше получены некоторые связи между нечеткими и случайными множествами. Стоит отметить, что изучение этих связей в работе [12] началось с введения случайных множеств с целью развития и обобщения аппарата нечетких множеств Л. Заде. Дело в том, что математический аппарат нечетких множеств не позволяет в должной мере учитывать различные варианты зависимости между понятиями (объектами), моделируемыми с его помощью, не является достаточно гибким. Так, для описания "общей части" двух нечетких множеств есть лишь две операции - произведение и пересечение. Если применяется первая из них, то фактически предполагается, что множества ведут себя как проекции независимых случайных множеств (см. выше теорему 4). Операция пересечения также накладывает вполне определенные ограничения на вид зависимости между множествами (см. выше теорему 5), причем в этом случае найдены даже необходимые и достаточные условия. Желательно иметь более широкие возможности для моделирования зависимости между множествами (понятиями, объектами). Использование математического аппарата случайных множеств предоставляет такие возможности.	Цель сведения теории нечетких множеств к теории случайных множеств состоит в том, чтобы за любой конструкцией из нечетких множеств увидеть конструкцию из случайных множеств, определяющую свойства первой, аналогично тому, как за плотностью распределения вероятностей мы видим случайную величину. Рассмотрим результаты по сведению алгебры нечетких множеств к алгебре случайных множеств.	Определение 3. Вероятностное пространство {?, G, P} назовем делимым, если для любого измеримого множества ХG и любого положительного числа , меньшего Р(Х), можно указать измеримое множество  такое, что 	Пример. Пусть  - единичный куб конечномерного линейного пространства, G есть сигма-алгебра борелевских множеств, а P - мера Лебега. Тогда {?, G, P} - делимое вероятностное пространство. Таким образом, делимое вероятностное пространство - это не экзотика. Обычный куб является примером такого пространства. 	Доказательство сформулированного в примере утверждения проводится стандартными математическими приемами. Они основаны на том, что измеримое множество можно сколь угодно точно приблизить открытыми множествами, последние представляются в виде суммы не более чем счетного числа открытых шаров, а для шаров делимость проверяется непосредственно (от шара Х тело объема  отделяется соответствующей плоскостью). 	Теорема 6. Пусть даны случайное множество А на делимом вероятностном пространстве {?, G, P} со значениями во множестве всех подмножеств множества У из конечного числа элементов, и нечеткое множество D на У. Тогда существуют случайные множества С1, С2, С3, С4  на том же вероятностном пространстве такие, что где B = Proj A.	Доказательство. В силу справедливости законов де Моргана для нечетких (см. теорему 1 в подразделе 1.1.4 выше) и для случайных множеств, а также теоремы 3 выше (об отрицаниях) достаточно доказать существование случайных множеств С1 и С2. Рассмотрим распределение вероятностей во множестве всех подмножеств множества У, соответствующее случайному множеству С такому, что Proj C = D (оно существует в силу теоремы 1). Построим случайное множество С2 с указанным распределением, независимое от А. Тогда  по теореме 4.Перейдем к построению случайного множества С1. По теореме 7 необходимо и достаточно определить случайное множество  так, чтобы Proj C1 = D и пересечение носителей случайных множеств  и  было пусто, т.е. для  идля .	Построим , исходя из заданного случайного множества  Пусть  Исключим элемент у1 из для стольких элементарных событий , чтобы для полученного случайного множества  было справедливо равенство(именно здесь используется делимость вероятностного пространства, на котором задано случайное множество ). Для , очевидно,Аналогичным образом последовательно исключаем у из для всех  и добавляем у в для всех , меняя на каждом шагу  только для  так, чтобы(ясно, что при рассмотрении  случайное множество  не меняется). Перебрав все элементы У, получим случайное множество , для которого выполнено требуемое. Теорема 6 доказана.	Основной результат о сведении теории нечетких множеств к теории случайных множеств дается следующей теоремой.	Теорема 7. Пусть  - некоторые нечеткие подмножества множества У из конечного числа элементов. Рассмотрим результаты последовательного выполнения теоретико-множественных операцийгде  - символ одной из следующих теоретико-множественных операций над нечеткими множествами: пересечение, произведение, объединение, сумма (на разных местах могут стоять разные символы). Тогда существуют случайные подмножества  того же множества У такие, что и, кроме того, результаты теоретико-множественных операций связаны аналогичными соотношениямигде знак  означает, что на рассматриваемом месте стоит символ пересечения  случайных множеств, если в определении Bm стоит символ пересечения или символ произведения нечетких множеств, и соответственно символ объединения  случайных множеств, если в Bm стоит символ объединения или символ суммы нечетких множеств.	Комментарий. Поясним содержание теоремы. Например, еслитоКак совместить справедливость дистрибутивного закона для случайных множеств (вытекающего из его справедливости для обычных множеств) с теоремой 2 подраздела 1.1.4 выше, в которой показано, что для нечетких множеств, вообще говоря,  ? Дело в том, что хотя в соответствии с теоремой 7 для любых трех нечетких множеств В1, В2 и В3 можно указать три случайных множества А1, А2 и А3 такие, чтогдено при этом, вообще говоря, и, кроме случаев, указанных в теореме 2 подраздела 1.1.4,	Доказательство теоремы 7 проводится по индукции. При t=1 распределение случайного множества строится с помощью теоремы 1. Затем конструируется само случайное множество А1, определенное на делимом вероятностном пространстве (нетрудно проверить, что на делимом вероятностном пространстве можно построить случайное подмножество конечного множества с любым заданным распределением именно в силу делимости пространства). Далее случайные множества А2, А3, ., At строим по индукции с помощью теоремы 6. Теорема 7 доказана.	Замечание. Проведенное доказательство теоремы 9 проходит и в случае, когда при определении Bm используются отрицания, точнее, кроме Bm ранее введенного вида используются также последовательности результатов теоретико-множественных операций, очередной шаг в которых имеет видА именно, сначала при помощи законов де Моргана (теорема 1 подраздела 1.1.4 выше) проводится преобразование, в результате которого в последовательности Bm остаются только отрицания отдельных подмножеств из совокупности , а затем с помощью теоремы 3 вообще удается избавиться от отрицаний и вернуться к условиям теоремы 7.	Итак, в настоящем подразделе описаны связи между такими объектами нечисловой природы, как нечеткие и случайные множества, установленные в нашей стране в первой половине 1970-х годов. Через несколько лет, а именно, в начале 1980-х годов, близкие подходы стали развиваться и за рубежом. Одна из работ [14] носит примечательное название "Нечеткие множества как классы эквивалентности случайных множеств". В прикладной статистике и эконометрике [13] разработан ряд методов статистического анализа нечетких данных. В том числе методы классификации, регрессии, проверки гипотез о совпадении функций принадлежности по опытным данным и т.д. При этом оказались полезными общие подходы статистики объектов нечисловой природы (см. главу 3.4 ниже). Методологические и прикладные вопросы теории нечеткости обсуждались и в научно-популярной литературе (см., например, статью [15]). 1.4.7. Устойчивость выводов и принцип уравнивания погрешностей	Устойчивость математических моделей. Проблемам познания, в том числе в технических исследованиях, естественно-научных и социально-экономических областях, посвящено огромное количество работ. Однако это не значит, что обо всем в этой области уже все сказано. А о некоторых положениях целесообразно говорить еще и еще раз, пока они ни станут общеизвестными.	В идеале каждую модель порождения и анализа данных следовало бы рассматривать как аксиоматическую теорию. В этом идеальном случае создание и использование модели происходит в соответствии с известной триадой "практика - теория - практика". А именно, сначала вводятся некоторые математические объекты, соответствующие интересующим исследователя реальным объектам, и на основе представлений о свойствах реальных объектов формулируются необходимые для успешного моделирования свойства математических объектов, которые и принимаются в качестве аксиом. Затем аксиоматическая теория развивается как часть математики, вне связи с представлениями о реальных объектах. На заключительном этапе полученные в математической теории результаты интерпретируются содержательно. Получаются утверждения о реальных объектах, являющиеся следствиями тех и только тех их свойств, которые ранее были аксиоматизированы.	После построения математической модели реального явления или процесса встает вопрос об ее адекватности. Иногда ответ на этот вопрос может дать эксперимент. Рассогласование модельных и экспериментальных данных следует интерпретировать как признак неадекватности некоторых из принятых аксиом. Однако для проверки адекватности социально-экономических моделей зачастую невозможно поставить решающий эксперимент в отличие, скажем, от физических моделей. С другой стороны, для одного и того же  явления или процесса, как правило, можно составить много возможных моделей, если угодно, много разновидностей одной базовой модели. Поэтому необходимы какие-то дополнительные условия, которые позволяли бы их множества возможных моделей и эконометрических методов анализа данных выбрать наиболее подходящие. В качестве одного из подобных условий выдвигается требование устойчивости модели и метода анализа данных относительно допустимых отклонений исходных данных и предпосылок модели или условий применимости метода.	Отметим, что в большинстве случаев исследователей и практических работников интересуют не столько сами модели и методы, сколько решения, которые с их помощью принимаются. Ведь модели и методы для того и разрабатываются, чтобы подготавливать решения. Вместе с тем очевидно, что решения, как правило, принимаются в условиях неполноты информации. Так, любые числовые параметры известны лишь с некоторой точностью. Введение в рассмотрение возможных неопределенностей исходных данных требует каких-то заключений относительно устойчивости принимаемых решений по отношению к этим допустимым неопределенностям.	Введем основные понятия согласно монографии [5]. Будем считать, что имеются исходные данные, на основе которых принимаются решения. Способ переработки (отображения) исходных данных в решение назовем моделью. Таким образом, с общей точки зрения модель - это функция, переводящая исходные данные в решение, т.е. способ перехода значения не имеет. Очевидно, любая рекомендуемая для практического использования модель должна быть исследована на устойчивость относительно допустимых отклонений исходных данных. Укажем некоторые возможные применения результатов подобного исследования:	- заказчик научно-исследовательской работы получает представление о точности предлагаемого решения;	- удается выбрать из многих моделей наиболее адекватную;	- по известной точности определения отдельных параметров модели удается указать необходимую точность нахождения остальных параметров;	- переход к случаю "общего положения" позволяет получать более сильные с математической точки зрения результаты.	Примеры. По каждому из четырех перечисленных возможных применений в [5, 13] приведены различные примеры. В прикладной статистике точность предлагаемого решения связана с разбросом исходных данных и с объемом выборки. Выбору наиболее адекватной модели посвящены многие рассмотрения в главах 3.1 и 3.2, связанные с обсуждением моделей однородности и регрессии. Использование рационального объема выборки в статистике интервальных данных (глава 3.5) исходит из принципа уравнивания погрешностей. Этот принцип основан на том, что по известной точности определения отдельных параметров модели удается указать необходимую точность нахождения остальных параметров. Другим примером применения принципа уравнивания погрешностей является нахождение необходимой точности оценивания параметров в моделях логистики, рассмотренных в главе 5 монографии [5]. Наконец, переходом к случаю "общего положения" в прикладной статистике является, в частности, переход к непараметрическим методам, необходимый из-за невозможности обосновать принадлежность результатов наблюдений к тем или иным параметрическим семействам.	Специалисты по математическому моделированию и теории управления считают устойчивость одной из важных характеристик технических, социально-экономических, медицинских и иных моделей. Достаточно глубокие исследования ведутся по ряду направлений.	Первоначальное изучение влияния малого изменения одного параметра обычно называют анализом чувствительности. Оно описывается значением частной производной. Если модель задается дифференцируемой функцией, то итог анализа чувствительности - вектор значений частных производных в анализируемой точке.Теория устойчивости решений дифференциальных уравнений развивается по крайней мере с XIX в. [16]. Выработаны соответствующие понятия - устойчивость по Ляпунову, корректность, доказаны глубокие теоремы. Для решения некорректных задач академиком АН СССР А.Н. Тихоновым в начале 1960-х годов был предложен метод регуляризации. Модели явлений и процессов, выражаемые с помощью дифференциальных уравнений, могут быть исследованы на устойчивость путем применения хорошо разработанного математического аппарата. 	Вопросы устойчивости изучались практически во всех направлениях прикладных математических методов - и в математическом программировании, и в теории массового обслуживания (теории очередей), и в эколого-экономических моделях, и в различных областях эконометрики. 	Общая схема устойчивости. Прежде чем переходить к конкретным постановкам, обсудим "общую схему  устойчивости", дающую понятийную базу для обсуждения проблем устойчивости в различных предметных областях.	Определение 1. Общей схемой устойчивости называется объект 	Здесь - множество, интерпретируемое как пространство исходных данных; - множество, называемое пространством решений. Однозначное отображение  называется моделью. Об этих трех составляющих общей схемы устойчивости уже шла речь выше. 	Оставшиеся два понятия нужны для уточнения понятий близости в пространстве исходных данных и пространстве решений. Подобные уточнения могут быть сделаны разными способами. Самое "слабое" уточнение - на языке топологических пространств. Тогда возможны качественные выводы (сходится - не сходится), но не количественные расчеты. Самое "сильное" уточнение - на языке метрических пространств. Промежуточный вариант - используются показатели различия (отличаются от метрик тем, что не обязательно выполняются неравенства треугольника) или вводимые ниже понятия.	Пусть d -показатель устойчивости, т.е. неотрицательная функция, определенная на подмножествах У множества  и такая, что из  вытекает  Часто показатель устойчивости d(Y) определяется с помощью метрики, псевдометрики или показателя различия (меры близости)  как диаметр множества У, т.е. Таким образом, говоря попросту, в пространстве решений с помощью показателя устойчивости вокруг образа исходных данных может быть сформирована система окрестностей. Но сначала надо такую систему сформировать в пространстве исходных данных.	Пусть  - совокупность допустимых отклонений. Т.е. система подмножеств множества  такая, что каждому элементу множества исходных данных  и каждому значению параметра  из некоторого множества параметров  соответствует подмножество  множества исходных данных. Оно называется множеством допустимых отклонений в точке х при значении параметра, равном . Наглядно можно представить себе, что вокруг точки х взята окрестность радиуса . 	Определение 2. Показателем устойчивости в точке х при значении параметра, равном , называется число	Другими словами, это - диаметр образа множества допустимых колебаний при рассматриваемом в качестве модели отображении. Очевидно, что этот показатель устойчивости зависит как от исходных данных, так и от диаметра множества возможных отклонений в исходном пространстве. Для непрерывных функций показатель устойчивости обычно называется модулем непрерывности. 	Естественно посмотреть, насколько сузится образ окрестности возможных отклонений при максимально возможном сужении этой окрестности. 	Определение 3. Абсолютным показателем устойчивости в точке х  называется число	Если функция f непрерывна, а окрестности - именно те, о которых идет речь в математическом анализе, то максимальное сужение означает сужение к точке и абсолютный показатель устойчивости равен 0. Но в теории измерений и статистике интервальных данных мы сталкиваемся с совсем иными ситуациями. В теории измерений окрестностью исходных данных являются все те вектора, что получаются из исходного путем преобразования координат с помощью допустимого преобразования шкалы, а допустимое преобразование шкалы берется из соответствующей группы допустимых преобразований. В статистике интервальных данных под окрестностью исходных данных естественно понимать - при описании выборки - куб с ребрами  и центром в исходном векторе. И в том, и в другом случае максимальное сужение не означает сужение к точке.	Естественным является желание ввести характеристики устойчивости на всем пространстве. Не вдаваясь в математические тонкости (см. о них монографию [5]), рассмотрим меру  на пространстве  такую, что мера всего пространства равна 1 (т.е. 	Определение 4. Абсолютным показателем устойчивости на пространстве исходных данных  по мере  называется число	Здесь имеется в виду интеграл Лебега. Интегрирование проводится по (абстрактному) пространству исходных данных  по мере . Естественно, должны быть выполнены некоторые внутриматематические условия. Читателю, незнакомому с интегрированием по Лебегу, достаточно мысленно заменить в предыдущей формуле интеграл на сумму (а пространство  считать конечным, хотя и состоящим из большого числа элементов). 	Определение 5. Максимальным абсолютным показателем устойчивости называется	Легко видеть, что  где супремум берется по всем описанным выше мерам. 	Итак, построена иерархия показателей устойчивости  математических моделей реальных явлений и процессов. Она с успехом использовалась в различных исследованиях, подробно развивалась, в частности, в монографии [5]. Приведем еще одно полезное определение.	Определение 6. Модель f называется абсолютно -устойчивой, если  где  - максимальный абсолютный показатель устойчивости.	Пример. Если показатель устойчивости формируется с помощью метрики , совокупность допустимых отклонений  - это совокупность всех окрестностей всех точек пространства исходных данных , то 0-устойчивость модели f эквивалентна непрерывности модели f на множестве .	Основная проблема в общей схеме устойчивости - проверка -устойчивости данной модели f относительно данной системы допустимых отклонений .	Часто оказываются полезными следующие два обобщения основной проблемы. 	Проблема А (характеризации устойчивых моделей). Даны пространство исходных данных , пространство решений , показатель устойчивости d, совокупность допустимых отклонений  и неотрицательное число . Описать достаточно широкий класс -устойчивых моделей f. Или: найти все -устойчивые модели среди моделей, обладающих данными свойствами, т.е. входящих в данное множество моделей. 	Проблема Б (характеризации систем допустимых отклонений). Даны пространство исходных данных , пространство решений , показатель устойчивости d, модель f и неотрицательное число . Описать достаточно широкий класс систем допустимых отклонений , относительно которых модель f является -устойчивой. Или: найти все такие системы допустимых отклонений  среди совокупностей допустимых отклонений, обладающих данными свойствами, т.е. входящих в данное множество совокупностей допустимых отклонений.	Ясно, что проблемы А и Б можно рассматривать не только для показателя устойчивости , но и для других только что введенных показателей устойчивости, а именно, 	Язык общей схемы устойчивости позволяет описывать конкретные задачи специализированных теорий устойчивости в различных областях исследований, выделять в основные элементы в них, ставить проблемы типа А и Б. В частности, на этом языке легко формулируются задачи теории устойчивости решений дифференциальных уравнений, теории робастности статистических процедур (см. главу 2.2.), проблемы адекватности теории измерений, достигаемой точности расчетов в статистике интервальных данных   и в логистике (см. монографию [5]), и т.д. 	Для примера рассмотрим определение устойчивости по Ляпунову решения  нормальной автономной системы дифференциальных уравнений  с начальными условиями  Здесь пространство исходных данных  - конечномерное евклидово пространство, множество допустимых отклонений  окрестность радиуса  точки , пространство решений - множество функций на луче  с метрикой Модель f - отображение, переводящее начальные условия х в решение системы дифференциальных уравнений с этими начальными условиями  	В терминах общей схемы устойчивости положение равновесия а называется устойчивым по Ляпунову, если  Для формулировки определения асимптотической устойчивости по Ляпунову надо ввести в пространстве решений  псевдометрику Положение равновесия а называется асимптотически устойчивым, если  для некоторого  где показатель устойчивости  рассчитан с использованием  псевдометрики . 	Таким образом, общая схема устойчивости естественным образом включает в себя классические понятия теории устойчивости по Ляпунову. Вместе с тем стоит отметить, что эта схема дает общий подход к различным проблемам устойчивости. Она дает систему понятий, которые в каждом конкретном случае должны приспосабливаться к решаемой задаче.	До настоящего момента для определенности речь шла о допустимых отклонениях в пространстве исходных данных. Часто оказывается необходимым говорить и об отклонениях от предпосылок модели. С чисто формальной точки зрения для этого достаточно расширить понятие "исходные данные" до пары (x, f), т.е. включив "прежнюю" модель в качестве второго элемента пары. Все остальные определения остаются без изменения. Теперь отклонения в пространстве решений вызываются не только отклонениями в исходных данных x, но и отклонениями от предпосылок модели, т.е. отклонениями f. Это соображение нам понадобится в подразделе 2.2.4, посвященном робастности статистических процедур. 	Устойчивость по отношению к объему выборки. Различные асимптотические постановки в прикладной статистике также естественно рассматривать как задачи устойчивости. Если при безграничном возрастании объема выборки некоторая величина стремится к пределу, то в терминах общей схемы устойчивости это означает, что она 0-устойчива в соответствующей псевдометрике (см. выше обсуждение асимптотической устойчивости по Ляпунову). С содержательной точки зрения употребление термина "устойчивость" в такой ситуации представляется вполне оправданным, поскольку рассматриваемая величина мало меняется при изменении объема выборки.	Рассмотрим проблему и методы оценки близости предельных распределений статистик и распределений, соответствующих конечным объемам выборок. При каких объемах выборок уже можно пользоваться предельными распределениями? Каков точный смысл термина "можно" в предыдущей фразе? Основное внимание уделяется переходу от точных формул допредельных распределений к пределу и применению метода статистических испытаний (Монте-Карло). 	Начнем с обсуждения взаимоотношений асимптотической математической статистики и практики анализа статистических данных. Как обычно подходят к обработке реальных данных в конкретной задаче? Первым делом строят статистическую модель. Если хотят перенести выводы с совокупности результатов наблюдений на более широкую совокупность, например, предсказать что-либо, то рассматривают, как правило, вероятностно-статистическую модель. Например, традиционную модель выборки, в которой результаты наблюдений - реализации независимых (в совокупности) одинаково распределенных случайных величин. Очевидно, любая модель лишь приближенно соответствует реальности. В частности, естественно ожидать, что распределения результатов наблюдений несколько отличаются друг от друга, а сами результаты связаны между собой, хотя и слабо.	Итак, первый этап - переход от реальной ситуации к математической модели. Далее - неожиданность: на настоящем этапе своего развития математическая теория статистики зачастую не позволяет провести необходимые исследования для имеющихся объемов выборок. Более того, отдельные математики пытаются оправдать свой отрыв от практики соображениями о структуре этой теории, на первый взгляд убедительными. Неосторожная давняя фраза Б.В. Гнеденко и А.Н.Колмогорова: "Познавательная ценность теории вероятностей раскрывается только предельными теоремами" (см. классическую монографию [17], одну из наиболее ценных математических книг ХХ в.) взята на вооружение и более близкими к нам по времени авторами. Так, И.А. Ибрагимов и Р.З. Хасьминский пишут: "Решение неасимптотических задач оценивания, хотя и весьма важное само по себе, как правило, не может являться объектом достаточно общей математической теории. Более того, соответствующее решение часто зависит от конкретного типа распределения, объема выборки и т.д. Так, теория малых выборок из нормального закона будет отличаться от теории малых выборок из закона Пуассона" (см. напичканную формулами монографию [18, с.7]). 	Согласно цитированным и подобным им авторам, основное содержание математической теории статистики - предельные теоремы, полученные в предположении, что объемы рассматриваемых выборок стремятся к бесконечности. Эти теоремы опираются на предельные соотношения теории вероятностей, типа Закона Больших Чисел и Центральной Предельной Теоремы. Ясно, что сами по себе подобные утверждения относятся к математике, т.е. к сфере чистой абстракции, и не могут быть непосредственно применены для анализа реальных данных. Их практическое использование, о котором "чистые" математики предпочитают не думать, опирается на важное предположение: "При данном объеме выборки достаточно точными являются асимптотические формулы".	Конечно, в качестве первого приближения представляется естественным воспользоваться асимптотическими формулами, не тратя сил на анализ их точности. Но это - лишь начало долгой цепи исследований. Как же обычно преодолевают разрыв между результатами асимптотической математической статистики и потребностями практики статистического анализа данных? Какие "подводные камни" подстерегают на этом пути?  	Точные формулы и асимптотика. Начнем с наиболее продвинутой в математическом плане ситуации, когда для статистики известны как предельное распределение, так и распределения при конечных объемах выборки. 	Примером является двухвыборочная односторонняя статистика Н.В.Смирнова. Рассмотрим две независимые выборки объемов m и n из непрерывных функций распределения F(x) и G(x) соответственно. Для проверки гипотезы однородности двух выборок (ср. главу 3.1)H0: F(x) = G(x) для всех действительных чисел xв 1939 г. Н.В. Смирнов в статье [19] предложил использовать статистикуD+(m,n) = sup (Fm(x) - Gn(x)) ,где Fm(x) - эмпирическая функция распределения, построенная по первой выборке, Gn(x) - эмпирическая функция распределения, построенная по второй выборке, супремум берется по всем действительным числам x. Для обсуждения проблемы соотношения точных и предельных результатов ограничимся случаем равных объемов выборок, т.е. m = n. Положим В цитированной статье [19] Н.В. Смирнов установил, что при безграничном возрастании объема выборки n вероятность H(n, t) стремится к exp(- t 2). 	В работе [20] 1951 г. Б.В. Гнеденко и В.С. Королюк показали, что при целом  (именно при таких t вероятность H(n, t) как функция t имеет скачки, поскольку статистика Смирнова D+(n,n) кратна 1/n) рассматриваемая вероятность H(n, t) выражается через биномиальные коэффициенты, а именно,		(1)	К сожалению, непосредственные расчеты по формуле (1) возможны лишь при сравнительно небольших объемах выборок, поскольку величина n! (n-факториал) уже при n=100 имеет более 200 цифр и не может быть без преобразований использована в вычислениях. Следовательно, наличие точной формулы для интересующей нас вероятности не снимает необходимости использования предельного распределения и изучения точности приближения с его помощью.	Широко известная формула Стирлинга для гамма-функции и, в частности, для факториалов позволяет преобразовать последнее выражение в асимптотическое разложение. Т.е. построить бесконечный степенной ряд (по степеням n) такой, что каждая следующая частичная сумма дает все более точное приближение для интересующей нас вероятности H(x, t). Это и было сделано в работе А.А. Боровкова 1962 г. Большое количество подобных разложений для различных статистических задач приведено в работах В.М. Калинина и О.В. Шалаевского конца 1960-х - начала 1970-х годов. (Интересно отметить, что асимптотические разложения в ряде случаев расходятся, т.е. остаточные члены имеют нетривиальную природу.) 	Затем в работах конца семидесятых годов была сделана попытка теоретически оценить остаточный член второго порядка. Итоги подведены в монографии [5, :2.2, с.37-45]. Справедливо равенствоH(n, t) =  exp ( - t 2).(1 + f(t)/n + g(n,t)/ n2 ),гдеf(t) = t2 (1/2 - t2/6).Целью последних из названных работ было получение равномерных по n, t оценок остаточного члена второго порядка g(n,t) сверху и снизу в области, задаваемой условиями 		(2)где  - некоторые параметры. С помощью длинных цепочек оценок остаточных членов в формулах, получаемых при преобразовании формулы (1) к предельному виду, сформулированная выше цель была достигнута. Для различных наборов параметров  получены равномерные по n, t оценки (сверху и снизу) остаточного члена второго порядка g(n,t) в области (2). Так, например, при А = 0,5, t max = 1,73, n0 = 8 нижняя граница равна (- 0,71), а верхняя есть 2,65.	Основными недостатками такого подхода являются, во первых, зависимость оценок от параметров , задающих границы областей, во-вторых, завышение оценок, иногда в сотни раз, обусловленное желанием получить равномерные оценки по области (оценкой реальной погрешности в конкретной точке является значение следующего члена асимптотического разложения).	Поэтому при составлении рассчитанной на практическое использование методики [21] проверки однородности двух выборок с помощью статистики Смирнова было решено перейти на несколько другую методологию (назовем ее "методологией заданной точности"), которую кратко можно описать следующим образом.	1) выбирается достаточно малое положительное число р, например р = 0,05 или р = 0,20;	2) приводятся точные значения H(n, t) для всех значений n таких, что |H(n, t) - exp( - t2)| > p exp( - t2);	3) если же последнее неравенство не выполнено, то используется вместо H(n, t) предельное значение exp(-t2).	Таким образом, принятая в методике [21] методология предполагает интенсивное использование вычислительной техники. Результатами расчетов являются граничные значения объемов выборок n(p,t) такие, что при меньших значениях объемов выборок рекомендуется пользоваться точными значениями функции распределения статистики Смирнова, а при больших - предельными. Описывается этот результат таблицей, а не формулой. Отметим, что при построении реальных таблиц не обойтись без выбора того или иного конкретного значения р, задающего объемы таблиц. 	Оценки скорости сходимости. Теоретические оценки скорости сходимости в различных задачах прикладной математической статистики иногда формулируются в весьма абстрактном виде. Так, в 1960-1970-х годах была популярна задача оценки скорости сходимости распределения классической статистики омега-квадрат (Крамера-Мизеса-Смирнова). Для максимума модуля разности допредельной и предельной функций распределения этой статистики различные авторы доказывали, что для любого e>0 существует константа С(e) такая, что он не превосходит С(e)n-w+e. Прогресс состоял в увеличении константы w. Сформулированный выше результат был доказан последовательно для w = 1/10, 1/6, 1/5, 1/4, 1/3, 1/2 и 1 (подробнее история этих исследований рассказана в :2.3 монографии [5]).	Конечно, все эти исследования не могли дать конкретных практических рекомендаций. Однако необходимой исходной точкой является само существование предельного распределения. Представим себе, что некто, не зная, что у распределения Коши нет математического ожидания, моделирует выборочные средние арифметические результатов наблюдений из этого распределения. Ясно, что его попытки оценить скорость сходимости выборочных средних к пределу обречены на провал.	Последовательное улучшение теоретических оценок скорости сходимости дает надежду на быструю реальную сходимость. Действительно, численные расчеты показали, что предельным распределением для статистики омега-квадрат (Крамера-Мизеса-Смирнова) можно пользоваться уже при объеме выборки, равном 4. 	Использование датчиков псевдослучайных чисел. Если же предельное распределение известно, то возникает возможность изучить скорость сходимости численно методом статистических испытаний (Монте-Карло). Однако при этом обычно возникают две проблемы.	Во-первых, откуда известно, что скорость сходимости монотонна? Если при данном объеме выборки различие мало, то будет ли оно мало и при дальнейших объемах? Иногда отклонения допредельного распределения от предельного объясняются довольно сложными причинами. Так, для распределения хи-квадрат они связаны с рядом до сих пор не решенных теоретико-числовых проблем о числе целых точек в эллипсоиде растущего диаметра.  	Во-вторых, с помощью датчиков псевдослучайных чисел получаем допредельные распределения с погрешностью, которая может преуменьшать различие. Поясним мысль аналогией. Растущий сигнал измеряется с погрешностями. Когда можно гарантировать, что его величина наверняка превзошла заданную границу? 	Напомним, что проблема качества датчиков псевдослучайных чисел продолжает оставаться открытой (см. главу 11 в [13]). Для моделирования в пространствах фиксированной размерности датчики псевдослучайных чисел решают поставленные задачи. Но для рассматриваемых здесь задач размерность не фиксирована - мы не знаем, при каком конкретно объеме выборки можно переходить к предельному распределению согласно "методологии заданной точности". 	Нужны дальнейшие работы по изучению качества датчиков псевдослучайных чисел в задачах неопределенной размерности. Поскольку критиков датчиков обычно обвиняют в том, что они сами их не используют, отметим, что мы применяли этот инструментарий при изучении помех, создаваемых электровозами (см. монографию [5]), при изучении статистических критериев проверки однородности двух выборок (см. работу [22]).	А нужна ли вообще асимптотика? В настоящее время развивается актуальное направление прикладной статистики, связанное с интенсивным использованием вычислительной техники для изучения свойств статистических процедур. Как уже отмечалось, математические методы в статистике обычно позволяют получать лишь асимптотические результаты, и для переноса выводов на конечные объемы выборок приходится применять вычислительные методы. В Новосибирском государственном техническом университете разработан и успешно применяется оригинальный подход, основанный на интенсивном использовании современной вычислительной техники. Основная идея такова: в качестве альтернативы асимптотическим методам математической статистики используется анализ результатов статистического моделирования (порядка 2000 испытаний) выборок конкретных объемов (200, 500, 1000). При этом анализ предельных распределений заменяется на анализ распределений соответствующих статистик при указанных объемах выборок.	К достоинствам подхода относится возможность замены теоретических исследований расчетами. Разработанная программная система дает (в принципе) возможность численно изучить свойства любого статистического алгоритма для любого конкретного распределения результатов наблюдений и любого конкретного объема выборки. К недостаткам рассматриваемого подхода относится зависимость от свойств датчиков псевдослучайных чисел, а также - что более важно - неизвестность предельного распределения (и даже самого факта его существования), а потому невозможность обоснованного переноса полученных выводов на объемы выборок, отличные от исследованных. Поэтому с точки зрения теории математической статистики полученные рассматриваемым способом результаты следует рассматривать как правдоподобные (а не доказательные, как в классической математической статистике). 	Кроме того, они принципиально неточные. Даже в наиболее благоприятных условиях отклонение (в метрике "супремум разности") смоделированного распределения, построенного по 2000 испытаниям, от теоретического предельного распределения может достигать 1,358?(1/2000)1/2 = 0,030 (см. главу 1.2). Это означает, в частности, что процентные точки, соответствующие уровням значимости 0,05 и особенно 0,01, могут сильно отличаться от соответствующих процентных точек предельных распределений. Очевидно, следующий этап работ - изучение точности полученных в рассматриваемом подходе выводов, прежде всего приближений и процентных точек.	Однако сразу все не сделаешь. Поэтому новосибирцы совершенно правы, развивая новые компьютерные подходы к давним задачам прикладной статистики. Так, весьма полезными и интересными являются результаты, касающиеся непараметрических критериев согласия и построения оптимального группирования, в частности, при использовании критериев типа хи-квадрат. 	Однако стоит сделать два замечания. В работе [23] сравниваются два плана контроля надежности технических изделий. Оказывается, что при объемах выборки, меньших 150, лучше первый план, а при объемах, больших 150 - второй. Значит, если бы по новосибирскому методу сравнивались эти планы при достаточно большом объеме выборки n=100, то лучшим был бы признан первый план, что неверно - наступит момент (объем выборки), когда лучшим станет второй план.  	Другая относящаяся к делу ассоциация - из весьма содержательной монографии о прикладной математике [24]. Будем суммировать бесконечный ряд с членами zn= 1/n . Поскольку члены его убывают, то обычно используемые алгоритмы остановят вычисления на каком-то шагу. А сумма-то - бесконечна!	Кажется, что компьютер дал универсальную отмычку ко всем проблемам вообще и в области прикладной статистики в частности. Но это только кажется. 	Принцип уравнивания погрешностей состоит в том, что погрешности различной природы должны вносит примерно одинаковый вклад в общую погрешность математической модели. Так, определение рационального объема выборки в статистике интервальных данных основано на уравнивании влияния метрологической и статистической погрешностей. Согласно подходу [5] выбор числа градаций в социологических анкетах целесообразно проводить на основе уравнивания погрешностей квантования и неопределенности в ответах респондентов. В классической модели управления запасами целесообразно уравнять влияние неточностей в определении параметров на отклонение целевой функции от оптимума. Из принципа уравнивания погрешностей следует, что относительные погрешности определения параметров модели должны совпадать. Погрешность, порожденная отклонением спроса от линейного, оценивается по данным об отпуске товаров. Это дает возможность оценить допустимые отклонения для других параметров. В частности, установить, что расхождения между методиками не являются существенными [5]. 	В терминах общей схемы устойчивости рассмотрим для простоты записи случай двух параметров. Пусть ? = [0, ?)?[0,?) и E(x, ?) = E(x, (?, ?)), где ? > 0 и ? > 0 задают точность определения соответствующих параметров, так что  при ?1<?2, ?1<?2. Пусть ? задано, а ? исследователь может выбрать, причем известно, что уменьшение ? связано с увеличением расходов. Как выбирать ?? Представляется естественным "уравнять" отклонения, порожденные различными параметрами, т.е. определить ? из условия ?(x, E(x, (?, ?)) - ?(x, E(x, (?, 0)) ? ?(x, E(x, (0, ?)).	Если затраты и полезный эффект точно известны, то ? можно определить путем решения соответствующей оптимизационной задачи. В противном случае соотношение (3) предлагается использовать в качестве эвристического правила. Литература1. Вероятность и математическая статистика: Энциклопедия / Гл. ред. Ю.В.Прохоров. - М.: Большая Российская энциклопедия, 1999. - 910с.2. Гнеденко Б.В. Курс теории вероятностей: Учебник. 7-е изд., исправл. - М.: Эдиториал УРСС, 2001. 320 с.3. Рао С.Р. Линейные статистические методы и их применения. - М.: Наука, 1968. 548 с.4. Келли Дж. Общая топология. - М.: Наука, 1968. - 384 с.5. Орлов А.И. Устойчивость в социально-экономических моделях. - М.: Наука, 1979. - 296 с.6. Орлов А.И. Асимптотическое поведение статистик интегрального типа. - В сб.: Вероятностные процессы и их приложения. Межвузовский сборник. - М.: МИЭМ, 1989. С.118-123.7. Вентцель Е.С. Теория вероятностей. - М.: Наука, 1964.- 576 с.8. Биллингсли П. Сходимость вероятностных мер. - М.: Наука, 1977. - 352 с.9. Орлов А.И. Задачи оптимизации и нечеткие переменные. - М.: Знание, 1980. - 64 с.10. Лебег А. Об измерении величин. - М.: Учпедгиз, 1960. - 204 с.11. Ефимов Н.В. Высшая геометрия. - М.: ГИФМЛ, 1961. - 580 с.12. Орлов А.И. Основания теории нечетких множеств (обобщение аппарата Заде). Случайные толерантности. - В сб.: Алгоритмы многомерного статистического анализа и их применения. - М.: Изд-во ЦЭМИ АН СССР, 1975. - С.169-175.13. Орлов А.И. Эконометрика. Учебник для вузов. Изд. 2-е, исправленное и дополненное. - М.: Изд-во "Экзамен", 2003. - 576 с.14. Goodman I.R. Fuzzy sets as equivalence classes of random sets // Fuzzy Set and Possibility Theory: Recent Developments. - New York-Oxford-Toronto-Sydney-Paris-Frankfurt, Pergamon Press, 1982. - P.327-343. (Перевод на русский язык: Гудмэн И. Нечеткие множества как классы эквивалентности случайных множеств. - В сб.: Нечеткие множества и теория возможностей. Последние достижения. - М.: Радио и связь, 1986. - С. 241-264.)15. Орлов А.И. Математика нечеткости. - Журнал "Наука и жизнь". 1982. No.7. С.60-67.16. Поляк Б.Т., Щербаков П.С. Робастная устойчивость и управление. - М.: Наука, 2002. - 303 с.17. Гнеденко Б.В., Колмогоров А.Н. Предельные распределения для сумм независимых случайных величин. - М.-Л.: ГИТТЛ, 1949. - 264 с.18. Ибрагимов И.А., Хасьминский Р.З. Асимптотическая теория оценивания. - М.: Наука, 1979. 528 с.19. Смирнов Н.В. Оценка расхождения между эмпирическими кривыми распределения в двух независимых выборках. // Бюллетень. МГУ им. М.В. Ломоносова. Сер. А. 1939. Т.2. № 2. С.3-14.20. Гнеденко Б.В., Королюк В.С. О максимальном расхождении двух эмпирических распределений. // Доклады АН СССР. 1951. Т.80. № 4. С.525-528.21. Методика. Проверка однородности двух выборок параметров продукции при оценке ее технического уровня и качества. - М.: Всесоюзный научно-исследовательский институт стандартизации Госстандарта СССР, 1987. - 116 с.22. Камень Ю.Э., Камень Я.Э., Орлов А.И. . Реальные и номинальные уровни значимости в задачах проверки статистических гипотез // Заводская лаборатория. 1986. Т. 52. №. 12. С. 55-57. 23. Левин Б.Р., Демидович Н.О. Использование непараметрических методов при обработке результатов испытаний на надежность. // Надежность средств связи. - Киев: Технiка, 1976. - С.59-72.24. Блехман И.И., Мышкис А.Д., Пановко Я.Г. Механика и прикладная математика: Логика и особенности приложений математики. - М.: Наука, 1983. - 328 с.Контрольные вопросы и задачи1. Почему в прикладной статистике необходимо использовать теоремы о наследовании сходимости?2. Примените метод линеаризации для изучения распределения выборочной дисперсии (исходя из асимптотической нормальности при n > ? среднего арифметического двумерных векторов (Xk, (Xk)2), k = 1, 2, . , n).3. Как применяется в прикладной статистике принцип инвариантности?4. Как с точки зрения нечетких множеств можно интерпретировать вероятность накрытия определенной точки случайным множеством?5. На множестве Y = {y1,y2,y3} задано нечеткое множество B с функцией принадлежности ?B(y), причем ?B(y1) = 0,1, ?B(y2) = 0,2, ?B(y3) = 0,3. Постройте случайное множество А так, чтобы Proj A = B.6. На множестве Y = {y1,y2,y3} задано нечеткое множество B с функцией принадлежности ?B(y), причем ?B(y1) = 0,2, ?B(y2) = 0,1, ?B(y3) = 0,5. Постройте случайное множество А так, чтобы Proj A = B.7. На множестве Y = {y1,y2,y3} задано нечеткое множество B с функцией принадлежности ?B(y), причем ?B(y1) = 0,5, ?B(y2) = 0,4, ?B(y3) = 0,7. Постройте случайное множество А так, чтобы Proj A = B.8. На множестве Y = {y1,y2,y3} задано нечеткое множество B с функцией принадлежности ?B(y), причем ?B(y1) = 0,3, ?B(y2) = 0,2, ?B(y3) = 0,1. Постройте случайное множество А так, чтобы Proj A = B.9. В чем состоит основная идея принципа уравнивания погрешностей?Темы докладов, рефератов, исследовательских работ1. Законы больших чисел и различные варианты Центральной предельной теоремы - основные результаты классической теории вероятностей.2. Место теорем о наследовании сходимости и метода линеаризации в асимптотической прикладной статистике.3. Принцип инвариантности для классических непараметрических статистик.4. Обсудите суждение: "Мы мыслим нечетко" (см. [15]). Почему нечеткость мышления помогает взаимопониманию?5. Взаимосвязь теории нечеткости и теории вероятностей.6. Методы оценивания функции принадлежности.7. Теория нечеткости и интервальная математика.8. Описание данных для выборок, элементы которых - нечеткие множества.9. Регрессионный анализ нечетких переменных (согласно [9]).10. Кластерный анализ нечетких данных.11. Непараметрические оценки плотности распределения вероятностей в пространстве нечетких множеств (согласно подходу главы 2.1).12. Проблема устойчивости в математическом моделировании.  