 Г Л А В А  7
 НЕПАРАМЕТРОИЧЕСК о Е ОЦЕНИВАНИЕ 
 
 В этой главе рассматриваются методы оценивания распределений случайных величин в тех случаях, когда тип этих распределений априори неизвестен. При этом к классу распределений могут предъявляться лишь самые общие требования: одномерность случайной величины, непрерывность функции распределения, существование функции плотности распределения и т.п. (эти требования специально оговариваются). 

 :7.1. Оценивание функции распределения

В п.1.2 было показано, что состоятельной оценкой функции распределения скалярной случайной величины служит эмпирическая функция распределения (1.1). Эта оценка является несмещенной и эффективной.
Действительно, оценка функции распределения  случайной величины X с использованием эмпирической функции распределения  полученной по простой выборке , представляет собой, по существу, оценку параметра  в биномиальном распределении числа событий  в N опытах при 
С другой стороны, по построению, эта функция для каждого  x  равна

где  - число элементов выборки  меньших x, т.е. представляет собой частоту  WA  события A.
Нетрудно убедиться (читатель может это сделать самостоятельно), что  является несмещенной и эффективной оценкой 
В практических задачах эмпирическая функции распределения в качестве оценки функции распределения используется сравнительно редко. Так, для дискретной случайной величины  X  оценкой её распределения обычно служат оценки вероятностей её значений , т.е. частоты событий 

где  - число опытов (из N), в которых случайная величина  X  приняла значение  x ( i ). Эти оценки также являются состоятельными, несмещенными и эффективными.
Такой подход к оцениванию распределения дискретной случайной величины применяется и тогда, когда она является случайным вектором. При абсолютно непрерывном распределении случайных величин используются оценки функций плотности распределения, методы получения которых рассмотрены ниже.

:7.2. Оценивание функции плотности
 	 распределения скалярной случайной величины. Гистограмма
 
 В этом параграфе рассматривается задача оценивания существующей , но неизвестной функции плотности распределения  скалярной случайной величины Х, представленной простой выборкой своих значений 
Оценивание функции  может иметь двоякий характер: оценивание её "в целом", т.е. получение графика, выражающего её общий вид, или локальное оценивание, преследующее цель оценки этой функции в некоторой фиксированной точке x.
Первый (более сложный) подход необходим в тех случаях, когда получаемые оценки функции плотности распределения служат, например, для построения решающих правил  в задачах выбора или проверки статистических гипотез, второй - в задачах принятия решений в схемах уже построенных решающих правил (например, при вычислении оценки значения функции отношения правдоподобия в фиксированной точке).
Оценка функции плотности распределения "в целом" (именуемая  гистограммой) строится следующим образом.
Пусть  - крайние точки вариационного ряда выборки . Разобьем отрезок  ("размах варьирования") на  непересекающихся отрезков (разрядов, "карманов")  длиной  li  каждый:

Построим ступенчатую функцию (гистограмму), принимающую в каждом разряде постоянное значение
 				 		             (7.1)
где  - число элементов  лежащих в 
Пусть функция плотности распределения конечна и непрерывна. Обозначая  частоту события  вероятность которого равна

, для математического ожидания и дисперсии значения гистограммы при получим 
,
       (7.2)
и, следовательно, 
Таким образом, для   - несмещенная и состоятельная оценка значения  для некоторого .Чтобы сделать гистограмму  асимптотически несмещенной состоятельной оценкой функции плотности распределения  для всех  x,  следует при устремлять все  к нулю, т.е. выполнять условие: . Для сохранения при этом условия (7.2), гарантирующего состоятельность  как оценки, необходимо, однако, потребовать, чтобы для  при  выполнялось предельное соотношение 
Перейдем теперь к локальному оцениванию функции плотности распределения, при котором ставится задача ее оценки по выборке  для некоторого фиксированного значения x.  Пусть

где  - некоторое положительное число. Исходя из определения функции плотности распределения как производной функции распределения, естественно её оценку выразить через эмпирическую функцию распределения  в виде
     (7.3)
Как и при построении гистограммы, для асимптотической несмещенности оценки (7.3) необходимо выполнять требование:

при условии

Рассмотрим этот вопрос подробнее.
Для удобства анализа придадим (7.3) несколько иную форму: 
      (7.4)
где 
                        (7.5) 
Таким образом, получилась оценка следующего вида:
                 (7.6)
При задании  в виде (7.5) сумма в последнем равенстве равна числу элементов выборки , лежащих в отрезке 
Можно, однако, выбрать иной вид функции   (при соблюдении ряда указанных ниже условий). Эта функция в общем случае выражает взвешенную относительную частоту попадания с.в. Х в отрезок  и носит название весовой функции в описываемом методе оценки функции плотности распределения   (называемом методом Парзена).
Итак, задача сводится к выбору функции  и числа  h .
Некоторые ограничения на вид функций  можно наложить сразу, пользуясь тем, что по очевидным соображениям  должна обладать всеми свойствами плотности вероятности:
		(7.7)
Другие ограничения на  будут вытекать из требований на свойства оценки  
Потребуем сначала, чтобы эта оценка была асимптотически несмещенной, т.е. чтобы для ( x  выполнялось условие
.
Это равенство оказывается справедливым при непрерывности функции  (что здесь предполагается) и если  удовлетворяет условиям (7.7), а также следующим ограничениям:
		(7.8)
			(7.9)
при этом    - последовательность положительных величин, такая, что
			(7.10)
Докажем это утверждение. В силу того, что исходная выборка  X ( N ) простая, имеем

Модуль разности  нетрудно представить в виде
Выберем  и разобьем область интегрирования в последнем равенстве на две области:  и   Тогда

Но


Следовательно


Таким образом, для за счет выбора  при выполнении условий (7.8) - (7.10), правая часть последнего неравенства может быть сделана меньше . А это и означает асимптотическую несмещенность во всех точках непрерывности функции , т.е. для ( x , если  она непрерывна.
Получим теперь условия состоятельности оценки 
Вычислим дисперсию 
.
Поскольку
и

(здесь использовано условие (7.10)), то

Заметим, что из (7.7) и (7.8) следует ограниченность  Тогда для состоятельности оценки достаточно потребовать выполнения еще одного ограничения на последовательность 
, 			(7.11)
при выполнении которого дисперсия оценки плотности распределения стремится  к нулю.
Таким образом, условия (7.7) - (7.11) обеспечивают асимптотическую несмещенность и состоятельность оценки (7.6). 
Следует отметить, что хотя  при  стремится к -функции, этот процесс должен осуществляться не слишком быстро. А именно так, чтобы число выборочных значений, "взвешиваемых" каждой функцией  неограниченно возрастало. (Это следует из (7.11)). Значит, оценка в каждой точке x оказывается суммой неограниченного числа независимых случайных величин. Следовательно, при определенных условиях, в соответствии с центральной предельной теоремой, оценка  будет асимптотически нормальной.

7.3. Оценка функции плотности распределения
 случайного вектора

Во многих практически важных случаях необходимо производить оценивание плотностей многомерных распределений. Изложенный выше метод Парзена допускает обобщение на  n  - мерный случай и при этом сравнительно нетрудно получить обобщение условий (7.7) - (7.11). Однако количество вычислительных операций и объем информации, которую необходимо хранить во время их выполнения, в многомерном случае резко возрастают. Поэтому, даже с применением ЭВМ, практическое получение многомерных оценок, являющихся прямым обобщением одномерных, в принципе возможное, становится фактически трудновыполнимым. Это обстоятельство часто заставляет отказаться от построения оценки всей многомерной плотности распределения и пытаться получить локальные оценки значений этой функции в точке    по имеющейся выборке     N  значений вектора  X .
Существует несколько методов получения таких оценок. Здесь будет рассмотрен так называемый метод " k  ближайших соседей ".
Этот метод сравнительно прост с вычислительной точки зрения и особенно удобен, когда нет необходимости строить оценки плотностей распределений целиком, а достаточно сравнивать их значения в отдельных точках (как это имеет место, например, в задачах классификации объектов по векторному случайному признаку, cм. Главы 2 и 3). 
Итак, пусть теперь  X  - n -мерный случайный вектор с неизвестной непрерывной плотностью распределения  - выборка значений этого вектора, - значение  X , для которого оценивается плотность  Будем считать, что  Обозначим через  евклидово расстояние i -го элемента от точки  , т.е.
 		    (7.12)
(здесь  xij  и  xj * -  j -е компоненты соответственно вектора xi из  и вектора  x *).
Многомерная плотность распределения в точке  может быть определена как
 		     (7.13)
где - шар радиуса r с центром в точке      - объем этого шара. Выберем радиус шара  таким, что, с одной стороны,  при , а с другой - позволяет получить весьма простую оценку вероятности  Для этого примем , где  - расстояние точки x* до k -й ближайшей точки из . Другими словами, это означает, что  -  k -е по величине значение ri для элементов выборки , образованной из выборки  согласно (7.12).  
Тогда есть, очевидно, сумма первых  k  долей выборки когда радиус гиперсферы (7.12) берется в качестве упорядочивающей функции выборки . Используя свойства долей выборки (см. п. 1.4), можно видеть, что
	      (7.14)
( Be ( ( | ( ) - бета-распределение).
Среднее значение случайной величины  равно  Поэтому естественно предложить в качестве оценки  значения функции плотности распределения  в точке  x * величину
 
 (здесь и далее ).
Покажем, что эта оценка является состоятельной, т.е. сходится по вероятности к  при , если выполняются следующие условия:

Вначале покажем, что
		   (7.15)
В соответствии с (7.13), для этого необходимо доказать сходимость

при выполнении условий для   
В самом деле, для любого  если имеет место событие  где - число точек выборки , лежащее внутри шара  с радиусом  и с центром в точке  x *.
Обозначая через  можно записать

Далее, воспользовавшись предельной теоремой для биноминального распределения, в силу свойств k(N) имеем

что и доказывает (7.15). Но (7.15) можно переписать в следующем виде:
.
В соответствии со свойствами сходимости последовательности случайных величин по вероятности, для состоятельности  необходимо и достаточно, чтобы имела место сходимость
.
Последнее установить нетрудно, поскольку ввиду (7.14), математическое ожидание и дисперсия равны, соответственно:

и требуемый результат сразу следует из неравенств Чебышева. Таким образом, состоятельность оценки доказана.
Обратим внимание на то, что в рассматриваемом методе оценки плотности распределения при фиксированных N и k размер "разряда" (объем шара ) есть случайная величина и зависит от случайного расположения элементов выборки.
Там, где элементы выборки расположены "плотнее", радиус шара "автоматически" сокращается и наоборот. Это обстоятельство благоприятно отражается на качестве оценивания плотности распределения. В то же время следует иметь в виду, что при относительно небольших N обеспечить малость можно только при малых значениях k.Тем самым точность оценки будет невысокой. Этот недостаток, серьезный с точки зрения решения задачи оценивания плотности распределения, не является существенным, когда оценивание является вспомогательной задачей и полученные оценки используются для целей классификации.
Рассмотрим этот вопрос подробнее.
Пусть - две выборки значений случайного вектора (признака), принадлежащих, соответственно, классам  т.е. имеющих распределения  и Зафиксируем  k  и найдем оценки

где - значения  для первой и второй выборки, объемы которых для простоты принимаем равными:  N 1 =  N 2 =  N . Тогда получаем оценку функции отношения правдоподобия

которая может использоваться для принятия решения в рамках рассмотренных выше статистических критериев Неймана-Пирсона и Байеса.
Это решающее правило является относительно простым и не требует знания плотностей вероятности "в целом". Вычислительные трудности этого алгоритма связаны только с нахождением расстояний от  x * до 2 N   элементов выборок. Следует, однако, заметить, что если  N  велико, то необходимость вычисления расстояний до всех элементов выборок при высокой размерности признака существенно снижает вычислительную эффективность такого алгоритма. Ниже будет описана модификация метода "k ближайших соседей", позволяющая существенно повысить его эффективность.
Остановимся кратко на методе классификации, близком к рассмотренному выше при , именуемом правилом "ближайшего соседа". Пусть - помеченная обучающая выборка значений с.в.  x , соответствующих гипотезам  H 1 ( N 1 элементов) и  H 2 ( N 2 элементов), причем значения чисел  N 1 и  N 2 отражают априорные вероятности и То, что эта выборка является помеченной означает, что для каждого её элемента известен соответствующий ему класс (гипотеза)  Hi .   
Решение о классе, к которому принадлежит наблюдаемый объект с значением признака  X = x , принимается теперь по классу, к которому относится ближайший к  x  элемент выборки  Оценим эффективность этого метода.
Пусть принято решение о том, что наблюдаемый объект принадлежит к классу  Hi , так как этому классу соответствует ближайший к  x  элемент выборки  x 1. Если истиный класс объекта  Hj , то при  Hj( Hi  возникает ошибка, вероятность которой равна

Будем считать, что N велико и поэтому x и x1  расположены близко друг к другу. В этом случае можно пользоваться приближенным равенством

Тогда вероятность ошибки примет вид

то есть  является только функцией .
Сравним с вероятностью ошибки критерия максимума апостериорной вероятности  при данном  x .
Очевидно, что

Таким образом, сравнивая можно сделать вывод, что

Полная вероятность ошибки принятия решения  есть математическое ожидание  поэтому

где 
Следовательно, вероятность шибки при использовании правила ближайшего соседа в качестве решающего правила меньше, чем удвоенная вероятность ошибки критерия максимума апостериорной вероятности в предположении, что  N  является достаточно большим (для выполнения приближенного равенства  Учитывая что правило ближайшего соседа не требует какой-либо информации о распределении, его можно считать весьма эффективным.
Нижнюю границу вероятности ошибки при использовании этого решающего правила можно получить следующим образом:

Последнее неравенство справедливо, поскольку выполняется очевидное условие  Таким образом, вероятность ошибки ограничена снизу вероятностью ошибки критерия максимума апостериорной вероятности. Причем  когда  или  почти всюду, что, впрочем и так понятно.
Несмотря на внешнюю простоту, правила "k ближайших соседей", его практическая реализация ведет к недопустимо большим временным затратам, когда требуется классифицировать выборку большого объема, а элементы выборки являются векторами. Этот недостаток алгоритма обусловлен тем обстоятельством, что традиционное представление точки многомерного пространства в виде вектора слабо связано с задачей идентификации положения этой точки. Поэтому при повышении размерности задачи резко возрастает сложность вычислений. Поясним сказанное на примере одно - и двумерного пространства.
В случае одномерного пространства положение точки на действительной оси полностью задается одним числом. Отметим важную особенность такого представления: если старший разряд (цифра) числа известен, то следующий, младший, лишь уточняет уже имеющуюся информацию, т.е. положение точки на прямой. Это свойство связано с позиционностью записи действительного числа. Следовательно, цифры (разряды) числа в позиционной записи могут служить естественной основой для организации поэтапных процедур его обработки - от старших разрядов к младшим. Таким образом, возможно построение алгоритмов, которые последовательно, шаг за шагом анализируют поразрядно значение скалярного признака до тех пор, пока не будет принято решение. При этом анализ полного представления величины этого признака вовсе необязателен.
Очевидно, что в двумерном пространстве любое представление точки в виде вектора свойством позиционности (как оно здесь понимается) не обладает. В то же время для задания положения точки на плотности существуют иерархические представления, обладающие этим свойством. Для этого, как и в одномерном случае, нужно уметь с помощью одного числа задавать положение точки в двумерном пространстве. Сделать это можно, например, следующим образом (для простоты считается, что точка может принадлежать некоему квадрату на плоскости). Все допустимое множество разбивается на равные квадраты (разбиение первого уровня), каждому квадрату присваивается свой номер. Затем каждый из квадратов в свою очередь разбивается на равные квадраты, которые также перенумеровываются ( разбиение второго уровня ). И так далее до любого уровня разбиения, т.е. до любой степени точности локализации точки на плоскости.
Любому квадрату можно поставить в соответствие число ( его номер ), которое полностью определяет его положение в пространстве: первая цифра этого числа есть номер квадрата первого уровня разбиения, которому принадлежит искомый квадрат, вторая цифра - номер квадрата второго уровня разбиения, содержащего искомый квадрат и т.д. Количество цифр в этом числе определяет размер квадрата, т.е. уровень разбиения. Теперь положение точки в пространстве можно задавать номером квадрата, которому она принадлежит, причем, как и в одномерно случае, каждая следующая цифра номер лишь уточняет положение точки в пространстве.
В таком подходе замечательно то, что его можно распространить на пространство любой размерности. Для этого надо разбить пространство на части (называемые далее квантами) и задать их способ нумерации. При этом положение точки в пространстве будет задаваться одним числом (независимо от размерности пространства) - номером кванта, которому принадлежит искомая точка. Такое описание положения точки в пространстве будем называть ее позиционной координатой.
Перейдем теперь непосредственно к описанию модифицированного метода " k ближайших соседей", учитывающего особенности позиционного представления многомерной информации. Пусть, как и раньше, точка x классифицируется по выборке . Вначале анализируется квант первого уровня разбиения, которому принадлежит эта точка. Если в этом кванте не менее  k  точек принадлежит распределению , а точек из распределения меньше  k  , то принимается решение о принадлежности искомой точки распределению  Если это требование не выполняется, то переходим к анализу кванта следующего уровня и проверяем то же условие. Эта процедура продолжается до тех пор, пока не будет принято то или иное решение. Вообще говоря, возможен и отказ от принятия решения о принадлежности точки  x  тому или иному распределению, когда при уменьшении размера кванта число лежащих в нем элементов выборки недостаточно для принятия решения. В этой ситуации можно поступить, например, следующим образом: рассмотреть содержимое кванта предыдущего уровня (т.е. вернуться на шаг "назад") и принять решение в пользу того распределения, точек которого в данном кванте больше.
Следует также отметить, что описываемый модифицированный метод " k  ближайших соседей" отличается от классического и тем, что теперь анализируемая точка не является центром кванта. Позиционное представление координат подразумевает разбиение пространства на кванты, которые, естественно, никак не связаны с расположением точек выборки. Поэтому возможна ситуация, когда точка, отнесенная традиционным методом к одному распределению, предложенным алгоритмом будет отнесена к другому. В то же время, этот недостаток во многом компенсируется тем обстоятельством, что в предлагаемом методе анализ областей идет в "обратном" порядке. Вследствие этого решение принадлежности к тому или иному распределению может приниматься на квантах более высокого уровня. Статистические эксперименты показывают, что число неправильно классифицированных точек для рассмотренных примеров относительно невелико.
Более подробно об эффективности алгоритмов классификации, использующих позиционное представление и о самих позиционных координатах, см.  [3].
 




