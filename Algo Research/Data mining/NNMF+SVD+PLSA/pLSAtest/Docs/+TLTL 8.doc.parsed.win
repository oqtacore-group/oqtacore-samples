 Г Л А В А  8
ЭЛЕМЕНТЫ РЕГРЕССИОННОГО АНАЛИЗА. МЕТОД НАИМЕНЬШИХ КВАДРАТОВ

Важный раздел математической статистики образуют модели, описывающие связи между изучаемыми случайными величинами. В этой главе приведены основные сведения о регрессионном анализе, широко используемым для построения таких моделей и исследования статистических зависимостей. Здесь же приводятся сведения об основном аппарате, используемом для решения такой задачи - о методе наименьших квадратов (который, впрочем, имеет более широкое применение).

:8.1. Множественная регрессия

Пусть    -   N  - мерный случайный вектор с функцией распределения  - его непересекающиеся подвекторы размерности  n 1 и  n 2 ( n 1 + n 2 = N ):
 
 ( без умаления общности здесь и далее будем полагать, что подвектор   содержит первые  n 1 компонент вектора   ,   - остальные  n 2 его компонент).
Напомним, что функцией множественной регрессии    на   называется условное математическое ожидание вектора   , рассматриваемое как функция значений вектора   :
 
 (здесь    - условная относительно    функция распределения вектора ).
Эта функция хорошо выражает зависимость    в среднем, так как при каждом фиксированном  средний квадрат отклонения вектора  от  имеет наименьшее значение на множестве всех функций 

(этот факт легко устанавливается по аналогии с (5.23) в (п.5.3).
Пусть теперь  Тогда 
 где  и  получаются из , R  отбором элементов, относящихся к компонентам  и  Известно [1], что в этом случае
	      (8.1)
где матрица  R (12) легко находится из блочного представления матрицы  R :
			      (8.2)
(её элементами являются корреляционные моменты компонент  и  векторов 
  .
На практике наиболее часто встречаются задачи, в которых  - скалярная случайная величина. Будем в дальнейшем рассматривать именно этот случай, обозначая  Для нормального распределения вектора  функция регрессия  Y  на  - скалярная и имеет линейную форму:
		      (8.3)
 - вектор коэффициентов, определяемых параметрами распределения вектора 
Задача обычно состоит в том, чтобы по экспериментально полученной выборке   N  пар значений  Y  и  найти зависимость (8.3), т.е. неизвестное значение  Модель такой задачи легко приводится к виду
			      (8.4)
в которой приняты обозначения:
 - выборка значений случайной величины  Y ;  - матрица, ( i , j ) - й элемент которой равен значению  j -й компоненты вектора  в  i -м измерении   n  - размерность вектора ,   - единичная матрица, (2 - дисперсия случайной величины  Y   (в (8.2)).
Последнее условие выражает тот факт, что выборка   -  простая. Ниже показано, как поступить, если существует корреляция между измерениями, т.е.
.
Если оснований для гипотезы о нормальности распределения вектора ( Y ,  Z )Т нет, функция регрессии, вообще говоря, не может точно выражаться линейной формой (8.3). Однако, выбирая подходящую аппроксимацию функции регрессии с помощью базисных функций  можно приближенно (с точностью аппроксимации) использовать модель (8.4), если положить   xj -  j -й коэффициент аппроксимации   - центрированный вектор с независимыми  компонентами  (для простой выборки  (  ., 

:8.2. Метод наименьших квадратов (МНК)

Итак, задача оценки функции регрессии сведена нами к оценке неслучайного вектора  в (8.4) по измеренному значению вектора  при неизвестном центрированном векторе ошибки 
Следует заметить, что эта модель имеет широкое применение и в других приложениях.
Далее предполагается независимость и, следовательно, некоррелированность компонент  т.е. выполнение условия
		      (8.5)
Однако, если (8.5) для модели (8.4) не выполняется т.е.
,
то можно перейти к модели

или

где  матрица, переводящая матрицу  в единичную матрицу , и представляющая собой произведение

где  F  - ортогональная матрица, приводящая матрицу к диагональной  D :
		
Далее предполагается, что А - матрица ранга  n,  т.е.

(отказ от этого условия требует привлечения теории обобщённых матриц и здесь не рассматривается).
Пусть  - полученное значение вектора . Идея  MHK  состоит в минимизации квадратичной формы
 
 т.е. в использовании оценки  вектора , удовлетворяющей условию
		.		      (8.6)
Из равенства

где  -  i -й вектор-столбец матрицы А, следует, что  -  N -мерный вектор, лежащий в  n  - мерном линейном подпространстве  пространства  с базисом 
МНК основан, следовательно, на выборе в качестве оценки вектора  вектора , которому соответствует вектор , также лежащий в  и имеющий минимальное (по модулю) отклонение от значения  вектора , т.е.представляющий собой проекцию вектора  (лежащего в пространтве ) на пространство .
Представим условие (8.6) системой уравнений

Последние равенства можно записать в виде

или, в матричной форме,
.
Обозначим  Тогда 
	      	(8.7)
Выражение (8.7) представляет собой систему так называемых нормальных уравнений метода наименьших квадратов.
Рассмотрим свойства МНК-оценок. Прежде всего установим, что - несмещенная оценка вектора 

Пусть  Тогда  является эффективной оценкой вектора  Действительно, в этом случае  и  представляет собой оцениваемый векторный параметр распределения  Оценивание  производится по единственному измерению  и 
		     (8.8)
Найдем матрицу  A , входящую в (5.8). Нетрудно проверить, что 

С другой стороны,  что соответствует превращению (5.8) в равенство и эффективности оценки 
При рассматриваемых условиях оценка  полученная методом наименьших квадратов, совпадает с оценкой метода наибольшего правдоподобия, поскольку вектор  минимизирующий квадратичную форму в (8.8), одновременно максимизирует функцию правдоподобия 
В более общем случае, когда
 ,
МНП-оценка  соответствует МНП-оценке при условии, что минимизируется не  а квадратичная форма
		
т.е. взвешенная сумма квадратов отклонений компонент векторов  и  ("веса" слагаемых тем больше, чем выше точность измерения соответствующей компоненты , т.е. чем меньше дисперсия 
В отличие от метода наибольшего правдоподобия, для применения метода наименьших квадратов не требуется знание типа распределения вектора измерения  При этом справедлива следующая теорема.
Теорема Гаусса-Маркова. Среди класса  несмещённых линейных оценок вектора , связанного с вектором измерений  Y  соотношением (8.4), метод наименьших квадратов доставляет оценку, все компоненты которой имеют дисперсии, не большие, чем дисперсия соответствующих компонент любой оценки   , т.е.
			      (8.9)
Доказательство. Выше было получено
.
Пусть теперь  - любая оценка из . Тогда  т.е. 
 UA = I .			    (8.10)
Далее, для корреляционной матрицы    получим

(последнее тождество справедливо ввиду (8.10)).
Итак, 

где  F  - матрица с неотрицательными диагональными элементами. Отсюда сразу следует (8.9).

:8.3. Интервальное оценивание методом наименьших квадратов

Рассмотрим вектор невязки

Предположим, что  тогда корреляционная матрица вектора  равна 

(поскольку  G  симметрична и идемпотентна:  GG = G ).
Найдём ранг  С одной стороны, 

с другой -

и

т.е.

в силу чего 
Поскольку  G  симметрична, существует ортогональная матрица  F , удовлетворяющая условию
  .
Но  D  - идемпотентная матрица, так как
.
Это значит, что для всех  т.е. 0 или 1.
Поскольку  rang D  =  rang G , то диагональ матрицы  содержит  n  единиц и ( N - n ) нулей; поэтому
 
Введем вектор 
Получим, учитывая идемпотентность  G ,

где  поэтому

Покажем теперь, что  и  - независимые случайные векторы. Этот факт следует из следующей леммы.
Лемма. Пусть  и  Для независимости  и  необходимо и достаточно выполнение условия

Для доказательства этого утверждения введем матрицу , состоящую из корреляционных моментов компонент векторов  и :  =.
Образуем вектор

Имеем

и равенство  является необходимым и достаточным для независимости  и   . Лемма доказана.
В нашем случае
  и

вместе с тем

откуда следует независимость  и . Из полученного результата следует независимость  и  а также
и 
где ( -  i -й диагональный элемент матрицы 
Поскольку  получаем
,
что позволяет осуществлять интервальное оценивание компонент вектора , используя соотношения
	 (8.11)
Подчеркнем тот факт, что формулы точечного и интервального оценивания вектора  (8.7) и (8.11) не содержат в явном виде  т.е. их использование не требует знания дисперсии ошибки. Более того, нетрудно показать, что при рассматриваемой постановке задачи можно найти оценку  дисперсии ошибки  и оценку корреляционной матрицы оценки  Для этого используем метод наибольшего правдоподобия:


Полученная оценка  смещена:

поэтому вместо неё следует взять скорректированную несмещённую оценку 

Далее:

откуда 

(в силу свойства инвариантности МНП-оценки).
В заключение заметим, что нередко условия эксперимента таковы, что матрица А не только известна, но и может видоизменяться  по воле экспериментатора. Тогда возникает задача такого её подбора, при котором несмещённая оценка вектора  имеет наименьшую дисперсию. Эта задача, однако, относится к проблеме планирования эксперимента и здесь не рассматривается.





