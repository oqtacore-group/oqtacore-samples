2.2. Оценивание2.2.1. Методы оценивания параметров	В прикладной статистике используются разнообразные параметрические модели. Термин "параметрический" означает, то вероятностно-статистическая модель полностью описывается конечномерным вектором фиксированной размерности. Причем эта размерность не зависит от объема выборки.	Рассмотрим выборку x1, x2,., xn из распределения с плотностью f(x;?0), где f(x;?0)- элемент параметрического семейства плотностей распределения вероятностей {f(x;?), ?є?}. Здесь ? - заранее известное k-мерное пространство параметров, являющееся подмножеством евклидова пространства Rk, а конкретное значение параметра ?0 статистику неизвестно. Обычно в прикладной статистике применяются параметрические семейства с k = 1,2,3 (см. главу 1.2). В статистике нечисловых данных вместо плотности часто рассматриваются вероятности попадания в точки. Напомним, что в параметрических задачах оценивания принимают вероятностную модель, согласно которой результаты наблюдений x1, x2,., xn рассматривают как реализации n независимых случайных величин. 	Задача оценивания состоит в том, чтобы оценить неизвестное статистику значение параметра ?0 наилучшим (в каком-либо смысле) образом.	Пример 1. В статистических задачах стандартизации и управления качеством используют семейство гамма-распределений. Плотность гамма-распределения имеет вид   (1)Плотность вероятности в формуле (1) определяется тремя параметрами a, b, c, где a>2, b>0. При этом a является параметром формы, b - параметром масштаба и с - параметром сдвига. Множитель 1/?(а) является нормировочным, он введен, чтобыЗдесь ?(а) - одна из используемых в математике специальных функций, так называемая "гамма-функция", по которой названо и распределение, задаваемое формулой (1),Подробные решения задач оценивания параметров для гамма-распределения содержатся в разработанном нами государственном стандарте ГОСТ 11,011-83 "Прикладная статистика. Правила определения оценок и доверительных границ для параметров гамма-распределения" [1]. В настоящее время эта публикация используется в качестве методического материала для инженерно-технических работников промышленных предприятий и прикладных научно-исследовательских институтов.	Поскольку гамма-распределение зависит от трех параметров, то имеется 23 - 1 = 7 вариантов постановок задач оценивания. Они описаны в табл.1. Таблица 1.Постановки задач оценивания для параметров гамма-распределения?№ п/пПараметр формыПараметр масштабаПараметр сдвига??1ИзвестенОцениваетсяИзвестен??2ОцениваетсяИзвестенИзвестен??3ИзвестенИзвестенОценивается??4ОцениваетсяОцениваетсяИзвестен??5ИзвестенОцениваетсяОценивается??6ОцениваетсяИзвестенОценивается??7ОцениваетсяОцениваетсяОценивается?	В табл.2 приведены реальные данные о наработке резцов до предельного состояния, в часах. Упорядоченная выборка (вариационный ряд) объема n = 50  взята из государственного стандарта [1]. Проверка согласия данных о наработке резцов с семейством гамма-распределений проведена в главе 2.3. Именно эти данные будут служить исходным материалом для демонстрации тех или иных методов оценивания параметров.Таблица 2.Наработка резцов до предельного состояния, ч?№ п/пНаработка, ч№ п/пНаработка, ч№ п/пНаработка, ч??191847,53563??217,519483664,5??32120503765??426,521513867,5??527,52253,53968,5??63123554070??732,524564172,5??83425564277,5??9362656,54381??1036,52757,54482,5??113928584590??124029594696??1341305947101,5??1442,5316048117,5??1543326149127,5??16453361,550130??17463462?	Выбор "наилучших" оценок в определенной параметрической модели прикладной статистики - научно-исследовательская работа, растянутая во времени. Выделим два этапа. Этап асимптотики: оценки строятся и сравниваются по их свойствам при безграничном росте объема выборки. На этом этапе рассматривают такие характеристики оценок, как состоятельность, асимптотическая эффективность и др. Этап конечных объемов выборки: оценки сравниваются, скажем, при n = 10. Ясно, что исследование начинается с этапа асимптотики: чтобы сравнивать оценки, надо сначала их построить и быть уверенными, что они не являются абсурдными (такую уверенность дает доказательство состоятельности). 	С какой оценки начинать? Одним из наиболее известных и простых в употреблении методов является метод моментов. Название связано с тем, что этот метод опирается на использование выборочных моментовгде x1, x2,., xn - выборка, т.е. набор независимых одинаково распределенных случайных величин с числовыми значениями. 	В прикладной статистике метод анализа данных называется методом моментов, если он использует статистику   (2)где g: Rq > Rk - некоторая функция (здесь k - число неизвестных числовых параметров). Чаще всего термин "метод моментов" используют, когда речь идет об оценивании параметров. В этом случае обычно предполагают, что плотность вероятности распределения элементов выборки f(x) входит в заранее известное статистику параметрическое семейство {f(x;?), ?є?}, т.е. f(x) = f(x;?0) при некотором ?0. Здесь ? - заранее заданное k-мерное пространство параметров, являющееся подмножеством евклидова пространства Rk, а конкретное значение параметра ?0 статистику неизвестно, его и следует оценить. Известно также, что неизвестный параметр определяется с помощью известной статистику функции через начальные моменты элементов выборки:   (3)В методе моментов в качестве оценки ?0 используют статистику Yn вида (2), которая отличается от формулы (2) тем, что теоретические моменты заменены выборочными. 	Статистики Yn вида (2) применяются не только для оценивания параметров, но и для непараметрического оценивания характеристик случайной величины, таких, как коэффициент вариации, и для проверки гипотез. Во всех случаях применения статистики Yn вида (2) говорят о методе моментов.	Распределение вектора Yn во всех практически важных случаях является асимптотически нормальным. Это утверждение опирается на следующий общий факт.	Пусть случайный вектор Zn є Rq асимптотически нормален с математическим ожиданием z? и ковариационной матрицей ||cij||/n, а функция h: Rq > R1 достаточно гладкая. Тогда случайная величина h(Zn) асимптотически нормальна с математическим ожиданием h(z?) и дисперсией   (4)Этот способ нахождения предельного распределения известен как ?-метод Рао [2], метод линеаризации [3]. Последний термин и будем использовать. Условия регулярности, накладываемые на распределение случайной величины Zn и функцию h, при которых метод линеаризации обоснован, хорошо известны (см. [4], [2, с.337-339], а также главу 1.4 настоящего учебника).	Для получения асимптотического распределения статистики Yn вида (2) можно применить метод линеаризации к асимптотически нормальному вектору выборочных моментов (Mn1, Mn2, ., Mnq) и функции g из формулы (2).	В силу многомерной центральной предельной теоремы (см. главу 1.4) указанная асимптотическая нормальность имеет место, если, например,Это условие выполнено, в частности, для результатов измерений, распределения которых сосредоточены на ограниченных сверху и снизу интервалах. 	При реализации намеченного плана для применения формулы (4) необходимо использовать асимптотические дисперсии и ковариации выборочных моментов, т.е. величины, обозначенные в формуле (4) как crs . Эти величины имеют вид [2, с.388]:  (5)Здесь ?r - теоретический центральный момент порядка r, т.е.Таким образом, для получения асимптотического распределения случайной величины Yn вида (2) достаточно знать теоретические центральные моменты результатов наблюдений и вид функции g. Отметим, что асимптотическим смещением оценок в рассматриваемом случае можно пренебречь, поскольку его вклад в средний квадрат ошибки статистической оценки - бесконечно малая величина более высокого порядка по сравнению с асимптотической дисперсией. 	Однако моменты неизвестны. Их приходится оценивать. В соответствии с теоремами о наследовании сходимости для нахождения асимптотического распределения функции от выборочных моментов можно воспользоваться не теоретическими моментами, а их состоятельными оценками. Эти оценки можно получить разными способами. Можно непосредственно применить формулы (5), заменив теоретические моменты выборочными. Можно выразить моменты через параметры рассматриваемого распределения. Можно применять более сложные процедуры, например, на основе непараметрических устойчивых (робастных) оценок моментов типа урезанных средних Пуанкаре и др. (в первой в России книге по общей теории устойчивости [5] проблематика робастных оценок рассмотрена в главе 2).	Для оценивания параметров гамма-распределения воспользуемся известной формулой [6, с.184-185], согласно которой для случайной величины Х, имеющей гамма-распределение с параметрами формы а, масштаба b =1 и сдвига c=0,     (6)Следовательно, M(X) = a, M(X2) = a(a+1), D(X) = M(X2) - (M(X))2 = a(a+1) - a2 = a. Найдем третий центральный момент M(X - M(X))3. Справедливо равенствоM(X - M(X))3 = M(X3) - 3 M(X2) M(X) + 3 M(X) (M(X))2 - (M(X))3.Из равенства (6) вытекает, что M(X - M(X))3 = a(a+1)(a+2) - 3 a (a+1) a + 3 a a2 - a3 = 2a.	Если Y - случайная величина, имеющая гамма-распределение с произвольными параметрами формы a, масштаба b и сдвига c, то Y = bX + c. Следовательно, M(Y) = ab+c, D(Y) = ab2, M(Y - M(Y))3 = 2 a b3.	 Пример 2. Оценивание методом моментов параметров гамма-распределения в случае трех неизвестных параметров (строка 7 таблицы 1).	В соответствии с проведенными выше рассуждениями для оценивания трех параметров достаточно использовать три выборочных момента - выборочное среднее арифметическоевыборочную дисперсиюи выборочный третий центральный моментПриравнивая теоретические моменты, выраженные через параметры распределения, и выборочные моменты, получаем систему уравнений метода моментов:Решая эту систему, находим оценки метода моментов.  Подставляя второе уравнение в третье, получаем оценку метода моментов для параметра сдвига:  Подставляя эту оценку во второе уравнение, находим оценку метода моментов для параметра формы:Наконец, из первого уравнения находим оценку для параметра сдвига:Для реальных данных [1], приведенных выше в табл.2, выборочное среднее арифметическое  = 57,88, выборочная дисперсия s2 = 663,00, выборочный третий центральный момент m3 = 14927,91. Согласно только что полученным формулам оценки метода моментов таковы: a* = 5,23; b* = 11,26, c* = - 1,01.	Оценки параметров гамма-распределения, полученные методом моментов, являются функциями от выборочных моментов. В соответствии со сказанным выше они являются асимптотически нормальными случайными величинами. Их распределения аппроксимируются нормальными распределениями, математические ожидания которых равны соответствующим  параметрам, а дисперсии находятся с помощью формулы (4) с учетом формул (5) и (6). В табл.3 приведены оценки метода моментов и их асимптотические дисперсии при различных вариантах сочетания известных и неизвестных параметров гамма-распределения.Таблица 3.Оценки метода моментов и их асимптотические дисперсии?№ п/пОписание вероятностной моделиОцени-ваемый пара-метрВид оценкиАсимптотическая дисперсия оценки??abc??1--+a??2--+b??3---a??4---b??5---c??6+--b??7+--c??8-+-A??9-+-c??10++-c?	Примечание. При описании вероятностной модели известные статистику параметры отмечены плюсами, оцениваемые - минусами.	Все оценки метода моментов, приведенные в табл.3, включены в государственный стандарт [1]. Они охватывают все постановки задач оценивания параметров гамма-распределения (см. табл.1) , кроме тех, когда неизвестен только один параметр - a или b. Для этих исключительных случаев в [1] разработаны специальные методы оценивания. 	Поскольку асимптотическое распределение оценок метода моментов известно, то не представляет труда формулировка правил проверки статистических гипотез относительно значений параметров распределений, а также построение доверительных границ для параметров. Например, в вероятностной модели, когда все три параметра неизвестны, в соответствии с третьей строкой таблицы 3 нижняя доверительная граница для параметра а, соответствующая доверительной вероятности ? = 0,95, в асимптотике имеет вида верхняя доверительная граница для той же доверительной вероятности таковагде а* - оценка метода моментов параметра формы (табл.3).	Метод моментов является универсальным. Однако получаемые с его помощью оценки лишь в редких случаях обладают оптимальными свойствами. Поэтому в прикладной статистике применяют и другие виды оценок.	В работах, предназначенных для первоначального знакомства с математической статистикой, обычно рассматривают оценки максимального правдоподобия (сокращенно ОМП):   (7)Таким образом, сначала строится плотность распределения вероятностей, соответствующая выборке. Поскольку элементы выборки независимы, то эта плотность представляется в виде произведения плотностей для отдельных элементов выборки. Совместная плотность рассматривается в точке, соответствующей наблюденным значениям. Это выражение как функция от параметра (при заданных элементах выборки) называется функцией правдоподобия. Затем тем или иным способом ищется значение параметра, при котором значение совместной плотности максимально. Это и есть оценка максимального правдоподобия.	Хорошо известно, что оценки максимального правдоподобия входят в класс наилучших асимптотически нормальных оценок (определение дано ниже). Однако при конечных объемах выборки в ряде задач ОМП недопустимы, т.к. они хуже ( дисперсия и средний квадрат ошибки больше), чем другие оценки, в частности, несмещенные [6]. Именно поэтому в ГОСТ 11.010-81 для оценивания параметров отрицательного биномиального распределения используются несмещенные оценки, а не ОМП [7]. Из сказанного следует априорно предпочитать ОМП другим видам оценок можно - если можно - лишь на этапе изучения асимптотического поведения оценок.	В отдельных случаях ОМП находятся явно, в виде конкретных формул, пригодных для вычисления.	Пример 3. Найдем ОМП для выборки из нормального распределения, каждый элемент которой имеет плотностьТаким образом, надо оценить двумерный параметр (m, ?2).	Произведение плотностей вероятностей для элементов выборки, т.е. функция правдоподобия, имеет вид   (8)Требуется решить задачу оптимизации 	Как и во многих иных случаях, задача оптимизации проще решается, если прологарифмировать функцию правдоподобия, т.е. перейти к функции,называемой логарифмической функцией правдоподобия. Для выборки из нормального распределения   (9)	Необходимым условием максимума является равенство 0 частных производных от логарифмической функции правдоподобия по параметрам, т.е.    (10)Система (10) называется системой уравнений максимального правдоподобия. В общем случае число уравнений равно числу неизвестных параметров, а каждое из уравнений выписывается путем приравнивания 0 частной производной логарифмической функции правдоподобия по тому или иному параметру. 	При дифференцировании по m первые два слагаемых в правой части формулы (9) обращаются в 0, а последнее слагаемое дает уравнение .Следовательно, оценкой m* максимального правдоподобия параметра m является выборочное среднее арифметическое,  .	Для нахождения оценки дисперсии необходимо решить уравнениеЛегко видеть, чтоСледовательно, оценкой (?2)* максимального правдоподобия для дисперсии ?2 с учетом найденной ранее оценки для параметра m является выборочная дисперсия,Итак, система уравнений максимального правдоподобия решена аналитически, ОМП для математического ожидания и дисперсии нормального распределения - это выборочное среднее арифметическое и выборочная дисперсия. Отметим, что последняя оценка является смещенной. 	Отметим, что в условиях примера 3 оценки метода максимального правдоподобия совпадают с оценками метода моментов. Причем вид оценок метода моментов очевиден и не требует проведения каких-либо рассуждений.	В большинстве случаев аналитических решений не существует, для нахождения ОМП необходимо применять численные методы. Так обстоит дело, например, с выборками из гамма-распределения или распределения Вейбулла-Гнеденко. Во многих работах каким-либо итерационным методом решают систему уравнений максимального правдоподобия ([8] и др.) или впрямую максимизируют функцию правдоподобия типа (8) (см. [9] и др.).	Однако применение численных методов порождает многочисленные проблемы. Сходимость итерационных методов требует обоснования. В ряде примеров функция правдоподобия имеет много локальных максимумов, а потому естественные итерационные процедуры не сходятся [10]. Для данных ВНИИ железнодорожного транспорта по усталостным испытаниям стали уравнение максимального правдоподобия имеет 11 корней [11]. Какой из одиннадцати использовать в качестве оценки параметра? 	Как следствие осознания указанных трудностей, стали появляться работы по доказательству сходимости алгоритмов нахождения оценок максимального правдоподобия для конкретных вероятностных моделей и конкретных алгоритмов. Примером является статья [12]. 	Однако теоретическое доказательство сходимости итерационного алгоритма - это еще не всё. Возникает вопрос об обоснованном выборе момента прекращения вычислений в связи с достижением требуемой точности. В большинстве случаев он не решен. 	Но и это не все. Точность вычислений необходимо увязывать с объемом выборки - чем он больше, тем точнее надо находить оценки параметров, в противном случае нельзя говорить о состоятельности метода оценивания. Более того, при увеличении объема выборки необходимо увеличивать и количество используемых в компьютере разрядов, переходить от одинарной точности расчетов к двойной и далее - опять-таки ради достижения состоятельности оценок. 	Таким образом, при отсутствии явных формул для оценок максимального правдоподобия нахождение ОМП натыкается на ряд проблем вычислительного характера. Специалисты по математической статистике позволяют себе игнорировать все эти проблемы, рассуждая об ОМП в теоретическом плане. Однако прикладная статистика не может их игнорировать. Отмеченные проблемы ставят под вопрос целесообразность практического использования ОМП.	Нет необходимости абсолютизировать ОМП. Кроме них, существуют другие виды оценок, обладающих хорошими статистическими свойствами. Примером являются одношаговые оценки (ОШ-оценки).	В прикладной статистике разработано много видов оценок. Упомянем квантильные оценки. Они основаны на идее, аналогичной методу моментов, но только вместо выборочных и теоретических моментов приравниваются выборочные и теоретические квантили. Другая группа оценок базируется на идее минимизации расстояния (показателя различия) между эмпирическими данными и элементом параметрического семейства. В простейшем случае минимизируется евклидово расстояние между эмпирическими и теоретическими гистограммами, а точнее, векторами, составленными из высот столбиков гистограмм. 2.2.2. Одношаговые оценки	Одношаговые оценки имеют столь же хорошие асимптотические свойства, что и оценки максимального правдоподобия, при тех же условиях регулярности, что и ОМП. Грубо говоря, они представляют собой результат первой итерации при решении системы уравнений максимального правдоподобия по методу Ньютона-Ватсона. Одношаговые оценки выписываются в виде явных формул, а потому требуют существенно меньше машинного времени, а также могут применяться при ручном счете (на калькуляторах). Снимаются вопросы о сходимости алгоритмов, о выборе момента прекращения вычислений, о влиянии округлений при вычислениях на окончательный результат. ОШ оценки были использованы нами при разработке ГОСТ 11.011-83 вместо ОМП.  	Как и раньше, рассмотрим выборку x1, x2,., xn из распределения с плотностью f(x;?0), где f(x;?0)- элемент параметрического семейства плотностей распределения вероятностей {f(x;?), ?є?}. Здесь ? - известное статистику k-мерное пространство параметров, являющееся подмножеством евклидова пространства Rk, а конкретное значение параметра ?0  неизвестно. Его и будем оценивать.	Обозначим ? =(?1, ?2,., ?k). Рассмотрим вектор-столбец частных производных логарифма плотности вероятностии матрицу частных производных второго порядка для той же функции	Положим	Пусть матрица информации Фишера I(?0) = M[-bn(?0)] положительно определена.	Определение 1 [10, с.269]. Оценку ?(n) параметра ?0 называют наилучшей асимптотически нормальной оценкой (сокращенно НАН-оценкой), если распределение случайного вектора  сходится при n > ? к нормальному распределению с нулевым математическим ожиданием и ковариационной матрицей, равной I-1(?0).	Определение 1 корректно: I-1(?0) является нижней асимптотической границей для ковариационной матрицы случайного вектора , где ?*(n) - произвольная оценка; кроме ОМП есть НАН-оценки (см. [10] и др.). Некоторые другие оценки также являются НАН-оценками, например, байесовские. Сказанное об ОМП и байесовских оценках справедливо при некоторых условиях регулярности (см., например, [13]). В ряде случаев несмещенные оценки являются НАН-оценками, более того, они лучше, чем ОМП (их дисперсия меньше), при конечных объемах выборки [6].	Для анализа реальных данных естественно рекомендовать какую-либо из НАН-оценок. (Это утверждение всегда верно на этапе асимптотики при изучении конкретной задачи прикладной статистики. Теоретически можно предположить, что при тщательном изучении для конкретных конечных объемов выборки наилучшей окажется какая-либо оценка, не являющаяся НАН-оценкой. Однако такие ситуации нам пока не известны.)	Пусть ?1(n) и  - некоторые оценки ?0 и I-1(?0) соответственно.	Определение 2. Одношаговой оценкой (ОШ-оценкой, или ОШО) называется оценка 	Теорема 1 [14]. Пусть выполнены следующие условия.(I) Распределение  сходится при n > ? к нормальному распределению с математическим ожиданием 0 и ковариационной матрицей I(?0) и, кроме того, существует     (II) При некотором ? > 0 и n > ?(III) Для любого ? > 0Тогда ОШ-оценка является НАН-оценкой.	Доказательство. Рассмотрим тождество   (1)В силу условия (II) теоремы  (2)Из условия (I) теоремы следует, что первое слагаемое в правой части формулы (2) сходится при n > ? по распределению к нормальному закону с математическим ожиданием 0 и ковариационной матрицей I-1(?0). Согласно  условию (III)по вероятности. Кроме того, согласно тому же условию последовательность матриц  ограничена по вероятности. Поэтому третье слагаемое в правой части формулы (2) сходится к 0 по вероятности. Для завершения доказательства теоремы осталось показать, что     (3)по вероятности. Левая часть формулы (3) преобразуется к виду           (4)где Е - единичная матрица. Поскольку из условия (I) теоремы следует, что для bn(?0) справедлива (многомерная) центральная предельная теорема, тоС учетом условия (III) теоремы заключаем, что         (5)Из соотношений (4), (5) и условия (III) теоремы вытекает справедливость формулы (3). Теорема доказана. 	Прокомментируем условия теоремы. Условия (I) и (II) обычно предполагаются справедливыми при рассмотрении оценок максимального правдоподобия [10]. Эти условия можно выразить в виде требований, наложенных непосредственно на плотность f(x;?) из параметрического семейства, как это сделано, например, в [13]. Условие (III) теоремы, наложенное на исходные оценки, весьма слабое. Обычно используемые оценки ?1(n) и  являются не n-1/4-состоятельными, а -состоятельными, т.е. условие (III) заведомо выполняется.	Какие оценки годятся в качестве начальных? В качестве ?1(n) можно использовать оценки метода моментов, как это сделано в ГОСТ 11.011-83 [1], или, например, квантильные. В качестве  в теоретической работе [10] предлагается использовать простейшую оценку       (6)	Для гамма-распределения с неизвестными параметрами формы, масштаба и сдвига ОШ-оценки применены в [1]. При этом оценка (6) оказалась непрактичной, поскольку с точностью до погрешностей измерений и вычислений det(bn) = 0 для реальных данных о наработке резцов до предельного состояния, приведенных выше в табл.2 (пункт 2.2.1). Поскольку det(bn) = 0, то обратная матрица не существует, вычисления по формуле (6) невозможны. Поэтому в [1] в качестве ОШ-оценки была применена непосредственно первая итерация метода Ньютона-Рафсона решения системы уравнений максимального правдоподобия, т.е. была использована оценка       (7)В формуле (7) непосредственно используется явный вид зависимости матрицы информации Фишера от неизвестных параметров распределения.	В других случаях выбор тех или иных начальных оценок, в частности, выбор между (6) и (7), может определяться, например, простотой вычислений. Можно использовать также устойчивые аналоги [5] перечисленных выше оценок.	Полезно отметить, что еще в 1925 г., т.е. непосредственно при разработке метода максимального правдоподобия, его создатель Р.Фишер считал, что первая итерация по методу Ньютона-Рафсона дает хорошую оценку вектору неизвестных параметров [10, с.298]. Он однако рассматривал эту оценку как аппроксимацию ОМП. А.А.Боровков воспринимает ОШ-оценки как способ "приближенного вычисления оценок максимального правдоподобия" [15, с.225] и показывает асимптотическую эквивалентность ОШ-оценок и ОМП (в более сильных предположениях, чем в теореме 1; другими словами, теорема 1 обобщает результаты А.А. Боровкова относительно ОШ-оценок). Мы же полагаем, что ОШ-оценки имеют самостоятельную ценность, причем не меньшую, а в ряде случаев большую, чем ОМП. По нашему мнению, ОМП целесообразно применять (на этапе асимптотики) только тогда, когда они находятся явно. Во всех остальных случаях следует использовать на этом этапе ОШ-оценки (или какие-либо иные, выбранные из дополнительных соображений).	С чем связана популярность оценок максимального правдоподобия? Из всех НАН-оценок они наиболее просто вводятся, ранее других предложены. Поэтому среди математиков сложилась устойчивая традиция рассматривать ОМП в курсах математической статистики. Однако при этом игнорируются вычислительные вопросы, а также отодвигаются в сторону многочисленные иные НАН оценки. 	В прикладной статистике - иные приоритеты. На первом месте - ОШ-оценки, все остальные НАН-оценки, в том числе ОМП, рассматриваются в качестве дополнительных возможностей. 	Пример 1. Найдем ОШ-оценки для гамма-распределения с плотностью   (8)Плотность вероятности в формуле (8) определяется тремя параметрами a, b, c, где a>0, b>0. При этом a является параметром формы, b - параметром масштаба и с - параметром сдвига. Здесь ?(а) - одна из используемых в математике специальных функций, так называемая "гамма-функция", по которой названо и распределение, задаваемое формулой (8),	Как следует из явного вида плотности (8), логарифмическая функция правдоподобия имеет вид [16, с. 98]: а уравнения правдоподобия таковы:где	Ясно, что выписанная система нелинейных уравнений не имеет аналитического решения, в отличие от аналогичной системы для семейства нормальных распределений. Построим ОШ-оценки для задачи оценивания трех неизвестных параметров [17]. 	В качестве начальных оценок ?1(n) будем использовать оценки метода моментов (см. пункт 2.2.1):где  - выборочное среднее арифметическое, s2 - выборочная дисперсия, m3 - выборочный третий центральный момент. 	Матрица информации Фишера согласно [16, с.98] при a > 2 имеет вид     (9)	Вектор-столбец частных производных логарифма плотности вероятностиимеет координатыТаким образом, для получения sn(a*, b*, c*) необходимо вычислить две суммыи произвести еще несколько арифметических действий, число которых не зависит от объема выборки.	Одношаговые оценки an, bn, cn для параметров гамма-распределения вычисляют по формулегде I-1 - обратная матрица к матрице информации Фишера I, заданной формулой (9). Матрицу I-1 нетрудно рассчитать аналитически. Формулы для нахождения одношаговых оценок расписаны в [1]. Расчеты облегчает то обстоятельство, что для гамма-распределения вторая координата вектора sn(a*, b*, c*) тождественно равна 0, т.е. sn(2)(a*, b*, c*) ? 0.	При n > ? распределение вектора оценок (an, bn, cn) приближается трехмерным нормальным распределением с математическим ожиданием, равным вектору истинных значений параметров (a, b, c), и ковариационной матрицей I-1(an, bn, cn). На этом приближении основаны правила расчета доверительных границ для параметров гамма-распределения [1]. Дисперсии оценок неизвестны, но зато имеются известные статистику зависимости этих дисперсий от параметров гамма-распределения. Эти зависимости непрерывные. Они стоят на главной диагонали ковариационной матрицы I-1(an,bn, cn). Поэтому можно вместо неизвестных параметров подставить в них оценки этих параметров и на основе принципа наследования сходимости (глава 1.4 выше) получить состоятельные оценки дисперсий. Затем на основе оценок дисперсий обычным образом строятся доверительные интервалы для параметров гамма-распределения. 	В табл.1 приведены результаты реализации описанной выше схемы расчетов - точечные и интервальные (при односторонней доверительной вероятности 0,95) оценки параметров гамма-распределения для данных, содержащихся в табл.2 предыдущего пункта 2.2.1.Таблица 1.Одношаговые оценки и доверительные границы для параметров гамма-распределения ?ПараметрОдношаговая оценкаВерхняя довери-тельная границаНижняя довери-тельная граница??Формы7,3216,41-1,77??Масштаба8,7715,242,30??Сдвига- 11,4623,28- 46,20?	Приведенные в табл.1 данные получены на основе асимптотических формул. Из-за конечности объема выборки необходимо внести некоторые коррективы. Поскольку параметр формы всегда положителен, a > 0, то нижняя доверительная граница для этого параметра должна быть неотрицательна, следует положить aH = 0. Поскольку плотность гамма-распределения положительна только правее параметра с, то, очевидно, c < xmin = 9,00, верхняя доверительная граница для параметра сдвига должна быть заменена на cB = 9,00. 	Может ли параметр сдвига быть отрицательным в данной прикладной задаче? Отрицательность параметра сдвига означает, что с положительной вероятностью рассматриваемая случайная величина отрицательна. Т.е. наработка резца до предельного состояния отрицательна. Ясно, что такого быть не может, хотя для специалиста по математической статистике отрицательность параметра сдвига вполне приемлема. Однако специалист по прикладной статистике должен признать неотрицательность параметра с при обработке данных, составляющих рассматриваемую выборку. Следовательно, нижнюю доверительную границу для параметра сдвига необходимо заменить на сн = 0.	Как следует из проведенных выше рассуждений и выкладок (см. также [16, с.98-100]), отношение дисперсий оценок метода моментиов и ОШ-оценок имеет видпри больших а. Это отношение, как и должно быть из общих соображений, всегда меньше 1. Отношение дисперсий возрастает при  приближении к 0 коэффициента асимметрии распределения. Если a > 39,1 (коэффициент асимметрии меньше 0,102), то эффективность оценки метода моментов превышает 80%. При а = 20 (коэффициент асимметрии 0,20) она равна 65%. Напомним, что при безграничном росте параметра формы а гамма-распределение приближается к нормальному, для которого оценки метода моментов и ОМП совпадают, а потому имеют равные дисперсии. Поэтому вполне естественно, что отношение дисперсий в формуле (10) стремится к 1 при безграничном росте параметра формы а.	Хотя дисперсии оценок метода моментов, как правило, меньше, чем дисперсии НАН-оценок, таких, как ОШО и ОМП, метод моментов играет большую роль в прикладной статистике. Во-первых, обычно их расчет проще (в частности, требует меньшего числа компьютерных операций), чем оценок других типов. К тому же оценки находятся с помощью выборочных моментов, которые, как правило, вычисляются на этапе описания статистических данных. Во-вторых, они служат основой для вычисления оценок других типов, например, ОШО. Для запуска итерационных методов нахождения ОМП также нужны начальные значения, и ими обычно являются оценки метода моментов. В-третьих, при учете погрешностей результатов наблюдений оценки метода моментов могут оказаться точнее ОМП и асимптотически эквивалентных им ОШО (см. главу 3.5 настоящего учебника). 	Методы оценивания параметров гамма-распределения и примеры расчетов для всех семи постановок, перечисленных в табл.1 пункта 2.2.1, приведены в [1]. Большинство из них основано на асимптотических (при n > ?) теоретических результатах прикладной статистики. Методом статистических испытаний (Монте-Карло) показано, что уже при  n > 10 используемые приближения удовлетворительны. Другими словами, асимптотической нормальностью оценок и другими важными для проведенных выше рассуждений предельными результатами можно пользоваться уже при  n > 10.	Алгоритмическое и программное обеспечение ОШ-оценок для распределения Вейбулла-Гнеденко и гамма-распределения рассмотрено в содержательной монографии [18]. История вопроса освещена в статье [14].2.2.3. Асимптотика решений экстремальных статистических задач	Если проанализировать приведенные выше в подразделе 2.1.5 постановки и результаты, касающиеся эмпирических и теоретических средних и законов больших чисел, то становится очевидной возможность их обобщения. Так, доказательства теорем практически не меняются, если считать, что функция f(x,y) определена на декартовом произведении бикомпактных пространств X и Y, а не на X2. Тогда можно считать, что элементы выборки лежат в Х, а Y - пространство параметров, подлежащих оценке. 	Обобщения законов больших чисел. Пусть, например, выборка х1 = х1(?),  х2 = х2(?), . , хn = хn(?) взята из распределения с плотностью p(x,y), где у - неизвестный параметр. Если положитьf(x,y) = - ln p(x,y),то задача нахождения эмпирического среднего переходит в задачу оценивания неизвестного параметра y методом максимального правдоподобия.Соответственно законы больших чисел переходят в утверждения о состоятельности этих оценок в случае пространств X и Y общего вида. 	При такой интерпретации функция f(x,y) уже не является расстоянием или показателем различия. Однако для доказательства сходимости оценок к соответствующим значениям параметров это и не требуется. Достаточно непрерывности этой функции на декартовом произведении бикомпактных пространств X и Y.	В случае функции f(x,y) общего вида можно говорить об определении в пространствах произвольной природы оценок минимального контраста и их состоятельности. При этом при каждом конкретном значении параметра у справедливо предельное соотношениегде f - функция контраста. Тогда состоятельность оценок минимального контраста вытекает из справедливости предельного перехода.Частными случаями оценок минимального контраста являются,   устойчивые (робастные) оценки Тьюки-Хубера (см. ниже), а также оценки параметров в задачах аппроксимации (параметрической регрессии) в пространствах произвольной природы. 	Можно пойти и дальше в обобщении законов больших чисел. Пусть известно, что при каждом конкретном y при безграничном росте n имеет быть сходимость по вероятностиfn(, y)  f(y),где fn(?, y) - последовательность случайных функций на пространстве Y, а f(y) - некоторая функция на У. В каких случаях и в каком смысле имеет место сходимостьArgmin {fn(, y), yX}  Argmin {f(y), y X}? Другими словами, когда из поточечной сходимости функций вытекает сходимость точек минимума? 	Причем здесь можно под n понимать натуральное число. А можно рассматривать сходимость по направленному множеству (подраздел 1.4.3), или же, что практически то же самое - "сходимость по фильтру" в смысле Картана и Бурбаки [19, с.118]. В частности, можно описывать ситуацию вектором, координаты которого - объемы нескольких выборок, и все они безгранично растут. В классической математической статистике такие постановки рассматривать не любят.	Поскольку, как уже отмечалось, основные задачи прикладной статистики можно представить в виде оптимизационных задач, то ответ на поставленный вопрос о сходимости точек минимума дает возможность единообразного подхода к изучению асимптотики решений разнообразных экстремальных статистических задач. Одна из возможных формулировок, основанная на бикомпактности пространств Х и У и нацеленная на изучение оценок минимального контраста, дана и обоснована выше. Другой подход развит в работе [20]. Он основан на использовании понятий асимптотической равномерной разбиваемости и координатной асимптотической равномерной разбиваемости пространств. С помощью указанных подходов удается стандартным образом обосновывать состоятельность оценок характеристик и параметров в основных задачах прикладной статистики. 	Рассматриваемую тематику можно развивать дальше, в частности, рассматривать аналоги законов больших чисел в случае пространств, не являющихся бикомпактными, а также изучать скорость сходимости Argmin{fn(x(), y), yX} к Argmin{f(y), y X}. 	Приведем примеры применения результатов о предельном поведении точек минимума.	Задача аппроксимации зависимости (параметрической регрессии). Пусть X и Y - некоторые пространства. Пусть имеются статистические данные - n пар (xk, yk), где xk  X, yk  Y, k = 1, 2, ., n. Задано параметрическое пространство ? произвольной природы и семейство функций g(x,?): XЧ? > Y. Требуется подобрать параметр ?  ? так. чтобы g(xk ,?) наилучшим образом приближали yk, k = 1, 2, ., n. Пусть fk - последовательность показателей различия в У. При сделанных предположениях параметр ? естественно оценивать путем решения экстремальной задачи:.		(1)	Часто, но не всегда, все fk совпадают. В классической постановке, когда Х = Rk, У = R1, функции fk различны при неравноточных наблюдениях, например, когда число опытов меняется от одной точки х проведения опытов к другой. 	Если fk(y1,y2) = f(y1,y2) = (y1- y2)2, то получаем общую постановку метода наименьших квадратов (см. подробности в главе 3.2):.	В рамках детерминированного анализа данных остается единственный теоретический вопрос - о существовании ?n. Если все участвующие в формулировке задачи (1) функции непрерывны, а минимум берется по бикомпакту, то ?n существует. Есть и иные условия существования ?n [20-22]. 	При появлении нового наблюдения х в соответствии с методологией восстановления зависимости рекомендуется выбирать оценку соответствующего у по правилуу* = g(x, ?n).Обосновать такую рекомендацию в рамках детерминированного анализа данных невозможно. Это можно сделать только в вероятностной теории, равно как и изучить асимптотическое поведение ?n, доказать состоятельность этой оценки. 	Кпк и в классическом случае, вероятностную теорию целесообразно строить для трех различных постановок. 	1. Переменная х - детерминированная (например, время), переменная у - случайная, ее распределение зависит от х. 	2. Совокупность (xk, yk), k = 1, 2, ., n, - выборка из распределения случайного элемента со значениями в ХЧУ.	3. Имеется детерминированный набор пар (xk0, yk0), k = 1, 2, ., n, результат наблюдения (xk, yk) является случайным элементом, распределение которого зависит от (xk0, yk0). Это - постановка конфлюэнтного анализа.	Во всех трех случаях ,однако случайность входит в правую часть по-разному в зависимости от постановки, от которой зависит и определение предельной функции f(?). 	Проще всего выглядит f(?) в случае второй постановки при fk ? f:f(?) = Mf(g(x1,?),y).В случае первой постановки в предположении существования указанного предела. Ситуация усложняется для третьей постановки:.	Во всех трех случаях на основе общих результатов о поведении решений экстремальных статистических задач можно изучить [20-22] асимптотику оценок ?n. При выполнении соответствующих внутриматематических условий регулярности оценки оказываются состоятельными, т.е. удается восстановить зависимость.	Аппроксимация и регрессия. Соотношение (1) дает решение задачи аппроксимации. Поясним, как эта задача соотносится с нахождением регрессии. Согласно [23] для случайной величины (?, ?) со значениями в ХЧУ регрессией ? на ? относительно меры близости f естественно назвать решение задачи Mf(g(?), ?) > ,		(2)где f: YЧY > R1, g: X > Y, минимум берется по множеству всех измеримых функций. 	Можно исходить и из другого определения. Для каждого хХ рассмотрим случайную величину ?(х), распределение которой является условным распределением ? при условии ? = х. В соответствии с определением математического ожидания в пространстве общей природы назовем условным математическим ожиданием решение экстремальной задачи.Оказывается, при обычных предположениях измеримости решение задачи (2) совпадает с . (Внутриматематические уточнения типа "равенство имеет место почти всюду" здесь опущены.) 	Если заранее известно, что условное математическое ожидание  принадлежит некоторому параметрическому семейству g(x,?), то задача нахождения регрессии сводится к оцениванию параметра ? в соответствии с рассмотренной выше второй постановкой вероятностной теории параметрической регрессии. Если же нет оснований считать, что регрессия принадлежит параметрическому семейству, то можно использовать непараметрические оценки регрессии. Они строятся с помощью непараметрических оценок плотности (см. главу 2.1).	Пусть ?1 - мера в Х, ?2 - мера в У, а их прямое произведение ? = ?1Ч?2 - мера в ХЧУ. Пусть g(x,y) - плотность случайного элемента (?,?) по мере ?. Тогда условная плотность g(y|x) распределения ? при условии ?=х имеет вид		(3)(в предположении, что интеграл в знаменателе отличен от 0). Следовательно,,а потому.	Заменяя g(x,y) в (3) непараметрической оценкой плотности gn(x,y), получаем оценку условной плотности.		(4)Если gn(x,y) - состоятельная оценка g(x,y), то числитель (4) сходится к числителю (3). Сходимость знаменателя (4) к знаменателю (3) обосновывается с помощью предельной теории статистик интегрального типа (см главу 2.3). В итоге получаем утверждение о состоятельности непараметрической оценки (4) условной плотности (3). 	Непараметрическая оценка регрессии ищется как.Состоятельность этой оценки следует из приведенных выше общих результатов об асимптотическом поведении решений экстремальных статистических задач. 	Применение к методу главных компонент. Исходные данные - набор векторов ?1, ?2, . , ?n, лежащих в евклидовом пространстве Rk размерности k. Цель состоит в снижении размерности, т.е. в уменьшении числа рассматриваемых показателей. Для этого берут всевозможные линейные ортогональные нормированные центрированные комбинации исходных показателей, получают k новых показателей, из них берут первые m, где m < k (подробности см. в главе 3.2). Матрицу преобразования С выбирают так, чтобы максимизировать информационный функционал,		(5)где x(i), i = 1, 2, . , k, - исходные показатели; исходные данные имеют вид ?j = (xj(1), xj(2), . , xj(k)), j = 1, 2, . , n; при этом z(?), ? = 1, 2, . , m, - комбинации исходных показателей, полученные с помощью матрицы С. Наконец, s2(z(?)), ? = 1, 2, . , m, s2(x(i)), i = 1, 2, . , k, - выборочные дисперсии переменных, указанных в скобках. 	Укажем подробнее, как новые показатели (главные компоненты) z(?) строятся по исходным показателям x(i) с помощью матрицы С:,где.Матрица C = ||c??|| порядка mЧk такова, что  		(6)(нормированность),		(7)(ортогональность).	Решением основной задачи метода главных компонент является ,где минимизируемая функция определена формулой (5), а минимизация проводится по всем матрицам С, удовлетворяющим условиям (6) и (7).	Вычисление матрицы Сn - задача детерминированного анализа данных. Однако, как и в иных случаях, например, для медианы Кемени, возникает вопрос об асимптотическом поведении Сn. Является ли решение основной задачи метода главных компонент устойчивым, т.е. существует ли предел Сn при n > ?? Чему равен этот предел? 	Ответ, как обычно, может быть дан только в вероятностной теории. Пусть ?1, ?2, . , ?n - независимые одинаково распределенные случайные вектора. Положим ,где матрица C = ||c??|| удовлетворяет условиям (6) и (7). Введем функцию от матрицы.Легко видеть, что при n > ? и любом С.Рассмотрим решение предельной экстремальной задачи.Естественно ожидать, что.Действительно, это соотношение вытекает из приведенных выше общих результатов об асимптотическом поведении решений экстремальных статистических задач. 	Таким образом, теория, развитая для пространств произвольной природы, позволяет единообразным образом изучать конкретные процедуры прикладной статистики.2.2.4. Робастность статистических процедур	Термин "робастность" (robustness - англ.) образован от robust - крепкий, грубый (англ.). Сравните с названием одного из сортов кофе - robusta. Имеется в виду, что робастные статистические процедуры должны "выдерживать" ошибки, которые теми или иными способами могут попадать в исходные данные или искажать предпосылки используемых вероятностно-статистических моделей. 	Термин "робастный" стал популярным в нашей стране в 1970-е годы. Сначала он использовался фактически как сужение термина "устойчивый" на алгоритмы статистического анализа данных классического типа (не включая теорию измерений, статистику нечисловых и интервальных данных). Затем реальная сфера его применения сузилась. 	Пусть исходные данные - это выборка, т.е. совокупность независимых одинаково распределенных случайных величин с одной и той же функцией распределения F(x). Наиболее простая модель изучения устойчивости - это модель засорения		(1)Эта модель имеются также моделью Тьюки - Хубера. (Джон Тьюки - американский исследователь, П. Хубер, или Хьюбер - швейцарский ученый.) Модель (1) показывает, что с близкой к 1 вероятностью, а именно, с вероятностью  наблюдения берутся из совокупности с функцией распределения  которая предполагается обладающей "хорошими" свойствами. Например, она имеет известный статистику вид (хотя бы с точностью до параметров), у нее существуют все моменты, и т.д. Но с малой вероятностью  появляются наблюдения из совокупности с "плохим" распределением, например, взятые из распределения Коши, не имеющего математического ожидания, резко выделяющиеся аномальные наблюдения, выбросы. 	Актуальность модели (1) не вызывает сомнений. Наличие засорений (выбросов) может сильно исказить результаты эконометрического анализа данных. Ясно, что если функция распределения элементов выборки имеет вид (1), где первое слагаемое соответствует случайной величине с конечным математическим ожиданием, а второе - такой, для которого математического ожидания не существует (например, если  H(x) - функция распределения Коши), то для итоговой функций распределения (1) также не существует математического ожидания. Исследователя обычно интересуют характеристики первого слагаемого, но найти их, т.е. освободиться от влияния засорения, не так-то просто. Например, среднее арифметическое результатов наблюдений не будет иметь никакого предела (это - строгое математическое утверждение, вытекающее из того, что математическое ожидание не существует [24]).	Существуют различные способы борьбы с засорением. Эмпирическое правило "борьбы с засорениями" при подведении итогов работы команды судей найдено в фигурном катании: наибольшая и наименьшая оценки отбрасываются, а по остальным рассчитывается средняя арифметическая. Ясно, что единичное "засорение" окажется среди отброшенных оценок. 	Оценивать характеристики и параметры, проверять статистические гипотезы, вообще осуществлять статистический анализ данных все чаще рекомендуют на основе эмпирических квантилей (другими словами, порядковых статистик, членов вариационного ряда), отделенных от концов вариационного ряда. Речь идет об использовании статистик вида,где a, b, c, d, e - заданные числа, x(0,1n), x(0,3n), x(0,5n), x(0,7n), x(0,9n) - члены вариационного ряда с номерами, наиболее близкими к числам, указанным в скобках. Так ценой небольшой потери в эффективности избавляемся от засоренности типа описанной в модели (1).	Вариантом этого подхода является переход к сгруппированным данным. Отрезок прямой, содержащий основную часть наблюдений, разбивается на интервалы, и вместо количественных значений статистик подсчитывает лишь, сколько наблюдений попало в те или иные интервалы. Особое значение приобретают крайние интервалы - к ним относят все наблюдения, которые больше некоторого верхнего порога и меньше некоторого нижнего порога. Любым методам анализа сгруппированных данных резко выделяющиеся наблюдения не страшны.	Можно поставить под сомнение и саму опасность засорения. Дело в том, что практически все реальные величины ограничены. Все они лежат на каком-то интервале - от и до. Это совершенно ясно, если речь идет о физическом измерении - все результаты измерений укладывается в шкалу прибора. По-видимому, и для иных статистических измерений наибольшие сложности создают не сверхбольшие помехи, а те засорения, что находятся "на грани" между "интуитивно возможным" и "интуитивно невозможным". Что же это означает для практики статистического анализа данных? Если элементы выборки по абсолютной величине не превосходят числа А, то все засорение может сдвинуть среднее арифметическое на величину  Если засорение невелико, то и сдвиг мал. Построена достаточно обширная и развитая теория, посвященная разработке и изучению методов анализа данных в модели (1). С ней можно познакомиться по монографиям [25-27]. К сожалению, в теории обычно предполагается известной степень засорения , а на практике эта величина неизвестна. Кроме того, теория обычно направлена на защиту от воздействий, якобы угрожающих из бесконечности (например, отсутствием математического ожидания), а на самом деле реальные данные финитны (сосредоточены на конечных отрезках). Все это объясняет, почему теория робастности, исходящая из модели (1), популярна среди теоретиков, но мало интересна тем, кто анализирует реальные технические, экономические, медицинские и иные статистические данные. Рассмотрим несколько более сложную модель. Пусть наблюдаются реализации  независимых случайных величин с функциями распределения  соответственно. Эта модель соответствует гипотезе о том, что в процессе наблюдения (измерения) условия несколько менялись. Естественной представляется модель малых отклонений функций распределений наблюдаемых случайных величин от некоторой "базовой" функции распределения . Множество возможных значений функций распределений наблюдаемых случайных величин (т.е. совокупность допустимых отклонений согласно общей схеме устойчивости, рассмотренной в главе 1.4) описывается следующим образом: 	Следующий тип моделей - это введение малой (т.е. слабой) зависимости между рассматриваемыми случайными величинами (см., например, монографию [28]). Ограничения на взаимную зависимость можно задать разными способами. Пусть  - совместная функция распределения n-мерного случайного вектора, F1(x1), F2(x2), . , Fn(xn) - функции распределения его координат. Если все координаты независимы, то  = F1(x1)F2(x2).Fn(xn). Пусть коэффициент корреляции между i-ой и j-ой случайными величинами - координатами вектора. Множество возможных совместных функций распределения (т.е. совокупность допустимых отклонений согласно общей схеме устойчивости, рассмотренной в главе 1.4) описывается следующим образом:Таким образом, фиксируются функции распределения координат, а коэффициенты корреляции предполагаются малыми (по абсолютной величине).	Есть еще целый ряд постановок задач робастности. Если накладывать погрешности непосредственно на результаты наблюдений (измерений) и предполагать лишь, что эти погрешности не превосходят (по абсолютной величине) заданных величин, то получаем постановки задач статистики интервальных данных (см. главу 3.5). При этом каждый результат наблюдения превращается в интервал - исходное значение плюс-минус максимально возможная погрешность. 	Разработано много вариантов робастных методов анализа статистических данных (см. монографии [5, 25-28]). Иногда говорят, что робастные методы позволяют использовать информацию о том, что реальные наблюдения лежат "около" тех или иных параметрических семейств, например, нормальных. В этом, дескать, их преимущество по сравнению с непараметрическими методами, которые предназначены для анализа данных, распределенных согласно произвольной непрерывной функции распределения. Однако количественных подтверждений этих уверений любителей робастных методов обычно не удается найти. В основном потому, что термин "около" трудно формализовать.	На примере различных подходов к изучению робастности статистических процедур оценивания и проверки гипотез видны сложности, связанные с изучением устойчивости. Дело в том, что для каждой конкретной статистической задачи можно самыми разными способами задать совокупность допустимых отклонений. Так, выше кратко рассмотрены четыре такие совокупности, соответствующие модели засорения Тьюки - Хубера, модели малых отклонений функций распределения, модели слабых связей и модели интервальных данных. 	В каждой из этих моделей общая схема устойчивости (глава 1.4) предлагает для решения целый спектр задач устойчивости. Кроме изучения свойств робастности известных статистических процедур можно в каждой из постановок находить оптимальные процедуры. Однако практическая ценность этих оптимальных процедур, как правило, невелика, поскольку в других постановках оптимальными будут уже другие процедуры. Литература1. ГОСТ 11.011-83. Прикладная статистика. Правила определения оценок и доверительных границ для параметров гамма-распределения. - М.: Изд-во стандартов, 1984. - 53 с. - Переиздание: М.: Изд-во стандартов, 1985. - 50 с. 2. Рао С.Р. Линейные статистические методы и их применения. - М.: Наука, 1968. - 548 с.3. Вентцель Е.С. Теория вероятностей. - М.: Наука, 1964. -576 с.4. Крамер Г. Математические методы статистики. - М.: Мир, 1975. - 648 с.5. Орлов А.И. Устойчивость в социально-экономических моделях. - М.: Наука, 1979. - 396 с.6. Лумельский Я.П. К вопросу сравнения несмещенных и других оценок // Прикладная статистика. - М.: Наука, 1983, С.316-319. 7. ГОСТ 11.010-81. Прикладная статистика. Правила определения оценок параметров и доверительных границ для биномиального и отрицательного биномиального распределений. - М.: Изд-во стандартов, 1982. - 32 с.8. Сатаров Г.А., Шмерлинг Д.С. Новая статистическая модель парных сравнений // Экспертные оценки в задачах управления. - М.: Изд-во Института проблем управления АН СССР, 1982. - С.67-79.9. Лапига А.Г. Многокритериальные задачи управления качеством: построение прогноза качества в балльной шкале // Заводская лаборатория. 1983. Т.49. № 7. С.55-59.10. Закс Ш. Теория статистических выводов. - М.: Мир, 1975. - 776 с.11. Бахмутов В.О., Косарев Л.Н. Использование метода максимального правдоподобия для оценки однородности результатов усталостных испытаний // Заводская лаборатория. 1986. Т.52. № 5. С.52-57.12. Резникова А.Я., Шмерлинг Д.С. Оценивание параметров вероятностных моделей парных и множественных сравнений // Статистические методы оценивания и проверки гипотез/ Межвузовский сборник научных трудов. - Пермь: Изд-во Пермского госуниверситета, 1984. - С.110-120.  13. Ибрагимов И.А., Хасьминский  Р.З. Асимптотическая теория оценивания. - М.: Наука, 1979. - 528 с. 14. Орлов А.И. О нецелесообразности использования итеративных процедур нахождения оценок максимального правдоподобия // Заводская лаборатория. 1986. Т.52. No.5. С.67-69.15. Боровков А.А. Математическая статистика / Учебное пособие для вузов. - М.: Наука, 1984. - 472 с.16. Кендалл М.Дж., Стьюарт А. Статистические выводы и связи. - М.: Наука, 1973. - 900 с.17. Орлов А.И., Миронова Н.Г. Одношаговые оценки для параметров гамма-распределения // Надежность и контроль качества. 1988. No.9. С.18-22.18. Петрович М.Л., Давидович М.И. Статистическое оценивание и проверка гипотез на ЭВМ. - М.: Финансы и статистика, 1989. - 191 с.19. Келли Дж. Общая топология. - М.: Наука, 1968. - 384 с.20. Орлов А.И. Асимптотика решений экстремальных статистических задач. - В сб.: Анализ нечисловых данных в системных исследованиях. Сборник трудов. Вып.10. - М.: Всесоюзный научно-исследовательский институт системных исследований, 1982. - С. 4-12.21. Орлов А.И. Общий взгляд на статистику объектов нечисловой природы. - В сб.: Анализ нечисловой информации в социологических исследованиях. - М.: Наука, 1985. С.58-92. 22. Орлов А.И. Некоторые неклассические постановки в регрессионном анализе и теории классификации. - В сб.: Программно-алгоритмическое обеспечение анализа данных в медико-биологических исследованиях. - М.: Наука, 1987. с.27-40.23. Орлов А.И. Статистика объектов нечисловой природы и экспертные оценки. - В сб.: Экспертные оценки / Вопросы кибернетики. Вып.58. - М.: Научный Совет АН СССР по комплексной проблеме "Кибернетика", 1979. С.17-33.24. Гнеденко Б.В. Курс теории вероятностей: Учебник. 7-е изд., исправл. - М.: Эдиториал УРСС, 2001.- 320 с.25. Смоляк С.А., Титаренко Б.П. Устойчивые методы оценивания: Статистическая обработка неоднородных  совокупностей. - М;: Статистика, 1980. - 208 с.26. Хьюбер П. Робастность в статистике. - М.: Мир, 1984. - 304 с.27. Хампель Ф., Рончетти Э., Рауссеу П., Штаэль В. Робастность в статистике. Подход на основе функций влияния. - М.: Мир, 1989. - 512 с.28. Эльясберг П.Е. Измерительная информация. Сколько ее нужно, как ее обрабатывать? - М.: Наука, 1983. - 208 с.Контрольные вопросы и задачи1. Чем задачи оценивания параметров распределения отличаются от задач оценивания характеристик распределения?2. С помощью метода линеаризации обоснуйте вид асимптотических дисперсий оценок метода моментов для параметров гамма-распределения (табл.3 подраздела 2.2.1).3. Почему одношаговые оценки предпочтительнее оценок максимального правдоподобия?4. Как связаны законы больших чисел в пространствах произвольной природы и утверждения об асимптотическом поведении решений экстремальных статистических задач?5. Как соотносятся параметрическая регрессия и непараметрическая регрессия?6. Сопоставьте различные постановки задач изучения робастности статистических процедур. Темы докладов, рефератов, исследовательских работ1. Квантильные оценки.2. Минимизация расстояния как способ построения оценок параметров.3. Одношаговые оценки параметров распределения Вейбулла-Гнеденко. 4. Оптимизационные постановки основных задач прикладной статистики.5. Роль функции влияния при изучении робастности в модели засорения Тьюки - Хубера.6. На основе четырех указанных в настоящем учебнике моделей сформулируйте новые постановки задач устойчивости статистических процедур. 