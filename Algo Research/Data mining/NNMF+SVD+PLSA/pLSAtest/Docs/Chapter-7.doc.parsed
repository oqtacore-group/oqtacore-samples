 Оценивание неизвестных параметров скрытой марковской модели фиксированной структуры 
Специфика применения принципа максимального правдоподобия для оценивания параметров в вероятностных моделях со скрытой случайной переменной 
Принцип максимального правдоподобия 

Специфика функции правдоподобия в моделях со скрытой случайной переменной 
Раздел 2.3.2 - полностью заданная модель скрытого и наблюдаемого процессов: 
, , , - априорная модель скрытого процесса (2), 
, , ,  для всех  - модель наблюдаемого процесса (3). 
Более общая ситуация - модель, определенная с точностью до параметров: 
	, ,  для всех , 	
	, , ,  для всех  и . 	
Маргинальная (частная) плотность распределения на множестве реализаций наблюдаемого процесса - функция правдоподобия относительно неизвестных значений параметров: 
	. 	(104)
Оценка максимального правдоподобия в предположении эргодичности пары процессов : 
	. 	(105)
Как правило, решение этой задачи оптимизации затруднительно. 
Идея EM-процедуры 
В пределах этого раздела мы будем рассматривать скрытый и наблюдаемый процессы с более общих позиций просто как пару случайных переменных , из которых одна понимается как скрытая, в данном случае , а вторая  как наблюдаемая. Предполагается, что их распределения заданы в терминах априорной плотности распределения скрытой переменной , зависящей от неизвестного параметра , и условной плотности распределения наблюдаемой переменной , содержащей другой неизвестный параметр . Эта пара случайных переменных характеризуется совместной плотностью распределения, зависящей от обоих неизвестных параметров: 
	. 	
Однако эту же совместную плотность можно выразить и по-другому - как произведение полной плотности распределения наблюдаемой переменной  и условной, в данном случае, апостериорной плотности распределения скрытой переменной : 
	. 	
Из этого равенства непосредственно следует, что полная плотность распределения наблюдаемой переменной выражается как отношение 
	. 	(106)
Заметим, что последнее равенство дает альтернативное выражение для функции правдоподобия (104). На первый взгляд это странное равенство - его правая часть содержит переменную , которой нет в левой части. Но эта странность легко объясняется - просто отношение в левой части не зависит от того, какое значение присвоено переменной  в пределах множества ее допустимых значений . В логарифмической форме функция правдоподобия запишется в следующем виде 
	 для всех . 	(107)
Именно эта форма представления функции правдоподобия лежит в основе достаточно общего принципа построения алгоритмов максимизации функции правдоподобия (105) в моделях данных, содержащих скрытую переменную, известного под названием EM-процедуры. 
Поскольку равенство (107) справедливо для любых значений , то для всякой функции , удовлетворяющей условию , справедливо также 
	 	
В частности, в качестве функции  можно принять апостериорную плотность распределения  для любых конкретных значений параметров  и : 
	 	
Мы уже можем приступить к построению итерационной процедуры максимизации логарифмической функции правдоподобия . Пусть  - очередное приближение к искомой точке минимума функции правдоподобия. Примем эти значения в качестве . Тогда для функции правдоподобия справедливо представление: 
	 	(108)
Рассмотрим новую пару значений , определяемых независимо друг от друга по правилу: 
	, 	(109)
	 	(110)
Теорема 4. Для двух пар значений параметров функции правдоподобия  и , соответствующих правилу (109)-(110), справедливо неравенство 
	, 	(111)
причем 
	, если  или . 	(112)
Доказательство. Запишем значение функции правдоподобия для обновленной пары значений параметров  согласно (108): 
	 	
Здесь в силу (109) и (110) 
	 	(113)
Очевидно также, что 
	 	(114)
Из (113) и (114) непосредственно следует (111). 



Исторический экскурс: алгоритм разделения смеси распределений М.И. Шлезингера 
Статья М.И. Шлезингера []. 
Смесь распределений: 
, , , - параметрическое семейство плотностей распределения вероятности в некотором пространстве . 
, , - конечное множество значений параметра. 
,  - вероятности этих значений, , . 
Наблюдаемая случайная переменная образуется следующим образом. Случайно выбирается индекс  в соответствии с вероятностями , затем случайная переменная  формируется в соответствии с плотностью распределения . Такая случайная переменная  называется смесью случайных переменных, определяемых плотностями  со смешивающими вероятностями . Плотность ее распределения есть линейная комбинация плотностей распределения смешиваемых случайных переменных с коэффициентами, равными смешивающим вероятностям: 
, где , . 

 - результаты  независимых испытаний смеси. Требуется оценить ее параметры  и . 

Плотность распределения результата  независимых испытаний: 
. 
Оценка максимального правдоподобия параметров смеси: 
 

Фактически мы имеем дело с двухкомпонентной случайной переменной , где  - скрытый случайный выбор типа распределения вероятностей,  - наблюдаемая реализация случайной переменной согласно этого распределения,  - номер наблюдения, который в данном случае не имеет смысла времени, поскольку порядок реализации независимых наблюдений не играет роли. 

Совокупность  независимых испытаний этой двухкомпонентной переменной образует двухкомпонентный "процесс"  с компонентами  и . 

В данном случае значения скрытого процесса  (типы распределений наблюдаемой переменной) в отдельных испытаниях независимы друг от друга и принадлежат конечному множеству . Множество всех реализаций скрытого процесса также конечно . Априорная плотность распределения на множестве реализаций скрытого процесса, определяемая неизвестными параметрами : 
, . 
Заметим, что это частный вырожденный случай марковского случайного процесса. 

Условная плотность распределения на множестве реализаций наблюдаемого процесса, определяемая неизвестными параметрами : 
. 

Апостериорная вероятность значения скрытого процесса  после наблюдения переменной : 
	,  . 	(115)
Апостериорное распределение на множестве реализаций скрытого процесса (множестве комбинаций типов распределения наблюдаемой переменной): 
 

Шаг EM-процедуры (109) и (110) в этом частном случае примет вид: 
	. 	(116)

	 	(117)

Преобразуем (116): 
 
Здесь сумма в квадратный скобках есть апостериорная вероятность того, что в наблюдении  скрытая переменная имела значение : 
	 	(118)
где 
. 
Значения апостериорных вероятностей  легко вычисляются согласно (115): 
	. 	(119)
Остается максимизировать (118) по  при ограничении . Функция Лагранжа: 
. 
Условия ее максимума по : 
 
Отсюда: 
. 
Из условия  следует, что . 
Итак, мы поучили выражения для очередных приближений к оценкам смешивающих вероятностей:
	,  . 	(120)

Аналогично, преобразуем (117): 
 
Получаем  независимых выражений для очередных приближений к оценкам параметров смешиваемых распределении: 
	. 	(121)

Что означает последнее выражение? Заметим, что если все наблюдения  получены как реализации распределения с одним и тем же значением параметра , то оценка максимального правдоподобия для этого единственного параметра определяется условием . Выражение (121) имеет аналогичную структуру, но в нем каждое значение наблюдаемой переменной  участвует с весом, численно равным апостериорной вероятности гипотезы, что это значение порождено -м распределением вероятности в составе смеси. 
Численная реализация EM-процедуры для некоторых моделей сигналов 
Скрытый процесс с конечным числом состояний 
Модель скрытого процесса с конечным числом состояний , изложенная в разделе 2, полностью определяется последовательностью матриц переходных вероятностей переходов ,  (42). Предположим, что скрытый марковский случайный процесс является однородным, т.е. что матрица переходных вероятностей остается неизменной  во все моменты времени . 
Ниже в разделе 8 мы покажем, что подход к оцениванию переходной матрицы скрытого марковского процесса  на основе принципа максимального правдоподобия является некорректным. Раздел, который мы сейчас изучаем, называется "Оценивание неизвестных параметров скрытой марковской модели фиксированной структуры", однако мы увидим разделе 8, что условные вероятности сохранения состояния скрытого процесса  характеризуют уже структуру модели, и оценивать их можно только с помощью специальных приемов. 

За очередным состоянием скрытого процесса  может следовать либо это же состояние  с вероятностью , либо одно из альтернативных состояний  с вероятностями . В невырожденном случае, т.е. если , в конце концов состояние  неизбежно будет заменено другим состоянием. Обозначим через  условную вероятность того, что таким состоянием будет . 
Очевидно, что . Нетрудно убедиться, что 
,   при . 
Отсюда следует, что . 
Если  и  Будем полагать, что

Будем полагать, что переходная матрица  известна. Заметим, что если переходные вероятности  не зависят от , т.е.  для всех , то скрытый процесс есть последовательность независимых состояний. 
Модель наблюдаемого процесса (43) для каждого скрытого состояния  будем считать заданной с точностью до неизвестного значения параметра: 
. 
Значения параметров  требуется оценить по достаточно длинной реализации наблюдаемого процесса . 
Состоятельное оценивание параметров случайного процесса по его единственной реализации возможно лишь в том случае, если этот процесс является эргодическим. В нашей модели условием эргодичности наблюдаемого процесса является эргодичность скрытой марковской цепи, которая понимается как независимость распределения вероятностей на множестве состояний  в "далекий" момент времени  от начального распределения вероятностей . Для марковской цепи с конечным множеством состояний необходимым и достаточным условием эргодичности является отсутствие в множестве ее состояний  поглощающих подмножеств , т.е. таких подмножеств, из которых "нет выхода":  для всех  и . 
Численная реализация EM-процедуры (110) выражается правилом 
, 
совершенно аналогичным правилу (121), полученным для задачи разделения смеси распределений, с той лишь разницей, что апостериорные вероятности  в данном случае являются интерполяционными вероятностями . 
Нормальный скрытый процесс в конечномерном линейном пространстве 
 (110)
 (64) 
 (63)
У нас: 
 
 
 
 

 

 

 
 

 

Здесь 
. 

 

 

. 

Сегментация шумоподобного сигнала с повторяющимся характером колебаний как пример оценивания параметров модели сигнала 



 ----------------------------
 






 1

 
 59

 
 39

 
 7

 

  .	Шлезингер М.И. О самопроизвольном различении образов. Читающие автоматы, Киев, Наукова думка, 1965, с. 38-45. 



























