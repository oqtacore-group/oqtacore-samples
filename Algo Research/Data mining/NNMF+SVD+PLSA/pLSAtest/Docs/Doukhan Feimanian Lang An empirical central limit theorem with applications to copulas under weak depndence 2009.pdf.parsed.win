
An Empirical Central Limit Theorem with applications to copulas under weak dependence Paul Doukhan (doukhan@ensae.fr) ENSAE-CREST, J120, 3 Av. Pierre Larousse, 92245 Malakor Cedex and SAMOS, Universit
e Paris 1, Centre Pierre Mendues, 90 rue de Tolbiac, F-75634, Paris Cedex 13, France. Jean-David Fermanian (fermania@ensae.fr) CREST, J320, 15 bd Gabriel P
eri, 92245 Malakor Cedex, France. Gabriel Lang (Corresponding author.) (lang@engref.fr) GRESE, ENGREF, 19 av du Maine 75732 Paris Cedex 15, France. Abstract. We state a multidimensional Functional Central Limit Theorem for weakly dependent random vectors. We apply this result to copulas. We get the weak convergence of the empirical copula process and of its smoothed version. The ?nite dimensional convergence of smoothed copula densities is also proved. A new de?nition and the theoretical analysis of conditional copulas and their empirical counterparts are provided. Keywords: Copulas, multivariate FCLT, weak dependence. AMS classi?cation (2000): 62M10, 62G07, 60F17 1. Introduction This paper is devoted to asymptotic results relative to the empirical process for weakly dependent sequences. Various de?nitions of weak dependence have been introduced in the literature. Among them, r- mixing and ?-mixing have been developped, but these notions are not fully satisfactory, as they are de?ned with respect to ?ltrations and di±cult to check in practice. Doukhan and Louhichi [11] introduce a de?nition of weak dependence that is easier to check on various exam- ples of stationary processes (see Doukhan [8]). Various applications and developments of weak dependence are addressed in Ango Nze, BAuhlmann and Doukhan[2] and Ango Nze and Doukhan [1]. The general notion of weak dependence corresponds to the following idea. Consider two ?nite samples with time indices P in the past and in the future F, separated by a gap r. The independence of P and F is equivalent to cov(f(F); g(P)) = 0 for a suitable class of measurable functions. A natural way to weaken this condition is to provide a precise control of these covariances as the gap r becomes larger, and to ?x the 'c 2009 Kluwer Academic Publishers. Printed in the Netherlands. copulas_SISP3.tex; 6/03/2009; 11:29; p.1
2 P. Doukhan, J.-D. Fermanian and G. Lang rate of decrease of the control as r tends to in?nity. Moreover the class of functions will be reduced to Lipschitz functions to make the weak dependence condition easy to check for a wide class of models. Section 2 introduces the de?nition of weak dependence, provides examples and the functional central limit theorem for the multivariate empirical process. Section 3 is devoted to applications of the main theorem to copulas processes. The last section contains the proofs. 2. De?nitions and main result 2.1. Weak dependence We state here the de?nition of weak dependence that is used in the paper and a re?nement of it. De?ne the Lipschitz modulus of a real function h on a space Rd as Lip (h) = sup x6=y jh(x) ! h(y)j kx ! yk1 ; where kxk1 = k(x1; : : : ; xd)k1 = Pdi=1 jxij. De?ne ¤(1) as the set of functions that are bounded by 1 and have a ?nite Lipschitz modulus. Declare two sequences of indices i1 - ? ? ? - iu and j1 - ? ? ? - jv as r-distant if iu - j1 and j1 ! iu = r. De?nition 1. [Doukhan & Louhichi, 1999)] Let ? = (?r)r?0 (resp. u = (ur)r?0) be a real positive sequence that tends to zero. We say that the d-dimensional process ("i)i2Z is ?-dependent (resp. u-dependent) if, for any r-distant ?nite sequences i = (i1; : : : ; iu) and j = (j1; : : : ; jv), for any functions f and g in ¤(1) de?ned on (Rd)u and (Rd)v respectively, we have jcov(f("i1 ; : : : ; "iu); g("j1 ; : : : ; "jv ))j - (uLip f + vLip g)?r; (1) jcov(f("i1 ; : : : ; "iu); g("j1 ; : : : ; "jv ))j - vLip gur: (2) Remark 1. The u-dependence condition corresponds to causal pro- cesses and is more restrictive that ?-dependence; note that ?r - ur: Mathematical advantages of u-dependence are presented in Dedecker and Doukhan [5]. The forthcoming examples will make clear the direr- ences between the two notions. Remark 2. Note that if " is ?-dependent and if f and g are bounded Lipschitz functions, the previous covariance is bounded by (uLip (f)kgk1 + vkfk1Lip (g)) ?r. copulas_SISP3.tex; 6/03/2009; 11:29; p.2
Copulas for weakly dependent processes 3 2.2. Examples. 1. Stable Markov processes. Consider ?rst stationary sequences satisfying a recurrence equation Xn = F(Xn!1; : : : ;Xn!d; "n) where the sequence ("n) is iid. In this case Yn = (Xn; : : : ;Xn!d+1) is a Markov chain such that Yn = M(Yn!1; "n) with M(x1; : : : ; xd; ") = (F(x1; : : : ; xd; "); x1; : : : ; xd!1): Consider a norm k ? k on Rd, then we set kZkm = (EkZkm)1=m for m ? 1 for any Rd-valued random variable Z. Stationarity follows from Du'o's Theorem 1.IV.24 [16] if kF(0; ")km < 1 and kF(x; ")!F(y; ")km - akx!yk for some real 0 - a < 1 and m ? 1. Here u-dependence holds with ur = O(ar=d)(hence ?r = O(ar=d) too) (as r " 1) for the following examples: ! Functional AR models: Xt = r(Xt!1; : : : ;Xt!d)+"t if k"0km < 1and jr(u1; : : : ; ud)!r(v1; : : : ; vd)j - Pdi=1 aijui!vij for some a1; : : : ; ad ? 0 with Pdi=1 ai < 1. ! Branching processes models. Here d = 1; and D ? 2. Set "t = 3"(1) t ; : : : ; "(D) t ?. Let now A1(u); : : : ;AD(u) be Lipschitz functions (with u 2 R), and for (u; z(1); : : : ; z(D)) 2 RD+1 let M 3u; 3z(1); : : : ; z(D)?? =XD j=1 Aj(u)z(j): Lm!stationarity holds if a = PDj=1 Lip (Aj)k"(j) 0 km < 1: The following examples are not necessarily Markov models. 2. Bernoulli shifts. Let H : RZ ! Rd be a measurable function. If the sequence ("n)n2Z is independent and identically distributed on the real line, a Bernoulli shift with innovation process ("n)n2Z is de?ned as Xn = H (("n!i)i2Z) ; n 2 Z: A simple case of in?nitely dependent Bernoulli shift is the moving average process, where the function H corresponds to a series. Assume that there exists a control of the functional dependence to the tail variables, i.e. a sequence ±r decreasing to zero such that: E''H ("j ; j 2 Z) ! H !"j1jjj-r; j 2 Z?''- ±r: (3) copulas_SISP3.tex; 6/03/2009; 11:29; p.3
4 P. Doukhan, J.-D. Fermanian and G. Lang where k?k is a norm on Rd. Then the process is ?!weakly dependent with ?r - 2±[r=2], see Doukhan & Louhichi [11]. If H (xj ; j 2 Z) does not depend on the xj 's with j < 0, then the process is causal and u-dependence holds with ur = ±r. A ?rst example is a Volterra stationary process de?ned through a convergent Volterra expansion Xt = v0 + 1Xk=1 Vk;t; Vk;t = X !1<i1<???<ik<1ak;i1;:::;ik"t!i1 ? ? ? "t!k where v0 denotes a constant and (ak;i1;:::;ik )(i1;:::;ik)2Zk are real num- bers for each k ? 1. This expression converges in Lm for m ? 1, pro- vided that Ej"0jm < 1 and P1k=1Pi1<???<ik jak;i1;:::;ik j < 1. Those models are ?-dependent since (3) is satis?ed, ±r corresponding to the tail of the previous series. The following examples illustrate this general class of models. 3. LARCH(1) models. A vast literature is devoted to the study of conditionally heteroscedastic models. A simple equation in terms of a vector valued process allows a uni?ed treatment of those models, see [15]. Let ("t)t2Z be an iid sequence of random d ? D-matrices, (Aj)j2N¤ be a sequence of D?d matrices, and a be a vector in RD. A vector valued LARCH(1) model is a solution of the recurrence equation Xt = "t0@a + 1Xj=1AjXt!j1A (4) We provide below su±cient conditions for the following chaotic expansion Xt = "t0@a + 1Xk=1 X j1;:::;jk?1Aj1"t!j1Aj2 ? ? ?Ajk"t!j1!???!jka1A (5) Such LARCH(1) models include a large variety of models, as ! Standard LARCH(1) models, correspond to the case of real valued Xt and aj . ! Bilinear model Xt = 3t 3r +P1j=1 rjXt!j?+?+P1j=1 ?jXt!j where the variables are real valued and 3t is the innovation. For this, we set "t = u 3t 1 
; a = u r? 
 and Aj = u rj ?j 
. Expansion (5) coincides with the chaotic expansion in [22]. copulas_SISP3.tex; 6/03/2009; 11:29; p.4
Copulas for weakly dependent processes 5 ! GARCH(p; q) models, ? rt = ?t"t ?2t = Ppj=1 ?j?2t!j + ' +Pqj=1 'jr2t!j where ' > 0, 'i ? 0, ?i ? 0 (and the variables " are centered at expectation); this model is a special case of the bilinear model with r0 = '0 1!P?i et Prizi = P'izi 1!P?izi (see [22]). ! ARCH(1) processes are given by equations, ? rt = ?t"t ?2t = ?0 +P1j=1 ?j?2t!j One sets "t = ! "t 1 ?, a = u -?0 ?1?0 
, Aj = u -?j ?1?j 
 with ?1 = E("20), -2 = Var ("20). Endow the sets of matrices with a norm k?k of algebra, derived from a norm for linear applications. Assume that ¤ = k"0kmPj?1 kAjk < 1 then one stationary of solution of eqn. (4) in Lm is given as (5). The solution (5) of eqn. (4) is u!weakly dependent with ur = AEk"0kXr!1 k=1 k¤k!1R3rk? + ¤r 1 ! ¤!Ek"0kkak; where R(x) = Pj?x kajk. There exists some constant K > 0 and b;C > 0 such that ur - ( K(log(r))b_1 rb ; under Riemaniann decay A(x) - Cx!b; K(q _ ¤)pr; under geometric decay A(x) - Cqx: 4. Non-causal LARCH(1) model. Now Aj is de?ned for j 6= 0. Doukhan, Teyssiuere and Winant (2005) prove the same results of existence as for the previous causal case (replace summation for j > 0 by summation for j 6= 0) and the process is now ?-weakly dependent with ?r = 0@k"0k1 X 0-2k<r k¤k!1R3 r 2k? + ¤r=2 1 ! ¤1AEk"0kkak where now R(x) = Xjjj?x kajk; ¤ = k"0k1Xj?1 kAjk < 1: copulas_SISP3.tex; 6/03/2009; 11:29; p.5
6 P. Doukhan, J.-D. Fermanian and G. Lang Here we need the restrictive assumption that innovations are uni- formly bounded. 2.3. Multivariate empirical central limit theorem The main theoretical result of the paper is a functional central limit theorem for ?-dependent vector-valued sequences (Xi)i2Z. It is an ex- tension of the independent case, where the limit process in the space of cuadluag functions D([0; 1]d) endowed with the Skorohod metric dS is known to be a multivariate Brownian bridge B0, i.e. a Gaussian process with covariance function cov(B0(x); B0(y)) = P (X0 - x ^ y) ! P(X0 - x)P(X0 - y); (6) for every vectors x and y in [0; 1]d. Here the order relation in [0; 1]d is partial : x - y if it holds for every coordinates and x ^ y = (xi ^ yi)i=1;:::;d. In the case of weak dependence, the limiting distributions are not free of the distribution's process. In this section, Y is a process with uniform marginal distributions and cdf F. We denote the empirical cdf: Fn(x) = n!1Xn i=1 1fYi;1 - x1; : : : ; Yi;d - xdg; (7) and de?ne the normalized empirical process Bn = pn(Fn ! F) asso- ciated with Y. Consider a centered Gaussian process B such that, for any vectors u and v in Rd, cov(B(u); B(v)) =Xi2Z cov (1fY0 - ug; 1fYi - vg) : (8) Note that the previous covariance structure depends on the joint dis- tribution of Y0 and Yi, for every i. We consider a dependence relation based on the covariance of some indicator functions. The link with the weak dependence is given in Lemma 2.1. De?nition 2. Let f be a function on Ru, i = (i1; : : : ; iu) be a sequence of elements in Z and s = (s1; : : : ; su) be a sequence of elements in [0; 1]d. With implicit reference to a process Y, we de?ne Z(f; i; s) = f(1fYi1 - s1g; : : : ; 1fYiu - sug): De?ne a¤d := d + p1 + d2: The main result of the paper is the following: copulas_SISP3.tex; 6/03/2009; 11:29; p.6
Copulas for weakly dependent processes 7 Theorem 1. Assume that (Yi)i2Z is a centered process with uniform marginal distributions such that for any r-distant ?nite sequences i = (i1; : : : ; iu) and j = (j1; : : : ; jv), for any functions f and g in ¤(1), de?ned on Ru and Rv: jcov(Z(f; i; s);Z(g; j; t))j - (uLip f + vLip g)?r: (9) Assume that there exist some constants C > 0 and a > a¤d such that ?r - Cr!a. Then Bn tends to B in distribution in D([0; 1]d; dS). See the proof in section 4. The following lemma is essential to apply theorem 1. Lemma 2.1. If (Yi)i2Z is ?-dependent (with dependence coe±cients ?Y;r), then condition (9) is satis?ed with ?r = 3(?Y;rd) 12 . Proof. De?ne 2-approximations of 1fx ? tg by h2;t(x) = Yd p=1 (x(p) ! t(p) + 2) 2 1ft(p) ! 2 < x(p) < t(p)g + 1fx ? tg: Then h2;t(x) is 1=2-Lipschitz, and Ekh2;t(Y0) ! 1fY0 ? tgk1 - 2d. De?ne the analogous approximation of Z(f; i; s) by Z2(f; i; s) = f(h2;s1(Y1); : : : ; h2;su(Yu)): Let f, g be in ¤(1) and set for short, A = uLip f + vLip g. Then jE(Z2(f; i; s)Z2(g; j; t)) ! E(Z(f; i; s)Z(g; j; t))j - kZ2(f; i; s)k1 Ek(Z2(g; j; t) ! Z(g; j; t))k1 + kZ(g; j; t)k1 Ek(Z2(f; i; s) ! Z(f; i; s))k1 - (vLip (g) + uLip (f))2d - A2d: Similarly, jE(Z2(f; i; s))E(Z2(g; j; t)) ! E(Z(f; i; s))E(Z(g; j; t))j - A2d: (10) As Y is ?-weak dependent with dependence coe±cients ?Y;r, for any r-distant sequences i and j, jcov(Z2(f; i; s);Z2(g; j; t))j - 2!1A?Y;r: Choosing 2 such that ?Y;r2!1 = 2d, we get jcov(Z(f; i; s);Z(g; j; t))j - 3A ? (?Y;rd)1=2: Several applications of theorem 1 are provided by a direct appli- cation of the functional delta-method. We shall consider below the empirical and the smoothed copula processes. copulas_SISP3.tex; 6/03/2009; 11:29; p.7
8 P. Doukhan, J.-D. Fermanian and G. Lang 3. Applications to copula processes 3.1. Empirical copula processes Copulas describe the dependence structure between some random vec- tors. They have been introduced a long time ago (Sklar [30]) and have been rediscovered recently, especially for their applications in ?nance and biostatistics. Brie'y, a d-dimensional copula is a cdf on [0; 1]d whose marginal distributions are uniform. It summarizes the dependence structure independently of the speci?cation of the marginal distributions. Consider a random vector X = (X1; : : : ;Xd) whose joint cdf is F and whose marginal cdfs' are denoted by Fj , j = 1; : : : ; d. Then there exists a unique copula C de?ned on the product of the values taken by the r.v. Fj(Xj ), such that C(F1(x1); : : : ; Fd(xd)) = F(x1; : : : ; xd); for any x = (x1; : : : ; xd) 2 Rd. C is called the copula associated with X. When F is continuous, C is de?ned on [0; 1]d. If F is discontinuous, there are several choices to extend C to [0; 1]d (see Nelsen [25] for a complete theory). Let (Xi)i2Z be a vector valued stationary process. The distribution of Xi is independent of i and we denote by C its copula which we shall estimate nonparametrically. For example, in the study a real valued stationary Markov sequence (Zi)i2Z, one may consider the vector Xi = (Zi;Zi+1;Zi+2), as in Chen and Fan [4]. The empirical copula is de?ned by Cn(u) = Fn(F!1 n;1 (u1); : : : ; F!1 n;d(ud)); for every u1; : : : ; ud in [0; 1]. As usual, we denote the empirical cdfs' Fn;j(xj) = n!1Xn i=1 1fXi;j - xjg; j = 1; : : : ; d; (11) and we use the usual generalized inverse notations, for every univariate cdf G, G!1(u) = infftjG(t) ? ug: In the i.i.d. framework the consistency of Cn and the limiting be- havior of n1=2(Cn ! C) are obtained by Deheuvels ([6], [7]) under the strong assumption of independence between marginals; Gaensler and Stute [20] and Fermanian et al. [17] get rid of this restriction. Theo- rem 1 applied to Yi = (F1(Xi;1); : : : ; Fd(Xi;d)) yields the extension to dependent data: copulas_SISP3.tex; 6/03/2009; 11:29; p.8
Copulas for weakly dependent processes 9 Theorem 2. If (Yi)i2Z is ?-dependent, ?n = O(n!a), a > a¤d, if C has continuous ?rst partial derivatives, then n1=2(Cn ! C) ! G in (D([0; 1]d); dS); the Gaussian limit has continuous sample paths: G(u) = B(u) !Xd j=1 @C @uj (u)B(vj); (12) here vj 2 [0; 1]d is the vector with components equal to 1 excepted for the j-th, equal to uj . The proof is based on our FCLT, theorem 1, for multivariate weakly dependent sequences. Note that the covariance structure of n1=2(Cn ! C) relies on both (12) and (8). Remark 3. The same result applies for sequences such that multivari- ate FCLT holds. We thus quote that theorem 2 still holds under mixing conditions (see examples in Doukhan [9]): 2 for stationary strongly mixing sequences, if rn = O(n!a) for some a > 1; we use Rio [27]'s empirical CLT for vector-valued sequences. 2 in the absolutely regular case Doukhan, Massart and Rio [13]'s result yields assumption ?n = O!n!1 log!b n? for some b > 2. Other results yielding FCLT are recalled in [8]. In practice, smoothed copulas are prefered for graphical represen- tation. Nonparametric estimation is often the ?rst step before a para- metric modelisation. For optimization purposes, estimates of the deriva- tives of underlying copulas are useful, e.g for portfolio optimization in a mean-variance framework (Markowitz [24]) or with respect to any other risk measure, estimation of the sensitivities of Value-at-Risk or Expected Shortfall with respect to notional amounts (Gouri
eroux et al. [23] or Scaillet [29]). The smoothed empirical ^ Fn the copula processes in d dimensions writes as: ^ Fn(x) = Z K((x ! v)=h) Fn(dv) associated with the usual empirical process Fn (see equation 7), where K is the primitive function of a d-dimensional kernel k subject to the limit condition lim!1K = 0, and where h = hn is a bandwidth. More precisely, R k = 1, hn > 0, and hn ! 0 when n ! 1. Similarly, the j-th marginal cdf Fj is estimated nonparametrically by ^ Fn;j(xj) = Z Kj((xj ! vj)=h) Fn;j(dvj); copulas_SISP3.tex; 6/03/2009; 11:29; p.9
10 P. Doukhan, J.-D. Fermanian and G. Lang where Kj is the primitive function of a univariate kernel kj . We assume for simplicity that the bandwidth h is the same for every marginal and that k(u1; : : : ; ud) = Qdj=1 kj(uj ). Then, for every u 2 [0; 1]d, the smoothed empirical copula process writes as: ^ C(1) n (u) = ^ Fn 3 ^ F!1 n;1 (u1); : : : ; ^ F!1 n;d(ud)? ; or by smoothing directly the process Cn, ^ C(2) n (u) = Z K((u ! v)=h)Cn(dv): As in the i.i.d. case, the uniform distance between empirical pro- cesses and smoothed empirical processes is oP (n!1=2) under some reg- ularity conditions. To prove this result, we need some technical assump- tion on the kernels: Assumption (K). Assume k is p times continuously direrentiable, and: 2 k is compactly supported, or 2 there exists a sequence of positive real numbers an such that hnan tends to zero when n ! 1, and n1=2 Zfkvk>ang jk(v)j dv !! 0: Moreover, we need: Lemma 3.1. Assume (K) and (i) the process n1=2(Fn ! F) is stochastically equicontinuous, (ii) kE ^ Fn ! Fk1 = o(n!1=2), (iii) nh2p ! 0. Then k ^ Fn ! Fnk1 = oP (n!1=2): See the proof in section 4. Assumption (i) is satis?ed when X is compactly supported, invoking theorem 1. We get assumption (ii) by assuming some regularity on F, e.g. F is p-times continuously direr- entiable. Therefore, folllowing the proof of theorem 10 in Fermanian et al. [17], we get: Theorem 3. Assume (K) and 2 the process n1=2(Fn ! F) is stochastically equicontinuous, copulas_SISP3.tex; 6/03/2009; 11:29; p.10
Copulas for weakly dependent processes 11 2 (Yi)i2Z is ?-dependent, ?n = O(n!a), a > a¤d, 2 F is p-times continuously direrentiable, 2 nh2p ! 0. Then n1=2( ^ C(1) n ! C) ! G in (D([0; 1]d); dS). This result extends for weakly dependent processes the result on ?nite dimensional distributions in Fermanian and Scaillet [18]. More- over, we can prove lemma 3.1 replacing Fn by Cn exactly by the same ways. Hence (see theorem 11 in [17]): Theorem 4. Assume (K) and 2 (Yi)i2Z is ?-dependent, ?n = O(n!a), a > a¤d, 2 C is p times continuously direrentiable, p ? 1, 2 nh2p n ! 0. Then k ^ C(2) n ! Cnk1 = oP (n!1=2): Hence n1=2( ^ C(2) n ! C) ! G in (D([0; 1]d); dS). 3.2. Weak convergence of kernel copula densities The limit of copulas is not distribution-free. This is why we also ad- dress the question of copulas densities. They are discussed in a semi- parametric framework (section 3.2). In this case, limit laws of their ?nite distributions are asymptotically Gaussian and distribution-free, after a normalization. Assume each marginal law of the random vector X, say the j-th, belongs to a parametric family fFj(?juj); uj 2 ?jg, j = 1; : : : ; d. The true parameter is denoted by u0j and the true cdf by Fj(?ju0j ) (or simpler Fj ). Usually, marginal dsitributions are im- posed by users, that like to put their commonly used univariate models into multivariate ones. Thus, we assume the parameters u01; : : : ; u0d are consistently estimated by ^u1; : : : ; ^ud. For convenience, denote ^ Fj(?) = Fj(?j^uj) (in this section us only refer to parameters!). The semipara- metric copula process is ^ C(u) = 1nXn i=1 Yd k=1 1fFk(Xi;kj^uk) - ukg: By smoothing this empirical copula process, we get an estimate of the copula density. The key point is that the asymptotic law of this copulas_SISP3.tex; 6/03/2009; 11:29; p.11
12 P. Doukhan, J.-D. Fermanian and G. Lang statistics is far simpler than G. For each index i the d-dimensional vectors we set Yi = (F1(Xi;1); : : : ; Fd(Xi;d)) and ^Yi = ( ^ F1(Xi;1); : : : ; ^ Fd(Xi;d)): Assume that the law of the vectors Yi has a density ? with respect to the Lebesgue measure on Rd. The kernel estimator of a copula density ? at point u is thus ^? (u) = 1 hd Z K uu ! v h 
 ^ C(dv) = 1 nhdXn i=1 K Au ! ^Yi h !; (13) where K is a d-dimensional kernel and h = hn is a bandwidth sequence. As usual, we denote Kh(?) = K(?=h)=hd. For convenience, we will assume Assumption (K0). The kernel K is the product of d univariate even compactly supported kernels Kr, r = 1; : : : ; d. It is assumed pK- times continuously direrentiable. As previously, these assumptions are far from minimal. Particularly, we could consider some multivariate kernels whose support is the whole space Rd, if they tend to zero \su±ciently quickly" when their argument tends to the in?nity (for instance, at an exponential rate, like for the Gaussian kernel). As usual, the bandwidth sequence needs to tend to zero not too quickly. Assumption (B0). When n tends to the in?nity, nh4+d ! 1. Assumption (T0). Denoting by V(u0) an open neighborhood of u0, for every j = 1; : : : ; d, there exists a measurable function Hj s.t. sup u2V(u0) k@2ujujFj(Xj juj)k < Hj(Yj) a:e:; E[Hj(Yj )] < 1: Moreover, ? and every density of (Y0;Yk) are bounded in sup-norm, uniformly with respect to k 2 Z. Assumption (E). For every j = 1; : : : ; d, ^uj ! u0j = n!1Aj(u0j )!1 Xn i=1 Bj(u0j ; Yi;j) + oP (rn); (14) and rn tends to zero quicker than n!1=2h1!d=2 when n tends to the in?nity. Here, Aj(u0j ) denotes a positive de?nite non random matrix and Bj(u0j ; Yj) is a random vector. Moreover, E[Bj(u0j ; Yj )] = 0 and E[kBj(u0j ; Yj)k2] < 1. Typically, Bj(u; ?) is a score function. It can be proved these assumptions are satis?ed particularly for the usual maximum likelihood estimator, or more generally by M-estimators. copulas_SISP3.tex; 6/03/2009; 11:29; p.12
Copulas for weakly dependent processes 13 To invoke Doukhan and Coulhon-Prieur [14], who state the result for the usual kernel density estimates, we need the assumption: Assumption (Y). The process (Yi)i2Z is stationary and ?-dependent, with ?n = O(n!a). The densities of the couples (Y0;Yk) are uniformly bounded with respect to k ? 0. Moreover the window width is assumed to satisfy nhd? n ! 1 as n ! 1 and a > 2 + 1d + ?. Thus: Theorem 5. Under (K0) with pK = 2, (B0), (T0), (E) and (Y), for every m and every vectors u1; : : : ; um in ]0; 1[d such that ? (uk) > 0 for every k, we have pnhd ((^? ! Kh ¤ ? )(u1); : : : ; (^? ! Kh ¤ ? )(um)) !! n!1N(0; :); where : is diagonal, and its k-th diagonal term is ? 2(uk) R K2. Such a result can be used to prove some GOF tests, exactly as in Fermanian [19]. Remark 4. We also derive the convergence pnhd(b? (x) ! Eb? (x)) !! n!1N u0; ? (x) Z K2
 under the conditions ur = O(r!a) for a > 2+ 1d and nhd? n ! 1 as n ! 1, as a corollary of theorem 1 in Coulon-Prieur and Doukhan [14]. The corresponding result also holds for ?nite dimensional distributions of this process (with independent limiting distributions). 3.3. Conditional copula processes As previously, we consider stationary time series. Their conditional distributions with respect to past observations are often crucial to specify some underlying models. They are most of the time more useful than the joint or marginal unconditional distributions themselves. For instance, for a Markov process, the law of Xi conditionally on Xi!1 de?nes the process itself. It can be written explicitly and sometimes simply, contrary to the joint law of (Xi; : : : ;X0). Dependence struc- tures, copulas can be considered similarly. Patton [26] has introduced conditional copulas, namely copulas associated with conditional laws in a particular way. We ?rst extend his de?nition. Let X be a d-dimensional random vector. Consider some arbitrary sub ?-algebras A1; : : : ;Ad and B, we denote A = (A1; : : : ;Ad). Assumption S. Let some d-vectors x and ~x. For almost every ! 2 -, P(Xj - xjjAj)(!) = P(Xj - ~xjjAj)(!) for every j = 1; : : : ; d implies P(X - xjB)(!) = P(X - ~xjB)(!): copulas_SISP3.tex; 6/03/2009; 11:29; p.13
14 P. Doukhan, J.-D. Fermanian and G. Lang This technical assumption is satis?ed particularly when every condi- tional cdfs' of X1; : : : ;Xd is strictly increasing. It is satis?ed too when A1 = : : : = Ad = B. Particularly, B may be the ?-algebra induced by the Ai, i = 1; : : : ; d. We introduce De?nition 3. A d-dimensional pseudo-copula is a function C : [0; 1]d !! [0; 1] such that 2 For every u 2 [0; 1]d, C(u) = 0 when at least one coordinate of u is zero. 2 C(1; : : : ; 1) = 1. 2 For every u and v in [0; 1]d such that u - v, the C-volume of [u; v] (see Nelsen [25], de?nition 2.10.1) is positive. Thus, a pseudo-copula is \as a copula" except that the margins are not necessarily uniform. We get Theorem 6. For every random vector X, there exists a random vari- able function C : [0; 1]d ? - !! [0; 1] such that P(X - ujB)(!) = C(P(X1 - u1jA1)(!); : : : ; P(Xd - udjAd)(!); !) := C(P(X1 - u1jA1); : : : ; P(Xd - udjAd))(!); for every u 2 [0; 1]d and almost every ! 2 -. This function C is B([0; 1]d) - ?(A; B) measurable. For almost every ! 2 -, C(?; !) is a pseudo-copula and is uniquely de?ned on the product of the values taken by uj 7! P(Xj - ujjAj)(!), j = 1; : : : ; d. When C is unique, it will be called the conditional (A; B)-pseudo copula associated with X. In general, it is not a copula, because of the direrence between B and any Ai (in terms of information). The latter pseudo-copula is denoted by C(?jA; B). Typically, when we consider a d-dimensional process (Xn)n2Z, the previous sigma-algebras are indexed by n, namely they depend on the past values. For instance, Aj;n = ?(Xj;n!1;Xj;n!2; : : :) and Bn = ?(Xn!1; : : :). Thus, conditional copulas depend on the index n and on the past values of X, in general. Actually, we get sequences of copulas. When the process X is one-order Markov, conditional copulas depend only on the last observed value. In this paper, we consider two basic following cases: (i) Aj;n = (Xj;n!1 = xj) for every j = 1; : : : ; d and Bn = (Xn!1 = x), (ii) Aj;n = (Xj;n!1 2 [aj ; bj ]), for some aj ; bj 2 1R, j = 1; : : : ; d and Bn = (Xn!1 2 [a; b]). copulas_SISP3.tex; 6/03/2009; 11:29; p.14
Copulas for weakly dependent processes 15 It is particularly relevant to specify (i) and (ii) when the process (Xn) is Markov. Even if the process does not satisfy this property, we could consider the previous ?-algebras Aj;n and Bn. One key issue is to state wether these copulas depend really on the past values. This assumption is made most of the time in practice (Rosenberg [28] among others). Only a few papers try to modelize time dependent conditional copulas. For instance, to study the dependence between Yen-USD and Deutsche mark-USD exchange rates, Patton [26] assumes a bivariate Gaussian conditional copula whose correlation pa- rameter follows a GARCH-type model. Alternatively, Genest et al. [21] postulate Kendall's tau is a function of current conditional univariate variances. Now, we try to estimate conditional copulas to test their constancy with respect to their conditioning subsets. There exists a relation between copulas in the (i) and (ii) cases, denoted by C(i) and C(ii). More precisely, with obvious notations, we have C(ii) !FX1;n(x1jX1;n!1 2 [a1; b1]); : : : ; FXd;n(xdjXd;n!1 2 [ad; bd])? = Z[a;b] C(i) (F1(x1); : : : ; Fd(xd)jXn!1 = u) dPXn!1(u) P(Xn!1 2 [a; b]) ; by denoting FXk;n(xkjXk;n!1 = uk) := Fk(xk), k = 1; : : : ; d. Clearly, when the underlying distributions are continuous and when the diameter of the box [a; b] is \small", FXi;n(xijXi;n!1 2 [ai; bi]) ' FXi;n(xijXi;n!1 = ui) for every i and every ui 2 [ai; bi]. We deduce C(i) ' C(ii) in this case. Thus, to test the constancy of C(i)(?jXn!1 = u) with respect to u is almost the same thing as to test the constancy of C(ii)(?jXn!1 2 [a; b]) with respect to \small" boxes [a; b]. This intuitive argument justi?es to test the zero assumption H0 : C(ii)(?jXn!1 2 [a; b]) = C0(?) for every a and b; against its opposite. Actually, a direct test of a similar zero assumption with C(i) is more di±cult because the marginal conditional cdfs' need to be estimated by some nonparametric techniques. At the opposite, we do not need such tools with C(ii), because the marginal conditioning probabilities can be easily estimated empirically. Assume we observe a weakly dependent stationary sequence (Xi)0-i-n. Denoting by Pn the empirical measure, we see that C(ii)(ujX0 2 [a; b]) may be estimated by Cn;(ii)(uj[a; b]) = Pn (X1;1 - x1; : : : ;Xd;1 - xd;X0 2 [a; b]) Pn(X0 2 [a; b]) copulas_SISP3.tex; 6/03/2009; 11:29; p.15
16 P. Doukhan, J.-D. Fermanian and G. Lang where we set, for j = 1; : : : ; d and i ? 1: ^ FXj;i(tjXj;i!1 2 [aj ; bj ]) = Pn (Xj;m - t;Xj;i!1 2 [aj ; bj ]) Pn(Xj;i!1 2 [aj ; bj ]) ? xj = ^ F!1 Xj;1(u1jXj;0 2 [aj ; bj ]): Note that the estimators ^ FXj;i(?j[aj ; bj ]) and Cn;(ii)(?j[a; b]) can be writ- ten as some regular functionals of the empirical cdf of (Xi;Xi!1). By the same reasoning as in lemma 3 in [17], we check that the \copula" Cn;(ii)(?j[a; b]) associated with the process X is the \copula" associated with the process Y, but by replacing every aj and bj by a0j = Fj(aj) and b0j = Fj(bj ), j = 1; : : : ; d. Thus, we could assume the underlying process has uniform marginals. By theorem 1 and the functional Delta method: Theorem 7. Assume (Yi;Yi!1)i2Z is ?-dependent, ?n = O(n!a), a > a¤ 2d, and that its copula has some continuous ?rst partial derivatives. For every d-vectors a and b, the process pn(Cn;(ii)(?j[a; b]) ! C(ii)(?j[a; b])) converges to a Gaussian process in D([0; 1]d; dS). The proof is left to the reader. Thus, a test of H0 can be based on the limiting behavior of pn(Cn;(ii)(?j[a; b])!C0(?)). The covariance structure of the limiting process is particularly tedious. Thus, the crit- ical values of such a test are obtained through Bootstrap procedures (see Fermanian et al. [17]). 4. Proofs 4.1. Proof of theorem 1 4.1.1. CLT for the ?nite dimensional distributions of Bn Let (s1; : : : ; sm) be a ?xed sequence of elements in [0; 1]d. Denote by Bn the vector-valued process Bn = (Bn(s1); : : : ;Bn(sm)): To prove a CLT for the vector Bn is equivalent to prove the Gaus- sian convergence for any linear combination of its coordinates. Let (r1; : : : ; rm) be a real vector such that Pm P j=1 rj 6= 0. De?ne Zi = j rj(1fYi - sjg ! P(Yi - sj)). copulas_SISP3.tex; 6/03/2009; 11:29; p.16
Copulas for weakly dependent processes 17 De?ne also Sn = 1 pn X 1-i-nZi = X 1-j-mrjBn(sj): We use the Bernstein blocking technique, as described by [11]. Let p(n) and q(n) be sequences of integers such that p(n) = o(n) and q(n) = o(p(n)). Assume that the Euclidean division of n by (p + q) gives a quotient k. For i = 1; : : : ; k, we de?ne the interval Pi = f(p + q)(i ! 1) + q + 1; : : : ; (p + q)ig and Q the set of indices that are not in one of the Pi. Note that the cardinal of Q is less than (k + 1)q. For each block Pi and Q, we de?ne the partial sums: ui;n = 1 pn Xj2Pi Zj ; vn = 1 pnXj2QZj : We use lemma 11 of [11]. Lemma 4.1. Let Sn = p1n Pnk=1 Zk be a sum of centered stationary r.v's, and set ?2n= var Sn. Assume that: lim n!1 1 ?2nEv2n= 0; (15) Xk j=2 ?????covAg A t ?n Xj!1 i=1 ui;n!; hu t ?n uj;n
!?????! 0; for all t 2 R; (16) where h and g are one of the sine or the cosine function, lim n!1 1 ?2n Xk i=1 E?jui;nj21fjui;nj ? 2?ng¤ = 0 for all 2 > 0; (17) and lim n!1 1 ?2n Xk i=1 Ejui;nj2 = 1: (18) Then Sn=?n converges in distribution to a Gaussian N(0; 1)-distribution. Since the proof of this lemma is a direct adaptation of the proof of lemma 3.1 in [32], it is omitted. First note that Xn i=0 cov(Z0;Zi) < 1 (19) so that ?2ntends to a constant, see [27]. If this constant is zero then the limit of Sn is 0. If it is not, we check the conditions of the preceding copulas_SISP3.tex; 6/03/2009; 11:29; p.17
18 P. Doukhan, J.-D. Fermanian and G. Lang lemma for the sequence Zj . To check (15), note that, with obvious notations, Ev2n- 1n Xi;j2Q cov(Zi;Zj) - 2m2 maxi r2i n Xi2QXj2Q ?jj!ij - 4m2 (k + 1)q n max i r2i nX!1 r=0 ?r = o(1): Consider (16). Note that g( t ?n Pj!1 i=1 ui;n) is a function of at most mp(k! 1) indicator functions. Its Lipschitz modulus is less than t maxi ri=(pn?n). Similarly h( t ?n uj;n) is a function of at most mp indicator functions whose Lipschitz modulus is less than t maxi ri=(pn?n). Invoking (9) we get ?????covAg A t ?n Xj!1 i=1 ui;n!; hu t ?n uj;n
!?????- mpktmaxi ri pn?n ?q; hence Xk j=2 ?????covAg A t ?n Xj!1 i=1 ui;n!; hu t ?n uj;n
!?????- mpk2 tmpaxi ri n?n ?q = O 3n3=2p!1q!a? : Choosing p = n5=6 and q = n5=6a gives a bound tending to 0. To prove (17), it is su±cient to show that Ejui;nj4 = O(k!2): But E0@ 1 pn Xj2Pi Zj1A4 = p2 n2EA Xm i=1 riBp(si)!4 - p2 n2m3 Xm i=1 r4i E(Bp(si) ! Bp(0))4 ; and we conclude by applying proposition 1 for l = 2 to the couples (0; si): sup i E(Bp(si) ! Bp(0))4 = O(1): In order to prove (18), note that (15) implies that lim n!1 1 ?2nvarA Xk i=1 ui;n! = 1: copulas_SISP3.tex; 6/03/2009; 11:29; p.18
Copulas for weakly dependent processes 19 Moreover, note that ?????varAXk i=1 ui;n! ! Xk i=1 Ejui;nj2?????- 2 X 1-i6=j-k jcov(ui;n; uj;n)j - 2k 1Xj=q ?j = O(np!1q!a+1): Taking p = n5=6 and q = n5=6a, we get a bound tending to 0. 4.1.2. Tightness of Bn As in [11], we prove a Rosenthal type inequality. This result is of independent interest. Proposition 1. Assume that Y has uniform marginals and is ?-dependent with ?r - Cr!a. For every integer l < (a+1)=2 and s; t such that s - t and kt ! sk1 < C: E(Bn(t) ! Bn(s))2l - 4(4l ! 2)! (2l ! 1)! 32l 0@A2kl ukt ! sk1 C 
1!1=a!l + (2l)!kln1!l ukt ! sk1 C 
1!(2l!1)=a1A; (20) where kl = 3C + C2a a!2l+1? : The same result may be easily proved when the marginal distribu- tions have a bounded density (see [10]). 4.1.2.1. Proof of proposition 1. Let s - t be in Rd. Denote xi(s; t) = 1fYi - tg!1fYi - sg!F(t)+F(s). Because process Y has uniform margins, we get jxi(s; t)j - 1; (21) and jxi(s; t)j - 1fYi - tg ! 1fYi - sg + F(t) ! F(s); so that Ejxi(s; t)j - E(1fYi - tg ! 1fYi - sg) + F(t) ! F(s) - 2(F(t) ! F(s)) - 2kt ! sk1: (22) copulas_SISP3.tex; 6/03/2009; 11:29; p.19
20 P. Doukhan, J.-D. Fermanian and G. Lang For any multi-index k of Z denote |k = Qj xkj (s; t). Roughly, jcov (|k1 ;|k2)j - 4kt ! sk1: (23) For any integer q ? 1, set Aq(n) = X k2f1;:::;ngq jE(|k)j ; (24) then E(Bn(s) ! Bn(t))2l - (2l)!n!lA2l(n): (25) For a ?nite sequence k = (k1; : : : ; kq) of elements of Z, let (k(1); : : : ; k(q)) be the same sequence ordered from the smaller to the larger. The gap r(k) in the sequence is de?ned as the max of the integers k(i+1) ! k(i), j = 1; : : : ; q ! 1. If k(j+1) ! k(j) = r, de?ne the two non-empty subsequences k1 = (k(1); : : : ; k(j)) and k2 = (k(j+1); : : : ; k(q)). De?ne the set Gr(q; n) = fk 2 f1; : : : ; ngq; r(k) = rg. Sorting the sequences of indices by their gaps, we get Aq(n) - Xn k=1 Ejxi(s; t)jq + Xn r=1 X k2Gr(q;n) jcov (|k1 ;|k2)j (26) + Xn r=1 X k2Gr(q;n) jE(|k1)E(|k2)j : (27) De?ne Vq(n) as the right hand side of (26). In order to prove that the expression (27) is bounded by the product Pm Am(n)Aq!m(n), we make a ?rst summation over the k's with #k1 = m. Hence Aq(n) - Vq(n) + Xq!1 m=1Am(n)Aq!m(n): (28) To build a sequence k belonging to Gr(q; n), we ?rst ?x one of the n points of f1; : : : ; ng. We choose a second point among the two points that are at distance r from the ?rst point. The third point is in an interval of radius r centered on one of the preceding points, and so on. Thus#Gr(q; n) - n2(2r + 1) ? ? ? (2(q ! 2)r + 1) - n(q ! 1)!(3r)q!2: We use condition (9) (here 2q replaces uLip f + vLip g) and condition (23) to deduce Vq(n) - 4nAkt ! sk1 + q! X2n r=1(3r)q!2 min(?r; kt ! sk1)!: copulas_SISP3.tex; 6/03/2009; 11:29; p.20
Copulas for weakly dependent processes 21 Denote R the integer such that R < (kt!sk1=C)!1=a - R+1. For any 2 - q - 2l: Vq(n) - 3(q!1)4nq!Akt ! sk1 RX!1 r=0 rq!2 + C 1Xr=R rq!2!a! - 3q!14nq!ukt ! sk1 q ! 1 Rq!1 + C (a ! q + 1)Rq!1!a
 - 3q!14nq!ukt ! sk1 C 
!(q!1)=a ukt ! sk1 q ! 1 + C (a ! q + 1)R!a
: By assumption, R ? 1, so that (kt ! sk1=C)!1=a - 2R, and Vq(n) - 3q!14nq!(kt ! sk1=C)1!(q!1)=a uC + C2a a ! q + 1
: We ?nd that: Vq(n) - 3q4nq!kl(kt ! sk1=C)1!(q!1)=a: (29) The rhs of equation (29) is a function of q that satis?es condition (H0) of [11]: if 2 - p - q; V q!2 p (n) - V p!2 q (n)V q!p 2 (n): Then, for 2 - m - q ! 1, (V m=2 2 (n) _ Vm(n))(V (q!m)=2 2 (n) _ Vq!m(n)) - (V q=2 2 (n) _ Vq(n)): De?ning Uq = Aq(n)=(V q=2 2 (n) ^ Vq(n)), we see from (28) that Uq - Xq!1 m=1UmUq!m + 1: Then, by invoking a lemma of [11] based on the Catalan's numbers property, we get that Uq - (2q ! 2)! q!(q ! 1)! and conclude that A2l(n) - 4(4l ! 2)! (2l)!(2l ! 1)!32l 0@A2klnukt ! sk1 C 
1!1=a!l + (2l)!klnukt ! sk1 C 
1!(2l!1)=a!; copulas_SISP3.tex; 6/03/2009; 11:29; p.21
22 P. Doukhan, J.-D. Fermanian and G. Lang and (20) is proved. Oscillation of the empirical process: We use this moment inequality and the techniques of [14] to compute the oscillations of the process. Let m be in Nd, and (s; t) be two elements of Rd, such that s - t - s+m=n. Let i be the element of Nd such that s + i=n - t < s + i+=n, where i+ = (i1 + 1; : : : ; id + 1). Then jBn(t) ! Bn(s)j - jBn(t) ! Bn(s + i=n)j + jBn(s) ! Bn(s + i=n)j: Because Bn is the direrence between two monotone functions, we get jBn(t) ! Bn(s + i=n)j - pnjFn(t) ! Fn(s + i=n)j + pnjF(t) ! F(s + i=n)j - pnjFn(s + i+=n) ! Fn(s + i=n)j + pnjF(s + i+=n) ! F(s + i=n)j - jBn(s + i+=n) ! Bn(s + i=n)j + 2pnjF(s + i+=n) ! F(s + i=n)j - jBn(s + i+=n) ! Bn(s)j + jBn(s + i=n) ! Bn(s)j + 2d=pn; because the marginal distributions of F are uniform. Thus, sup s-t<s+m=n jBn(t) ! Bn(s)j - 3 max 0-i-m????Bn(s) ! Bn us + in
????+ 2d pn? (30) For s 2 Rd and m 2 Nd, de?ne the \discrete" box U = B(m; s) = fs + i=n; 0 - i - mg. For such a box, p<U= s and p>U= s + m=n are opposite vertices of the box and we de?ne M(U) = max t2U !??Bn(p<U) ! Bn (t)??^??Bn !p>U ? ! Bn (t)??? : Then max 0-i-m????Bn(s) ! Bn us + in
????- M(B(m; s)) +???Bn 3s + mn ? ! Bn(s)???: (31) Following [14], we use the moment inequality (20) to bound the distri- bution tail of M(B(m; s)): Lemma 4.2. Assume that p is an integer satisfying a > 2p ! 1 and p(1 ! 1=a) ! d ? 0. Then P (M(B(m; s)) ? ?) - Cp Kp ukmk1 n 
p(1!1=a) ?!2p; (32) with the constants Kp = 12 !2(p(1!1=a)!d)=(2p+1) ! 1?2p+1 and Cp pro- vided by proposition 1. copulas_SISP3.tex; 6/03/2009; 11:29; p.22
Copulas for weakly dependent processes 23 The ?rst condition on p is needed to use the moment inequality. The second ensures that Kp > 0. The two constraints are satis?ed par- ticularly when p = h12(1 + d + p1 + d2)i. This induces the condition a > a¤d. Proof of the lemma. Note that (32) is true for kmk1 < 2 and ev- ery s, because the box B(m; s) contains at most two points so that M(B(m; t)) = 0. Let m be ?xed, such that kmk1 ? 2 and for ev- ery i < m and every t, the lemma is true for M(B(i; t)). De?ne h = (s1 + [m1=2]=n; : : : ; sd + [md=2]=n). Using h as a vertex, one de- ?nes a partition of 2d sub-boxes of B(m; s). Let i 2 B(m; s) and denote U(i) the unique sub-box that contains i. Then ???Bn(p<B(m;s)) ! Bn (i)???^???Bn 3p>B(m;s)? ! Bn (i)??? - M(U(i))+???Bn 3p>B(m;s)? ! Bn 3p>U(i)????_?? ?Bn 3p<B(m;s)? ! Bn 3p<U(i)????: Because of the moment inequality and '' 'p>U(i) ! p>B(m;s)''' 1 - kmk1=2n, P 3???Bn 3p>B(m;s)? ! Bn 3p>U(i)????? ?? - Cp kmkp(1!1=a) 1 (2n)p(1!1=a)?2p ; and the same relation for the lower vertex yields P 3?? ?Bn 3p>B(m;s)? ! Bn 3p>U(i)????_???Bn 3p<B(m;s)? ! Bn 3p<U(i)????? ?? - 2Cp kmkp(1!1=a) 1 (2n)p(1!1=a)?2p ? From induction assumption and kp>U(i) ! p<U(i)k1 - kmk1=2n: P (M(U(i)) ? ?) - Cp Kp kmkp(1!1=a) 1 (2n)p(1!1=a)?2p ? The following result may be found in [3] on p. 1661: assume that P(A ? ?) - a?!2p and P(B ? ?) - b?!2p together imply P(A + B ? ?) - (a1=(2p+1) + b1=(2p+1))2p+1?!2p: copulas_SISP3.tex; 6/03/2009; 11:29; p.23
24 P. Doukhan, J.-D. Fermanian and G. Lang We thus deduce by using the de?nition of Kp: P 3M(U(i)) +???Bn 3p>B(m;s)? ! Bn 3p>U(i)???? _???Bn 3p<B(m;s)? ! Bn 3p<U(i)????? ? ?? - Cp (21=(2p+1) + K!1=(2p+1) p )2p+1 2p(1!1=a) ? kmkp(1!1=a) 1 np(1!1=a)?2p - Cp2!d Kp kmkp(1!1=a) 1 np(1!1=a)?2p : Now, using P(maxi=1;:::k Ai ? ?) - Pi=1;:::k P(Ai ? ?), we have P (M(B(m; s)) ? ?) - Cp Kp kmkp(1!1=a) 1 np(1!1=a)?2p ; so that (32) is proved for m. 2 To prove the tightness of the sequence of processes Bn, we study the oscillations of Bn. Let 2 > 0. Let n be such that 2d=pn < 2=8. Let ± > 0 and assume that n± ? 1. Set m = (2[n±] + 1; : : : ; 2[n±] + 1). Because of relation (30), we have PA sup ks!tk1<± jBn(t) ! Bn(s)j ? 2! - 2PA sup ks!tk1<± jBn(t) ! Bn(s ^ t)j ? 2=2! - 2PA sup s-t<s+m=n jBn(t) ! Bn(s)j ? 2=2! - 6Pu max 0-i-m????Bn(s) ! Bn us + in
????? 2=8
: Because of relation (31) and proposition 1, we obtain Pu max 0-i-m????Bn(s) ! Bn us + in
????? 2=8
 - P (M(B(m; s))j ? 2=16) + P 3jBn(s) ! Bn(s + mn )j ? 2=16? - Cp Kp ukmk1 n 
p(1!1=a) 162p 22p + Cp ukmk1 n 
p(1!1=a) 162p 22p - Cp !1 + K!1 p ? (2d(± + 1=n))p(1!1=a) 22p 162p; copulas_SISP3.tex; 6/03/2009; 11:29; p.24
Copulas for weakly dependent processes 25 so that Bn satis?es the tightness criteria for the multi-dimensional case, see [3]: for every 2 > 0, lim ±!0 lim sup n!1 PA sup ks!tk1<± jBn(t) ! Bn(s)j ? 2! = 0; proving the result. 2 4.2. Proof of theorem 2 From lemma 3 in Fermanian et al. [17], it is enough to assume that the law of X is compactly supported on [0; 1]d with uniform marginals. The argument relies on the functional delta method through the function A de?ned on the Skorohod space (D([0; 1]; dS), A : F1 7! F!1 1 ; from the compact support assumption, this application is now de?ned on (l1([0; 1]); k?k1). As in [17], we apply theorem 3:9:23 in Van der Vaart and Wellner [31] to conclude. Note that, for any function h 2 C([0; 1]), the convergence of a sequence hn to h in (D([0; 1]); dS) is equivalent to the convergence in (D([0; 1]); k ? k1). The result follows by applying theorem 3:9:4 in Van der Vaart and Wellner [31] and our theorem 1. 2 4.3. Proof of lemma 3.1 First, let us assume that k is compactly supported. Then, by some integrations by parts, we get pn( ^ Fn ! Fn)(u) = pn Z [Fn(u ! hv) ! Fn(u)] k(v) dv = Z pn [(Fn ! F)(u ! hv) ! (Fn ! F)(u)] k(v) dv + n1=2 Z (F(u ! hv) ! F(u)) k(v) dv: Since v belongs to a compact subset, hv is bounded above uniformly with respect to v and n. Equicontinuity of the process pn(Fn ! F) thus provides the result with our assumptions. If k is not compactly supported, we lead the same reasoning. Now, for n su±ciently large, Pujpn Z [(Fn ! F)(u ! hv) ! (Fn ! F)(u)] k(v) dvj > ?
 - PAn1=2kkkL1 : sup ktk<? j(Fn ! F)(u ! t) ! (Fn ! F)(u)j > ?=2! + PA2n1=2 Zfkvk>ang jk(v)j dv > ?=2!; copulas_SISP3.tex; 6/03/2009; 11:29; p.25
26 P. Doukhan, J.-D. Fermanian and G. Lang which tends to zero under our assumptions. 2 4.4. Proof of theorem 5 A Taylor expansion yields for every u 2 [0; 1]d, ^? (u) = 1 nhdXn i=1 K uu ! Yi h 
 ! 1 nh Xn i=1 dK uu ! Yi h 
(^Yi ! Yi) + 1 2nh2 Xn i=1 d2K uu ! Y¤i h 
(^Yi ! Yi)-2 = ? ¤(u) + R1(u) + R2(u); for some random vectors ^Y¤i satisfying k^Y¤i ! Yik - k^Yi ! Yik a.e. Note that ? ¤ is the kernel density estimator studied in Doukhan and Louhichi [12], when applied to the weakly dependent sequence (Yi)i2Z, which is improved in the paper by Doukhan and Prieur-Coulon [14]. Thus we get ?di convergence of pnhd(? ¤ ! ? ). It remains to prove that R1(u) and R2(u) are negligible. Let us ?rst study R1(u). Denote partial derivatives wrt uj by @j , R1(u) = ! 1 n2hXi;k Xd j=1 @jK uu ! Yi h 
@u0jFj(Xi;j ju0j )A!1 j (u0j )Bj(u0j ; Yk;j) + OP 0@ 1 n2hXi;k Xd j=1 ????@jK uu ! Yi h 
????sup u¤j k@2uju0jFj(Xi;j ju¤j )kk^uj ! u0j k21A + oP 3rn h ? ; where u¤j belongs a.e. to a neighborhood of u0j for every j. Since the process (Yi)i2Z is weakly dependent, and since Bj(u0j ; Yk;j) is centered, we get E-@jK uu ! Yi h 
@u0jFj(Xi;j ju0j )A!1 j (u0j )Bj(u0j ; Yk;j)? = O 3?ji!kj h1+d ? ; and ER1(u) = O u 1 nh2+d
 = ou 1 pnhd
? Moreover, with obvious notations, the main term in the expansion of ER21(u) is the expectation copulas_SISP3.tex; 6/03/2009; 11:29; p.26
Copulas for weakly dependent processes 27 of 1 n4h2 Xn i1;i2=1 Xn k1;k2=1 Xd j1;j2=1 @j1K uu ! Yi h 
@u0j 1Fj1(Xi1;j1 ju0j1)A!1 j1 (u0j1) Bj1(u0j1 ; Yk1;j1)(@j2K)h(u ! Yi2)@u0j 2Fj2(Xi2;j2 ju0j2) A!1 j2 (u0j2)Bj2(u0j2 ; Yk2;j2) := 1 n4h2 Xj1;j2Xi1;i2 Xk1;k2 Ti1;j1 ~ Tk1;j1Ti2;j2 ~ Tk2;j2 : We consider every relative positions of the indices i1; i2; k1; k2 (j1 and j2 do not play any role). In each cases, weak dependence allows us to bound the expectation of Ti1;j1 ~ Tk1;j1Ti2;j2 ~ Tk2;j2 . As in Theorem 5 of Fermanian [19], ER21(u) = o((nhd)!1) and R1(u) = oP ((nhd)!1=2). The second term R2(u) is simpler because R2(u) = OP u 1 h2+d ? 1n
 = oP u 1 pnhd
; which proves the result. References 1. Ango Nze, P. and Doukhan, P.: Weak dependence: models and applications, in Dehling W. (ed.) et al., Empirical Processes Techniques for Dependent Data, BirkhaAuser, 117-137, 2002. 2. Ango Nze, P., BAuhlmann, P. and Doukhan, P.: Weak dependence beyond mix- ing and asymptotics for non parametric regression, Ann. Statist. 30, 397-430, 2002. 3. Bickel, P.J. and Wichura, M.J.: Convergence criteria for multiparameter stochastic and some applications, Ann. Math. Statist. 42, 1656-1671, 1971. 4. Chen, X. and Fan, Y.: Estimation of Copula-based semiparametric time series models, J. of Econometrics 130, 307-335, 2006. 5. Dedecker, J., Doukhan, P.: A new covariance inequality and applications, Stoch. Proc. Appl. Vol. 106, n1, 63-80, 2003. 6. Deheuvels, P.: La fonction de d
ependance empirique et ses propri
et
es, Acad. Roy. Belg., Bull. C1 Sci. 5iueme s
er. 65, 274-292, 1979. 7. Deheuvels, P.: A Kolmogorov-Smirnov Type Test for independence and multivariate samples, Rev. Roum. Math. Pures et Appl. 26 N2, 213-226, 1981. 8. Doukhan, P.: Mixing: Properties and Examples, Lecture Notes in Statist. 85. Springer Verlag, New York, 1994. 9. Doukhan, P.: Limit theorems for stationary sequences, in Theory and Appli- cations of Long-range Dependence, Paul Doukhan, Georges Oppenheim and Murad S. Taqqu editors. BirkhaAuser, Boston, 43 ! 100, 2002. 10. Doukhan, P. and Lang, G.: Rates in the empirical central limit theorem for stationary weakly dependent random ?elds, Stat. Inf. Stoch. Proc. 5, 199-228, 2002. copulas_SISP3.tex; 6/03/2009; 11:29; p.27
28 P. Doukhan, J.-D. Fermanian and G. Lang 11. Doukhan, P. and Louhichi, S.: A new weak dependence condition and application to moment inequalities, Stoch. Proc. Appl. 84, 313-342, 1999. 12. Doukhan, P. and Louhichi, S.: Functional estimation for weakly dependent stationary time series, Scand. J. Statist. 28, 325-342, 2001. 13. Doukhan, P., Massart, P. and Rio, E.: Invariance principle for absolutely regular empirical processes, Ann. Inst. H. Poincar
e 31.2, 393-427, 1995. 14. Doukhan, P. and Prieur-Coulon, C.: A CLT for triangular arrays of weakly dependent sequences, Statist. Probab. Letters 47, 61-68, 2000. 15. Doukhan, P., Teyssiuere, G., Winant, P. A LARCH(1) Vector Valued Process. To appear in statistics for times series ed. Soulier et al., 2006. 16. Du'o, M. Algorithmes stochastiques Math. & Appl. 23, Springer, 1996. 17. Fermanian, J-D., Radulovic, D. and Wegkamp, M.: Weak convergence of empirical copula processes, Bernoulli 10, n5 , 847860, 2004. 18. Fermanian, J-D. and Scaillet, O.: Nonparametric estimation of copulas for time series, J. Risk 5, 25 ! 54, 2002. 19. Fermanian, J-D.: Goodness-of-?t tests for copulas, J. Multivariate Anal., 95, 119-152, 2005. 20. Gaenssler, P. and Stute, W.: Seminar on Empirical Processes., DMV Seminar, Band 9, BirkhAauser, 1987. 21. Genest, C., van der Goorbergh, R. and Werker, B.: Multivariate option pricing using dynamic copulas, discussion paper 122, Tilburg University, 2003. 22. Giraitis, L., Surgailis, D. ARCH-type bilinear models with double long memory. Stochastic Processes and their Applications, 100, 275-300, 2002. 23. Gouri
eroux C., Laurent J. P. and O. Scaillet: Sensitivity Analysis of Values at Risk, J. Empirical Finance 7, 225-245, 2000. 24. Markowitz H.: Portfolio Selection, Journal of Finance 7, 77-91, 1952. 25. Nelsen, R. B.: An introduction to copulas, Lecture Notes in Statistics, 139, Springer, 1999. 26. Patton, A.: Modelling Time-Varying Exchange Rate Dependence Using the Conditional Copula, UCSD WP 2001-09, 2001. 27. Rio, E.: Th
eorie asymptotique des processus al
eatoires faiblement d
ependants, Math
ematiques et Applications, 31, Springer Verlag, Berlin, 2000. 28. Rosenberg, J.: Nonparametric pricing of multivariate contingent claims, WP Stern School of Business, 2001. 29. Scaillet O.: Nonparametric Estimation and Sensitivity Analysis of Expected Shortfall. Mathematical Finance, Vol. 14, 115-129, 2004. 30. Sklar, A.: Fonctions de r
epartition ua n dimensions et leurs marges. Publ. Inst. Statist. Univ. Paris 8, 229-231, 1959. 31. Vaart, A. W. van der and Wellner, J.: Weak convergence and empirical processes, Springer, New-York, 1996. 32. Withers, C.S.: Central limit theorems for dependent variables, Z. Wahrsch. Verw. Gebiete 57, 509-534, 1981 (corrigendum 63, 555, 1983). copulas_SISP3.tex; 6/03/2009; 11:29; p.28