
1560 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 43, NO. 5, SEPTEMBER 1997 Gauss-Markov Random Fields (GMrf) with Continuous Indices Jos?e M. F. Moura, Fellow, IEEE, and Sauraj Goswami Abstract- Gauss-Markov random fields (GMrf's) play an important role in the modeling of physical phenomena. The paper addresses the second-order characterization and the sample path description of GMrf's when the indexing parameters take values in bounded subsets of <d; d 1. Using results of Pitt, we give conditions for the covariance of a GMrf to be the Green's function of a partial differential operator and, conversely, for the Green's function of an operator to be the covariance of a GMrf. We then develop a minimum mean square error representation for the field in terms of a partial differential equation driven by correlated noise. The paper establishes for GMrf's on <d secondorder characterizations that parallel the corresponding results for GMrf's on finite lattices. Index Terms- Biorthogonal, Gauss-Markov random fields, Green's functions, innovations, MMSE representation. I. INTRODUCTION WE study representations for signals that describe the spatial variability of natural phenomena. These signals are commonly referred to as random fields (rf). Random fields are of interest in a variety of engineering areas. They may represent the distribution of the temperature in materials or of the concentration of components in process control, elucidate the dispersion of atmospheric pollutants in environmental engineering, govern the transport of groundwater flow in hydrology, characterize the mesoscale circulation of ocean fields in physical oceanography, study the rainfall in remote sensing, or describe the gray-level intensity in image processing. Consider Poisson's equation (1) completed with appropriate boundary conditions (bc). In (1), is the gradient operator, is the Laplacean, and is a positive integer. In hydrology, Poisson's equation models a perturbation approximation of the steady-state flow in , [1]. In physical oceanography, it describes the quasigeostrophic wind-driven circulation in a mid-latitude oceanic basin, [2]. In electrostatic systems, the Poisson equation governs the potential field when bulk charge density is a significant source, Manuscript received March 28, 1995; revised December 10, 1996. This work was supported in part by ONR under Grant N00014-91-J-1001. The material in this paper was presented in part at the 1994 Institute of Mathematical Statistics Annual Meeting, Chappel Hill, NC, June 1994, and at the IEEE Information Theory Workshop on Image Processing and Statistics, Alexandria, VA, October 1994. J. M. F. Moura is with the Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA 15213-3890 USA. S. Goswami was with Carnegie Mellon University, Pittsburgh, PA 15213-3890 USA. He is now with Tudor Investment Corporation, New York, NY 10006 USA. Publisher Item Identifier S 0018-9448(97)05016-5. like in transmission lines in corona, in electrostatic paint sprayers, in electrophotography, and laser printing devices. Under the right set of conditions, the linear process given by (1) is a Gauss-Markov random field (GMrf). The covariance associated with when is "white noise" is the solution to the biharmonic equation, a fourth-order partial differential equation (pde) (see Section III). Poisson's equation, suitably interpreted, is a sample path representation of the GMrf , while the Green's function of the biharmonic equation provides a covariance representation for the GMrf. These parsimonious representations are extremely useful when fitting models to data, in predicting the natural phenomena variability under different operating conditions, or when assimilating data obtained from measurements. We are concerned with these issues as well as their converses: i) set of conditions satisfied by the covariance function of a GMrf ; ii) when can we associate a GMrf with a given covariance function ; iii) what is the canonical sample-path representation of a GMrf. We see in Section IV that the canonical sample path representation for space-dependent GMrf's involves correlated noise rather than white noise. These questions are well understood for one-dimensional (1-D) time-dependent random fields (random processes). It is well known that the covariance function of a finite-dimensional Gauss-Markov random process (GMrp) exhibits a factorization structure, see for example [3, pp. 83-84], satisfies a second-order linear differential equation, the Lyapounov equation, and its sample path representations are linear Ito diffusions. In engineering applications, covariance descriptions underline Wiener filtering, while sample path differential models are the departing point for Kalman-Bucy filters. For GMrf's defined on finite lattices , i.e., discrete GMrf's where , being the set of integers, it is well understood that the sample path representation provided by the minimum mean-square error (MMSE) description involves correlated noise and that the covariance is the inverse of a banded block structured matrix, see for example [4], [5]. In this paper, we consider these issues for continuous parameter spatially dependent GMrf's , where , , bounded with smooth boundary. The paper recovers for the continuous context many of the results presented in [5] and [6] for GMrf's on finite lattices. Continuous GMrf's have been considered in the engineering literature, for example [7]-[9], as well as in the Mathematics and Probability Theory literature, for example [10]-[12]. 0018-9448/97$10.00 a 1997 IEEE
MOURA AND GOSWAMI: GAUSS-MARKOV RANDOM FIELDS (GMrf) WITH CONTINUOUS INDICES 1561 References [7]-[9] are limited to restricted classes of twodimensional (2-D) fields, e.g., isotropic fields, for which they develop filtering and smoothing algorithms. Mathematical literature references do address question ii) above but usually in a general abstract framework. We emphasize ordinary random fields rather than generalized random functions and generalized random fields (see Section IV). We structure our approach under simpler practical conditions, avoiding in our proofs much of the machinery required by more general setups, [11]-[13]. We address the three questions above on covariance and sample path representations. We obtain explicit results on question i), establishing the conditions satisfied by the covariance of a GMrf. We obtain converse results on conditions to associate a GMrf to a given operator, question ii) above. These latter conditions are in the spirit of the conditions in [12]. Finally, regarding question iii), we present the MMSE representation of a GMrf as partial differential equations driven by correlated noise interpreted in a weak sense. Although we resort in this section to the framework of generalized random functions, our partial differential equation model does provide a representation for a GMrf in terms of ordinary random fields. Our results regarding the three questions i)-iii) parallel for continuous indices the corresponding results for discrete GMrf's in [5]. An outline of the paper follows. In Sections III and IV, we study the issues of covariance characterization and MMSE sample path representation for GMrf's. Section V concludes the paper. In Section II and Appendix I, we review the acausal Markov property in the context of Gauss fields and introduce background needed to make the paper self-contained. The major proofs are relegated to Appendix II. II. GAUSS-MARKOV RANDOM FIELDS We consider the noncausal or acausal Markov property. This concept is appropriate when dealing with spacedependent phenomena. It contrasts with causal Markov associated with time-dependent signals. We distinguish between the two by referring to Markov random fields (Mrf) when the Markov property is acausal or noncausal and Markov random processes (Mrp) when the signals are causal. In one dimension (1-D), a class of Markov fields that has received considerable attention recently in the literature is the class of reciprocal processes; see [14], [15], and references therein. We introduce the definition of acausal Markov in a general setting in terms of -algebras in Appendix I. In this paper, we focus attention on linear Markov fields or Gauss-Markov random fields (GMrf). For GMrf's, the Markov property is restated in terms of Hilbert spaces, much easier to handle. There are two types of isometrically isomorphic Hilbert spaces associated with Gauss fields: Hilbert spaces spanned by collections of random variables and functional Hilbert spaces. The Markov property is rephrased in terms of these spaces. These equivalent definitions are used in Section III to characterize the covariance of the GMrf. We summarize the section. In Section II-A, we state the basic assumptions on the random field (rf). In Section II-B, we introduce needed background on Hilbert spaces, reproducing kernel Hilbert spaces, Sobolev spaces, Dirichlet forms, and partial differential operators. These concepts will be used in Sections III and IV. Finally, Section II-C defines the Markov property for Gauss random fields. A. Ordinary Random Field On the probability space , consider the set of zero mean Gauss real valued -random variables (rv) (2) The covariance is . We refer to this family as an ordinary Gauss random field (rf). We make explicit the conditions we assume throughout the paper. 1) Boset: We consider bounded open sets with smooth boundary . We refer to such as a domain. We let . In , represents an open set with smooth boundary and is the complement in of the closure . The sets and are referred to as complementary sets. 2) Dbc: Dirichlet boundary conditions. For simplicity we fix the boundary conditions (bc) to be of the zero Dirichlet type and (3) For the most part, our results remain valid for more general sets . In particular, they remain true for sets with the segment property, see [16, p. 36, Definition 2.1]. These sets include rectangular domains. We restrict ourselves to smooth domains to remain focused on the relevancy of the results rather than distracting the reader with additional technical assumptions. B. Preliminaries: Hilbert Spaces, Locality, Dirichlet Forms Hilbert Spaces of Random Variables: We associate with the Gauss random field the following spaces [17]. Let be the Hilbert space of finite-energy real-valued random variables closure of linear span (4) equipped with the usual inner product and induced norm E and (5) Let be as in (81) in Appendix I and define the Hilbert spaces (6) Define likewise the linear spaces , and . All these Hilbert spaces inherit the norm (5).
1562 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 43, NO. 5, SEPTEMBER 1997 Functional Hilbert Space-RKHS: A second space of importance associated with Gauss fields is the reproducing kernel Hilbert space abbreviated as RKH space or simply RKHS. This is a functional space associated with the covariance of the field. The RKHS is E (7) Let E , . The inner product and norm in are E and (8) The spaces and are defined similarly to and and (9) These spaces are Hilbert spaces which are isometrically isomorphic to the corresponding spaces of rv's. For example, for , the isometric isomorphism is (10) (11) The image of the rv under is the function E . The following are equivalent defining properties of an RKHS. RKHS1: Reproducing kernel property: There is a reproducing kernel (12) RKHS2: Pointwise evaluation of functions: In the RKHS, pointwise evaluation of functions is a bounded linear functional, i.e., the functional is continuous. In the space of square integrable functions, pointwise evaluation of functions is not continuous, so property RKHS2 is not satisfied in . Hence, is not an RKHS. Sobolev spaces introduced below provide a rich class of RKHS's. Locality: A useful property of RKHS associated with GMrf's is that of locality. Definition II.1-Locality [12]: A Hilbert space is local if and only if (iff), for every open complementary sets and with smooth boundary, the following two conditions hold: 1) Local1: If such that , , then . 2) Local2: If , such that , , then Sobolev Spaces: These are candidate spaces for RKHS of GMrf's. There are several types of Sobolev spaces. We focus on the class of Sobolev spaces of order , , which are the closure in an appropriate norm of the set of smooth functions with compact support. For other types of Sobolev spaces see any standard text, for example [18]. They are subspaces of . To introduce Sobolev spaces, we recall the Schwartz notation of multi-indices. The -tuple of nonnegative integers is a multi-index of order Given the multi-indices and , we say provided , . The operator represents the weak (or distributional) partial derivative operator [19] (13) where . Let be the set of infinitely differentiable functions with compact support in . Definition II.2-Sobolev Space: The Sobolev space is the closure of under the Sobolev standard norm(14) These Sobolev spaces telescope (15) Sobolev spaces are RKHS and local spaces as we discuss now. Sobolev Spaces as RKHS and Local Spaces: Let represent the set of continuous functions with compact support. Lemma II.1: The Sobolev space , , is an RKHS. This result follows from the Sobolev embedding Theorem [16] (16) The symbol stands for continuous embedding, i.e., (17) In words, (17) states that convergence in implies pointwise convergence. By Property RKHS2 above, the continuous embedding of in for implies that the Sobolev space is an RKHS. Lemma II.2: The Sobolev space is local. The Lemma is proved by a limiting argument. Let the sets and in be complementary with smooth boundary and with and . Because , there are and in , with , , and , and In the limit this verifies condition Local1 in Definition II.1.
MOURA AND GOSWAMI: GAUSS-MARKOV RANDOM FIELDS (GMrf) WITH CONTINUOUS INDICES 1563 We verify condition Local2 by showing that where, for , , and are as in Local2. Because and have disjoint supports, by direct substitution of the decomposition of in the expression for the norm of , the cross terms are zero. We get The last inequality is a direct consequence of . Since each term in the middle side of the equality is nonnegative, it is finite, and so and belong to as desired. Partial Differential Operators and Dirichlet Forms: The results in Section III are in terms of differential operators. Let be the linear differential operator of order (18) The real-valued coefficients are assumed to be sufficiently differentiable in , for example, , . In the sequel, we assume that is positive and symmetric. Positivity: (19) Symmetry: (20) In these equations, is the usual inner product in . Associate with the positive, symmetric differential operator in (18) the bilinear form (21) (22) (23) The bilinear form is referred to as a Dirichlet form. The form is well-defined in . In fact, it is well-defined for all , see [19, p. 511]. The positive, symmetric densely defined operator admits a self-adjoint extension, see [19, p. 131] and [20]. This is the Friederichs extension of . In this paper when referring to the differential operator we always assume its Friederichs extension. Locality and Dirichlet Forms: In [12] and [21], the following is proved, see [12, Theorem 4.1 (iii)]. Let be the closure of under a positive-symmetric bilinear form . Assume the space is local. Then, if the bilinear form is continuous, it is a Dirichlet form. The following "honesty condition" is a sufficient condition for the continuity of the nonnegative form [12]. Honesty condition: if in and as , then . C. Markov Property for Gauss Random Fields The Markov property for Gauss fields is now restated in terms of and . We follow [12]. Definition II.3-Markov Property for Gauss Fields (GMrf's): The Gauss field is a GMrf iff: open set with smooth boundary 1) Continuity: . 2) Conditional independence. The projection of onto is . Recalling from (10) the isometric isomorphism between the spaces and , the continuity condition in Definition II.3 is reexpressed as (24) Definition II.4: A Gauss field which satisfies (24) is Markov iff the RKHS is local. III. SECOND-ORDER CHARACTERIZATION OF GMRF'S In this section we characterize the covariance of a GMrf. The model is specified in Section II-A, namely, the indexing set , , is bounded open with sufficiently smooth boundary and the covariance of the zero mean GMrf satisfies zero Dirichlet bc's. We address the following two questions: 1) Direct: what properties are satisfied by the covariance of a GMrf. 2) Converse: when is a positive-definite function the covariance of a GMrf, i.e., when can we construct a GMrf whose covariance function is the given positivedefinite function . The explicit conditions contained in the Theorems and Corollaries below provide rich classes of examples of GMrf's. After each result we comment briefly on the proof. Detailed proofs are in Appendix II. Theorem III.1: Let , where is bounded open with smooth boundary , be a zero-mean GMrf satisfying Dirichlet bc's. Let be a dense subset of its RKHS . Then the covariance of the field is the Green's function of the partial differential operator associated with the inner product of the RKHS. This theorem considers the direct question above and shows that the covariances of GMrf's are solutions to certain partial differential equations. The proof in Appendix II establishes that the inner product in the RKHS is given by a Dirichlet form and then shows that, in a distributional sense, is a delta function. We now provide converses to Theorem III.1. The next theorem states a sufficient condition for the Green's function of a positive-symmetric differential operator to be the covariance of a GMrf.
1564 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 43, NO. 5, SEPTEMBER 1997 Theorem III.2: Given a positive-symmetric partial differential operator of order with coefficients such that (25) then there exists a GMrf whose covariance is the Green's function of . The theorem is proved in Appendix II by considering the space which is the completion of under . In the Appendix we show first that is a local space. Then, we show it is an RKHS. Finally, we construct a GMrf with as RKHS and whose covariance is the Green's function of the operator associated with the inner product of the RKHS. We now consider Sobolev spaces. Before we state the first result for these spaces, we recall the notion of strong ellipticity, e.g., [19]. Definition III.1-Strong Ellipticity: The differential operator of order in (18) is strongly elliptic [19] iff there is a positive constant , independent of , such that (26) where . Strong ellipticity involves the principal part of the operator, i.e., the differential terms with . If we can only guarantee that the polynomial in the left-hand side of (26) is nonzero for then the operator is said to be elliptic. A symmetric, elliptic operator is strongly elliptic [16, p. 147, Theorem 10.7]. Also, if the principal part of the operator has real coefficients (as in all cases we consider), ellipticity and strong ellipticity are equivalent [16, p. 142, Theorem 10.2(c)]. The next Corollary shows that Sobolev spaces are the RKHS of GMrf's. Corollary III.1: Let be a Sobolev space with . Let be the partial differential operator of order associated with the inner product. Then is the RKHS of a GMrf. The covariance of this GMrf is the Green's function of the partial differential operator . Moreover, is strongly elliptic. By Lemmas II.1 and II.2, Sobolev spaces are RKHS's and local. The first part of the Corollary then follows from Theorem III.2 by showing that the covariance is the Green's function of the operator . Finally, an equivalence of norms shows that is strongly elliptic (see Definition III.1). The spaces provide examples of GMrf's. Example III.1: Let and define . In this space, consider the inner product (27) Let be the reproducing kernel indexed by . Then (28) Using the definition of inner product (27) in the left-hand side of (28), we get Integration by parts (and using the fact that ) leads further to (29) By (28), the left-hand side is . Then, the bracket in the right-hand side of (29) defines (in a generalized sense) a delta function. Hence (30) The boundary conditions follow because , and so andClearly, we can have one-dimensional fields whose covariance satisfies higher order operators. The next example provides one such field. Example III.2: Let and consider . Endow the space with the inner product (31) In divergence form (32) The differential operator is now (33) which is a fourth-order operator. In Theorem III.2, the differential operator provides the locality of the space; it is the dominance of the norm condition (25) that guarantees that is an RKHS. In the next theorem, we assume strong ellipticity of the operator, which gives us the norm dominance condition.
MOURA AND GOSWAMI: GAUSS-MARKOV RANDOM FIELDS (GMrf) WITH CONTINUOUS INDICES 1565 Theorem III.3: Let be a strongly elliptic symmetric partial differential operator of order satisfying the smoothness assumption (34) Then, for some , there exists a GMrf whose covariance is the Green's function of The proof in Appendix II follows by showing that the closure of by the bilinear form associated with is a Sobolev space. This results by establishing the equivalence of the norm induced by and the standard Sobolev norm. If we restrict attention to operators with only highest order derivatives and constant coefficients, we can forego the in the theorem. Corollary III.2: Let the operator be given in divergence form (35) where constant If is strongly elliptic and symmetric, then there exists a GMrf whose covariance is the Green's function of . Symmetry follows if . The proof establishes again an equivalence of norms and uses a form of G?arding's inequality where in Theorem III.3 can be taken to be zero when the assumptions in the corollary hold. See Appendix II for details. Example III.3-The Biharmonic Operator: Let , . This implies that . Then is a suitable candidate for an RKHS space. An appropriate inner product for is where is the second-order derivative with respect to and likewise for the other quantities. Using the method in the proof of Theorem III.1, it follows that the biharmonic operator (36) is the operator associated with this inner product. This is the operator associated with the covariance of random fields described by the Poisson equation in Section I driven by white noise. Before leaving the section, we make some final comments. 1) Theorems III.2 and III.3 as well as Corollaries III.1 and III.2 describe conditions on the differential operator under which we can associate with it a GMrf. They are in the spirit of Pitt [12, Theorem 5.4]. These are all converses to Theorem III.2. Pitt's Theorem 5.4 makes the assumption that certain norms are equivalent. Our converses state conditions under which the norms we work with are equivalent, in particular, for the norm induced by the operator to be equivalent to the standard norm of a Sobolev space. In contrast, Theorem III.1 is a direct result that describes the covariance of a GMrf as a Green's function of a partial differential operator. These results hold for both nonhomogeneous as well as homogeneous fields. 2) Covariance smoothness of order . Under the above results, it is clear that the covariance of the field associated with the operator has generalized derivatives. Moreover, under the assumptions of Theorem III.3, as well as Corollary III.1, the norm induced by for of order is equivalent to the Sobolev norm, and hence the RKHS associated with the GMrf is the Sobolev space . Then, we can make the much stronger statement that the distributional derivatives of of order up to are , i.e., Smooth covariance: and (37) Since spans , is the largest integer for which (37) holds in this case. When is the highest nonnegative integer such that a covariance satisfies (37), we say that the covariance is smooth of order . 3) Order of the GMrf. McKean [10] introduced the notion of (normal) generalized derivative of a field. The order of the field is if these generalized derivatives are continuously differentiable up to order and if the -algebra generated by the generalized derivatives is the minimal splitting -algebra. In this case, contains information about the generalized derivatives up to order . Pitt [12] shows that the order of the field is half the order of the associated operator . If the covariance is smooth of order , see (37), the field is of order in the sense of McKean and Pitt. 4) Example III.1 is interesting because it shows that our results include examples drawn from a class of GMrf's which has been the subject of recent attention in the literature. In the example, the differential operator of the field is second-order. Hence, the field is a first-order GMrf in the sense of McKean and Pitt. This means that the field is sharp Markov, see Appendix I. The splitting -algebra, see (85) in Appendix I, has no derivative information, it is generated by the values of the field at the boundary, i.e., . This 1-D field is referred to in the literature as a reciprocal process [14], [15]. 5) The results in this section do not cover fields when and the covariance operator is order , i.e., . A prototypical example is the Laplacian operator on the plane or higher dimensions when . The corresponding field is the Nelson free field, the basic building block of Euclidean field theory, a branch of Quantum Physics, [22], [23]. Free fields describe noninteracting particles but are basic to the study of the more complex quantum systems of interacting particles. In Statistical Mechanics, the free field is known as the Gauss field. The Sobolev space associated with it is . Although a local space, this is not an RKHS for , since, in the Sobolev embedding
1566 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 43, NO. 5, SEPTEMBER 1997 Theorem, for , the condition is not verified when . The preceding theorems cannot be applied to the free field. To show that the inverse of is still the covariance of a GMrf one needs the theory of generalized random fields. Generalized random fields, which are to be distinguished from generalized random functions, see [13] and Section IV, are indexed by distributions. Nelson showed that the dual space of is the appropriate indexing space and that the corresponding field is in fact a generalized random field known as the Nelson free field. IV. MMSE SAMPLE PATH REPRESENTATION The previous section discussed covariance-based representations for GMrf's. In signal processing, the covariance is often obtained directly from the data. An alternative representation which is very useful in many applications in control, communications, or signal processing is a differential/difference equation driven by noise. We study in this section such models. We refer to them as sample path representations. When fitting minimum mean-square error (MMSE) models to (time-dependent) random processes, the canonical sample path representations that result are white-noise-driven models. In contrast, as will be discussed in this section, with spatial dependent data, canonical MMSE sample path representations lead to noise with a very specific correlation structure. This correlated noise is related to the concept of biorthogonal field. In this section, our main focus is to derive a sample path representation for ordinary random fields as discussed in Section II-A, not generalized random functions. In Section IV-A we discuss preliminary material regarding generalized random functions as introduced by Molcan [11], see [13], and biorthogonal fields. Our final result on this subsection is a partial differential equation for the GMrf driven by the biorthogonal field. This equation is in terms of generalized random functions. Section IV-B introduces the MMSE predictor representation for the GMrf. Finally, Section IV-C provides the sample path representation of the field in terms of ordinary random fields rather than generalized random functions. A. Preliminaries: Grf's Biorthogonal Fields A good reference for this subsection is [13]. Generalized Random Function: The setup is the same as described in Section II-A. Let be the set of random variables defined on the underlying probability space . Let , bounded, and consider a continuous linear mapping The linear functional maps each fixed into the meansquare-integrable random variable . For each , we obtain a real number.1 The linear functional is referred to as a generalized random 1We deal with real-valued random variables. function (grf). The grf is indexed by the functions. If we fix and let vary (38) we get a sample path. The sample path is a continuous linear functional on , i.e., an element of the space of distributions . Following usual notation with random variables, we omit the dependence and denote the grf by . Molcan and Rozanov [11], [13] study conditions for the grf to be a Gauss-Markov generalized random function (GMgrf). We now associate a grf with an ordinary random field. Grf's and Ordinary rf's: Let bounded, be an ordinary (weakly) continuous random field (39) We associate with the rf a grf by the following construction: (40) The space is the closure of the linear span of the . Kallianpur and Mandrekar [24] show that is a Gauss-Markov random field (GMrf) iff is a Gauss-Markov generalized random function (GMgrf). Biorthogonal Grf-Definition: To study the sample path description and to establish results that are the analog to the discrete sample path results in [4] and [5], we introduce the notion of the biorthogonal generalized random function of a grf [13]. The biorthogonal grf is the continuous linear functional represented by , which is uniquely determined by the biorthogonality condition E (41) For smooth and bounded sets, the closure of the random variables , , is . When this holds, the biorthogonal grf is often referred to as the dual grf. Biorthogonal Grf and Markov Property [13]: The grf is Markov iff is local, i.e., iff such that E (42) In the Markov case, the expectation is given by a Dirichlet form, see (22) E (43)
MOURA AND GOSWAMI: GAUSS-MARKOV RANDOM FIELDS (GMrf) WITH CONTINUOUS INDICES 1567 Biorthogonal Grf Representation: Consider the ordinary GMrf and its Hilbert spaces of rv's and RKHS , with dense in . These spaces were introduced in Section II. With this field, we associate the GMgrf given by (40). Since by the isometric isomorphism of (11), for some E (44) Kallianpur and Mandrekar [24] show that the random element in this equation is (45) This is easy to verify. Assume (45) and (40) of . Then E E (46) E (47) (48) By using (45) in (46), we got (48) which is the biorthogonality condition (41) that defines uniquely the biorthogonal grf . In these equations, interchanging expectations with integration is valid because Fubini's theorem applies as a result of (39). Biorthogonal Grf and : We now establish a relation between and the inverse of the isometric isomorphism between the spaces and . This isomorphism was introduced in Section II, and is given by (10). Each is mapped by onto a function E (49) Since is dense in , take and consider its pre-image under . In terms of the inverse , let (50) We then have E E (51) E (52) (53) Equations (51)-(53) say that is biorthogonal to , hence by the uniqueness of the biorthogonal grf, this states that is (54) PDE for GMgrf: Next, we see that the GMgrf satisfies a partial differential equation. By the isometry between the two spaces, the following equality of the inner products holds: E (55) (56) (57) where is the differential operator defining the inner product in the RKHS . The last equality is a consequence of the fact that being the RKHS of a Markov field is a local space and so its inner product is given by a Dirichlet form. We assume that . Then (see [13]) the GMgrf satisfies the following stochastic partial differential equation (PDE): (58) We develop now a representation for this abstract equation. B. MMSE Field The goal in this subsection is to present a relation between the biorthogonal grf and the minimum mean-square prediction error field. This result is then used in the next subsection to derive a representation for (58) in terms of ordinary random fields. Consider and to be the usual complementary sets with boundary in set . Let be the minimum mean-square error (MMSE) prediction of the field given the boundary data and the data in , i.e., E E (59) The second equality follows from the Markov property of the field. By Gaussianity, conditional expectations are computed by orthogonal projections (60) where is orthogonal projection on the subspace . Represent the MMSE prediction errors by (61) We consider the relation between the biorthogonal grf and the MMSE field . This leads in the next subsection to a representation for (58). Introduce the Hilbert space generated by the error field closed linear span of E (62) and likewise for . Recall the definitions of and , see (4). We have the following decompositions.
1568 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 43, NO. 5, SEPTEMBER 1997 Lemma IV.1: Proof of Lemma IV.1: Follows by orthogonality that Also, To show equivalence, pick , . Then which clearly is in . Any is either for some or the limit of a sequence of such, which proves the decomposition in Lemma IV.1. From this Lemma, the following decomposition holds:(63) Now consider the RKHS and let be the subspace of elements with . By locality of the space, (64) Theorem IV.1: The image of under the isometric isomorphism is , i.e., The proof in Appendix II proceeds in three steps. We show: i) ; ii) is closed in ; iii) the orthogonal complement in of is the empty set, i.e., . The last step shows that the two spaces are equivalent and the conclusion of the theorem follows. Remark: By Theorem IV.1, the range of the inverse of the isometric isomorphism is (65) MMSE Predictor: We can use Theorem IV.1 to get a representation for the MMSE predictor. By orthogonality since , the MMSE error field and the MMSE predictor and by decomposition (63) these spaces are orthogonal. Then, let for and By Theorem IV.1, . By isometry of and by orthogonality, it follows that Since this is true for every , we have that the image under of is the (weak) solution to in (66) with boundary conditions (67) where are derivatives along normal directions to the boundary and is the order of the operator . C. Canonical MMSE Sample Path Representation Riesz Representability of : We derive the representation for the partial differential equation (58) for . By using Theorem IV.1, since Using (54), we conclude that Hence, either E or the limit of such E This representation for the biorthogonal grf is not totally satisfactory. We want to represent as resulting from an integral operation on the prediction errors. What is needed is Riesz-type representability, see for example [25], for . We address this issue next. We first introduce this notion formally. Represent by the space of absolutely integrable functions with respect to measure and by the space of bounded functions with values in the Banach space .Definition IV.1: A bounded linear operator where is a Banach space, is Riesz representable if there exists such that From [25, pp. 63 and 64, Theorems 5 and 6], we have that if has a boundedly complete Schauder basis, then a linear continuous operator is representable. In the problem with which we are concerned so that is a Hilbert space. For a separable Hilbert space, any orthogonal basis is a boundedly complete Schauder basis. Thus will be Riesz representable if we can show that it is continuous. We first show that is continuous and then invoke the open mapping theorem to show that is continuous. We need the additional assumption. Assumption: Let , , and bounded subsets of and let be the Lebesgue measure on . We assume that , which is closed as a subspace of and which is a subspace of , is closed as a subspace of . We consider as a linear operator from the closed subspace of to a closed subspace of . Call this latter subspace .
MOURA AND GOSWAMI: GAUSS-MARKOV RANDOM FIELDS (GMrf) WITH CONTINUOUS INDICES 1569 Theorem IV.2: Let E Then is continuous. Proof of Theorem IV.2: The map is and onto (since is an isometric isomorphism). We show that is continuous. The conclusion of the theorem follows by application of the corollary to the Open Mapping Theorem in Rudin [26, p. 49], that shows then is continuous. E E E by Schwartz inequality E By the last step, is continuous. So is its inverse by the open mapping theorem as desired. Remark: Since by Schwartz inequality E E the condition in Theorem IV.2 is weaker than the finite energy requirement (39) on the field. MMSE Sample Path Representation: We obtain the representation for the biorthogonal grf in terms of the error field. By Theorem IV.2 and by Riesz representability, see Definition IV.1, there exists a family of random variables such that for each , we have and (68) (69) This is a representation of the abstract (58) as (70) Equation (70) is the weak formulation of (71) Of course, by the biorthogonality condition (41) E E or, formally, E (72) Equation (72) states the orthogonality condition between the GMrf and the field . The field is the continuous index equivalent of the MMSE-correlated predictor noise in the discrete case, see [4] and [5]. We compute the covariance of the prediction error noise . For that, we recall (57) E (73) Substituting in (73) by the value given by (69), we get E E (74) E (75) Equations (73) and (75) state that, in a distributional sense E (76) i.e., that the covariance of is formally equivalent to the differential operator whose Green's function is the GMrf covariance. V. CONCLUSION The paper considered the covariance and the sample path representations for Gauss-Markov random fields indexed by continuous indices in higher dimensions. The paper satisfactorily parallels the corresponding discrete GMrf results, see [5]. The covariance of the GMrf is the Green's function of a positive symmetric formally self-adjoint partial differential operator (77) with appropriate boundary conditions. The order of the field with continuous indices is half the order of the differential operator . Secondly, the MMSE sample path representation for the GMrf is formally (78) where, by (72) and (76) E and E (79) The random input noise field is orthogonal to the GMrf and is correlated, with covariance acting like the differential operator . These results are in a certain sense canonical. The operator appears in the field covariance description (77), in the MMSE representation (78), and defines the correlated noise covariance (79). We refer to it as the field canonical operator.
1570 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 43, NO. 5, SEPTEMBER 1997 APPENDIX I ACAUSAL MARKOV PROPERTY Let , , , and be as in Section II. Following Pitt [12], we introduce the following -algebra: (80) where stands for the -algebra generated by the collection of elements included in . Likewise for . Let be a metric in , for example, the Euclidean metric. Define the distance from a point to a set as For , introduce (81) The set is a neighborhood of . Further, define the following -algebras: (82) (83) (84) We introduce the Markov property in terms of splitting -algebras. We discuss these first. Splitting -Algebra Let and be sub--algebras of the -algebra . Let be a sub--algebra of . Following McKean [10] and Pitt [12], and split over , or is a splitting -algebra of and iff and are conditionally independent given . There is a minimal splitting algebra, [12], given by E bounded and -measurable (85) For any splitting -algebra , we have that . Also(86) The acausal Markov property is now defined, see [12]. We refer to it simply as the Markov property. Definition A.1-Markov Property: The field is Markov iff for every open set with smooth boundary the following two conditions hold: 1) Continuity . 2) Minimal splitting field: Conditional independence is the minimal splitting algebra of and . From the continuity condition, it is clear that the boundary -algebra is contained in the "past" -algebra and in the "future" -algebra and so in their intersection. From (86), we then have (87) where is the minimal splitting-algebra of and of . The conditional independence condition states that is in fact the minimal splitting field. Remark: The Markov property in Definition A.1 requires more than simply boundary data about the field. Besides information about the field on the boundary , contains derivative information about the field, see McKean [10] for details. The -algebra is referred to in the literature as the germ -algebra, [27]. This is in general different from the -algebra generated by the boundary data (88) which is the so-called sharp -algebra. Conditions under which the germ and the sharp -algebra are equivalent are studied in [27]. The Markov property with respect to the sharp field is called sharp Markov. The sharp Markov property may lead to degenerate fields. For example, sharp Markov with respect to open discs with the additional assumption of isotropy, i.e., with a covariance which depends only on the distance, leads to constant fields, see [28]. APPENDIX II PROOFS Proof of Theorem III.1 By the Markov property, see Definition II.4, the RKHS is a local space. We now verify that the inner product satisfies the "honesty condition" stated in Section IIB. If satisfies the "honesty condition," then, as stated in the same subsection, the inner product is given by a Dirichlet form. An inner product satisfies the "honesty condition" if in and implies that . Recall the isometric isomorphism between spaces and , see (10), and let . Since in , we have for all as . Therefore, tends weakly to in . Also, since the are Cauchy in , through the isometric mapping , we see that the corresponding are Cauchy in . Therefore, being complete, converges strongly to some in . Since strong limit implies weak limit, when both exist they have to be equal, and so must be . Therefore, converges to in the metric of the inner product in . Hence, again by the isometry , converges to in the metric of the inner product in , , which verifies the "honesty condition." We have shown that the inner product is given by a Dirichlet form, see (22). So (89) By the reproducing kernel property RKHS2 of (90) (91)
MOURA AND GOSWAMI: GAUSS-MARKOV RANDOM FIELDS (GMrf) WITH CONTINUOUS INDICES 1571 Integration by parts of (91) leads to (92) Recalling the definition of the operator in (18), (92) gives In a distributional sense, this defines the covariance as the fundamental solution of (93) The bc's associated with (93) are the values of the field covariance at the boundary, see (3), i.e., zero Dirichlet bc's. This proves the Theorem. Proof of Theorem III.2 Let be the space which is the completion of under . The proof is in three steps. First, we show that is local, then that it is an RKHS, and finally, we associate with a GMrf. is Local: We verify the two conditions Local1 and Local2 through a limiting argument. Let and be complementary sets, and with and . Because is dense in , there are sequences and , and . For each of these, by direct computation implying in the limit that which verifies condition Local1. For Local2, let , with and as in Local2. Then, because and have disjoint supports, which shows and , hence as desired. This shows is local. is an RKHS: We show that the pointwise evaluation of functions is a continuous linear functional. This follows if (25) holds for all , not just for . We use a limiting argument. Let . Then there exists a sequence such that . From (25), since the are in The space is closed under . Since is a convergent sequence, it is Cauchy in the sense of . So, for large there exists a small that bounds above the right-hand side of the previous equation, i.e., This equation says that if is Cauchy under the inner product norm , then it is Cauchy under the norm. Therefore, (25) holds for all , showing that pointwise evaluation of functions is a linear continuous functional on and the space is an RKHS. Construction of GMrf: We associate with the RKHS a Gauss field. The covariance of the field is the reproducing kernel of . We determine this reproducing kernel. Let be the Green's function of . In a distributional sense (94) From this property of , it follows (95) The right-hand side of this equation can be written in terms of the inner product in . We then have (96) A standard limiting argument shows that satisfies zero Dirichlet boundary conditions, since (it is well known that it spans the RKHS) we can find such that and so for . This shows that the Green's function of is the reproducing kernel of the RKHS and hence the covariance of the field. Finally, by the smoothness on , the kernel is smooth of order (see (37)). Then, the continuity condition (24) follows by arguments similar to those in [12] (see the proof in [12, p. 374, Theorem 3.3]). Hence the RKHS being local, the field is Markov. Proof of Corollary III.1 By the Sobolev embedding, see (16), Sobolev spaces are RKHS. By Lemma II.2, Sobolev spaces are local spaces. Then, by Theorem III.2, the covariance is the Green's function of the operator associated with the inner product of . To show that is strongly elliptic, we recall the fact that if two norms generate the same topology they are equivalent. The norms and being the Sobolev space standard norm and the norm induced by the inner product, respectively, generate the same space, namely, the Sobolev space , so they are equivalent. By the equivalence of these two norms, see for example [19, p. 261, Corollary 5.9.4], we can bound below the norm induced by the inner product by the Sobolev standard norm. For some This implies, see [16], that the operator is strongly elliptic. Finally, the continuity condition (24) follows by an argument similar to that used in the proof of Theorem III.2, and the field is Markov.
1572 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 43, NO. 5, SEPTEMBER 1997 Proof of Theorem III.3 In this proof we need the concept of coercivity. Definition A.2-Coercive Bilinear Form: Let be a Sobolev space of order . A bilinear form defined on is coercive iff there exist constants and such that Garding's inequality: (97) where is the Sobolev standard norm in given by (14). Let the operator be given as in (18) and associate with it a bilinear form as given by (97). On , define the bilinear form (98) By the smoothness of the coefficients of , and the fact that is bounded there is a positive constant such that (99) We show that the completion of by the bilinear form generates the Sobolev space by proving the equivalence of the standard Sobolev norm defined by (14) and the norm induced by the bilinear form . We first show that the norm induced by is dominated by the standard Sobolev norm. (100) (101) (102) (103) (104) (105) Equation (101) follows from (100) simply by bringing the magnitude signs inside the sum and the integrals. The next step, (102), uses the boundedness condition on the coefficients, see (99). The two following steps, (103) and (104), are applications of Schwartz inequality in a discrete and continuous parameter setting, respectively. The last equality follows by identifying in the first term of the right-hand side the Sobolev norm and bounding the second term by this norm. We now consider the reverse inequality. Garding's Theorem, see Wloka [16, p. 291, Theorem 19.2], states that, for bounded, if the bilinear form has continuous coefficients up to the boundary, i.e., for all , the strong ellipticity of on is a necessary and sufficient condition for the coercivity of the bilinear form . In our case, is strongly elliptic with smooth coefficients, so that the bilinear form is coercive. Hence, there exist constants and , such that (106) This is G?arding's inequality, for example see [16] and [19]. Putting together the two inequalities (105) and (106) (107) Therefore, the norm induced by and the standard norm are equivalent. Hence, the closure of under generates the Sobolev space of order . Let be the Green's function of and take . The inner product in is the inner product induced by the bilinear form in (98). Then (108) (109) (110) The third equality follows because is the Green's function of and so is in a distributional sense a delta function. But equalities (108)-(110) state the reproducing kernel property. Therefore, is the reproducing kernel and so it is the covariance of the associated GMrf. Remark: The proof of the Theorem uses only the boundedness of the coefficients in the associated bilinear form, see (99). Given the boundedness of the domain, this requires only continuity of the coefficients of the bilinear form, not the stronger condition in (34). Proof of Corollary III.2 For as in (35), which is restricted to the highest order terms, it can be shown that, in G?arding's inequality (106), see [19, p. 514, proof of Theorem 7.7.2], can be taken to be zero, and so (111) Likewise, by arguments similar to the ones used in the proof of Theorem III.3, there is a sufficiently large such that
MOURA AND GOSWAMI: GAUSS-MARKOV RANDOM FIELDS (GMrf) WITH CONTINUOUS INDICES 1573 Therefore, the norm is equivalent to on . The reproducing kernel is the Green's function of the operator given by (35). Proof of Theorem IV.1 We mentioned below the theorem that the proof follows in three steps. We prove that . From the definition of , see (49), for some E E E E When and , by the orthogonality principle, the last equation is zero. This means that the function E when and i.e., the function has support in . Therefore, it is in and so for E By a limiting argument, we can conclude that which proves the first step. We consider now the second step that is closed in . The image is closed because is an isometric isomorphism and is closed. We address the final step that . Let By the definition of , there exists such that E (112) E (113) The second equality follows from the fact that was chosen from and so with . From (113) (114) Since is also chosen to be orthogonal to (115) (116) Since from (112) Equation (116) states that E (117) i.e., (118) Equations (114) and (118) imply that which in turn implies This proves the Theorem. REFERENCES [1] G. Christakos, Random Field Models in Earth Sciences. New York: Academic, 1992. [2] J. J. O'Brien, Advanced Physical Oceanographic Numerical Modelling. Dordrecht, The Netherlands: D. Reidel, 1986. [3] E. Wong and B. Hajek, Stochastic Processes in Engineering Systems. New York: Springer-Verlag, 1985. [4] J. W.Woods, "Two-dimensional discrete Markovian fields," IEEE Trans. Inform. Theory, vol. IT-18, pp. 232-240, 1972. [5] J. M. F. Moura and N. Balram, "Recursive structure of noncausal Gauss Markov random fields," IEEE Trans. Inform. Theory, vol. 38, pp. 334-354, Mar. 1992. [6] , "Statistical algorithms for noncausal Markov random fields" (invited), in Handbook of Statistics, N. K. Bose and C. R. Rao, Eds. Amsterdam, The Netherlands: North Holland, July 1993, ch. 15, pp. 623-691. [7] E. Wong, "Recursive causal linear filtering for two-dimensional random fields," IEEE Trans. Inform. Theory, vol. IT-24, pp. 50-59, Jan. 1978. [8] R. G. Ogier and E. Wong, "Recursive linear smoothing for twodimensional random fields," IEEE Trans. Inform. Theory, vol. IT-27, pp. 72-82, Jan. 1981. [9] A. H. Tewfik, B. C. Levy, and A. S. Willsky, "Internal models and recursive estimation for 2-D isotropic random fields," IEEE Trans. Inform. Theory, vol. 37, pp. 1055-1066, July 1991. [10] H. P. McKean, Jr., "Brownian motion with a several-dimensional time," Theory of Probab. Its Appl., vol. VIII, no. 4, pp. 335-354, 1963. [11] G. M. Molcan, "Characterization of Gaussian fields with Markovian property," Sov. Math.-Dokl., vol. 12, no. 2, pp. 563-567, 1971. [12] L. D. Pitt, "A Markov property for Gaussian processes with a multidimensional parameter," Arch. Ration. Mech. Anal., vol. 43, pp. 367-391, 1971. [13] Y. A. Rozanov, Markov Random Fields. New York: Springer-Verlag, 1982. [14] A. J. Krener, "Reciprocal diffusions and stochastic differential equations of second order," Stochastics, vol. 24, pp. 393-422, 1988. [15] A. J. Krener, R. Frezza, and B. C. Levy, "Gaussian reciprocal processes and self-adjoint stochastic differential equations of second order," Inst. Theor. Dyn., Univ. of Calif., Davis, Tech. Rep., Mar. 1990. [16] J. Wloka, Partial Differential Equations. Cambridge, UK: Cambridge Univ. Press, 1987. [17] T. Hida, Brownian Motion. New York: Springer-Verlag, 1980. [18] R. A. Adams, Sobolev Spaces. New York: Academic, 1978. [19] A. W. Naylor and G. R. Sell, Linear Operator Theory in Engineering and Science, 2nd ed. New York: Springer-Verlag, 1982. [20] J. Glimm and A. Jaffe, Quantum Physics, A Functional Integral Point of View, 2nd ed. New York: Springer-Verlag, 1987. [21] J. Peetre, "Rectification a l'article 'Une charact?erization abstraite des op?erateurs diff?erentiels'," Math. Scand., vol. 8, pp. 116-120, 1960. [22] E. Nelson, "Construction of quantum fields from Markoff fields," J. Functional Anal., vol. 12, pp. 97-112, 1973. [23] , "The free Markoff field," J. Functional Anal., vol. 12, pp. 211-227, 1973. [24] G. Kallianpur and V. Mandrekar, "The Markov property for generalized random fields," Ann. Inst. Fourier, vol. 24, no. 2, pp. 143-167, 1974. [25] J. Diestel and J. J. Uhl, Jr., Vector Measures. Providence, RI: Amer. Math. Soc., 1977. [26] W. Rudin, Principles of Mathematical Analysis, 2nd ed. New York: McGraw-Hill, 1964. [27] L. D. Pitt and R. S. Robeva, "On the sharp Markov property for the Whittle field in 2-dimensions," in Stochastic Analysis in Infinite Dimensional Spaces (Research Notes in Mathematics), Kunita and Kuo, Eds. Belmont, CA: Pitman, 1994,. [28] M. I. Yadrenko, Spectral Theory of Random Fields. New York: Optimization Software Inc., 1983.