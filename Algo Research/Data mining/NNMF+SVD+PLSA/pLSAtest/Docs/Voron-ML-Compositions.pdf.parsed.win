
Лекции по алгоритмическим композициям К. В. Воронцов 24 июня 2010 г. Материал находится в стадии разработки, может содержать ошибки и неточности. Автор будет благодарен за любые замечания и предложения, направленные по адресу vokov@forecsys.ru, либо высказанные в обсуждении страницы ?Машинное обучение (курс лекций, К.В.Воронцов)? вики-ресурса www.MachineLearning.ru. Перепечатка фрагментов данного материала без согласия автора является плагиатом. Содержание 1 Композиции алгоритмов 2 1.1 Понятие композиции алгоритмов . . . . . . . . . . . . . . . . . . . . . . 2 1.2 Бустинг в задачах классификации . . . . . . . . . . . . . . . . . . . . . . 4 1.2.1 Алгоритм AdaBoost . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.2.2 Алгоритм AnyBoost . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.2.3 Голосование по большинству . . . . . . . . . . . . . . . . . . . . . 9 1.2.4 Голосование по старшинству . . . . . . . . . . . . . . . . . . . . . 13 1.3 Стохастические методы построения композиций . . . . . . . . . . . . . . 15 1.3.1 Бэггинг и метод случайных подпространств . . . . . . . . . . . . 15 1.3.2 Кооперативная коэволюция . . . . . . . . . . . . . . . . . . . . . 17 1.4 Квазилинейные композиции (смеси алгоритмов) . . . . . . . . . . . . . . 20 1.4.1 Выпуклые функции потерь . . . . . . . . . . . . . . . . . . . . . . 22 1.4.2 Последовательный метод построения смеси . . . . . . . . . . . . 23 1.4.3 Иерархический метод построения смеси . . . . . . . . . . . . . . 26 1.5 Нелинейные монотонные композиции . . . . . . . . . . . . . . . . . . . . 28 1.5.1 Оптимизация базовых алгоритмов . . . . . . . . . . . . . . . . . . 30 1.5.2 Монотонная интерполяция и аппроксимация . . . . . . . . . . . 33 1.6 Краткий обзор литературы . . . . . . . . . . . . . . . . . . . . . . . . . . 36
2 1 Композиции алгоритмов При решении сложных задач классификации, регрессии, прогнозирования ча- сто оказывается, что ни один из алгоритмов не обеспечивает желаемого качества восстановления зависимости. В таких случаях имеет смысл строить композиции ал- горитмов, в которых ошибки отдельных алгоритмов взаимно компенсируются. Наи- более известные примеры композиций простое и взвешенное голосование. В данной главе рассматриваются и другие типы композиций голосование по старшинству, смеси и монотонные корректоры. Напомним основные обозначения. Рассматривается задача обучения по прецедентам hX, Y, y?,X?i, где X про- странство объектов; Y множество ответов; y? : X > Y неизвестная целевая зависимость; X? = (x1, . . . , x?) обучающая выборка; Y ? = (y1, . . . , y?) вектор от- ветов на обучающих объектах, yi = y?(xi). Требуется построить алгоритм a: X > Y , аппроксимирующий целевую зависимость y? на всём множестве X. :1.1 Понятие композиции алгоритмов Наиболее общее определение алгоритмической композиции даётся в алгебраи- ческом подходе Ю. И.Журавлёва [6]. Наряду с множествами X и Y вводится вспо- могательное множество R, называемое пространством оценок. Рассматриваются ал- горитмы, имеющие вид суперпозиции a(x) = C(b(x)), где функция b : X > R назы- вается алгоритмическим оператором, функция C : R > Y решающим правилом. Многие алгоритмы классификации имеют именно такую структуру: сначала вычисляются оценки принадлежности объекта классам, затем решающее правило переводит эти оценки в номер класса. Значением оценки b(x) может быть вероят- ность принадлежности объекта x классу, расстояние от объекта до разделяющей поверхности, степень уверенности классификации и т. п. Опр. 1.1. Композицией алгоритмов at(x) = C(bt(x)), t = 1, . . . , T называется суперпозиция алгоритмических операторов bt : X > R, корректирующей операции F : RT > R и решающего правила C : R > Y : a(x) = C??F(b1(x), . . . , bT (x)), x ? X. (1.1) Алгоритмы at, а иногда и операторы bt, называют базовыми алгоритмами. Суперпозиции вида F(b1, . . . , bT ) являются отображениями из X в R, то есть, опять-таки, алгоритмическими операторами. Это позволяет строить иерархические композиции, применяя определение 1.1 рекурсивно. Пространство оценок R вводится для того, чтобы расширить множество допу- стимых корректирующих операций. Можно было бы определить корректирующую операцию и как отображение F : Y T > Y , то есть комбинировать непосредственно ответы базовых алгоритмов. Однако в задачах классификации, когда множество Y конечно, число ?разумных? корректирующих операций такого вида невелико, что ограничивает возможность оптимизации F под конкретную задачу [6]. Если же ком- бинировать ответы алгоритмических операторов, то операция F получает на входе более детальную информацию, не огрублённую решающим правилом.
3 Пример 1.1. В задачах классификации на два класса, Y = {?1,+1}, в качестве пространства оценок обычно используется множество действительных чисел R = R. В этом случае алгоритмические операторы называют также вещественнозначными классификаторами (real-valued classifiers): C(b(x)) = sign b(x). Пример 1.2. В задачах классификации на M классов, Y = {1, . . . ,M}, в каче- стве пространства оценок обычно используется R = RM. Алгоритмический опе- ратор b(x) выдаёт вектор оценок принадлежности объекта x каждому из классов, b(x) = ??b1(x), . . . , bM(x). Решающее правило C относит объект к тому классу, для которого оценка максимальна: C(b(x)) ? C??b1(x), . . . , bM(x)= argmax y?Y by(x). В частности, именно такой вид имеют байесовские алгоритмы классификации из гла- вы ?? и метрические алгоритмы из ??. Взвешенное голосование. Корректирующая операция F может иметь параметры, настраиваемые по обучающей выборке, наряду с параметрами базовых алгоритмов. Например, в линейной комбинации настраиваются веса ?t базовых алгоритмов: b(x) = F??b1(x), . . . , bT (x)=XT t=1 ?tbt(x), x ? X, ?t ? R. (1.2) Если веса ?t неотрицательны и нормированы, PTt=1 ?t = 1, то композицию (1.2) называют выпуклой комбинацией базовых алгоритмов. Естественно предполагать, что вес ?t тем больше, чем выше качество базового алгоритма bt. В задачах классификации корректирующая операция (1.2) называется взвешен- ным голосованием (weighted voting). Пример 1.3. Рассмотрим задачу классификации с двумя классами, Y = {?1,+1}, и двухслойную нейронную сеть, принимающую на входе n-мерный вектор признаков, x = (x1, . . . , xn), x ? X = Rn: a(x) = signXT t=1 wt?Xn j=1 wjtxj, где T число нейронов скрытого слоя, wjt вес связи между j-м признаком и t-м нейроном скрытого слоя, wt вес связи между t-м нейроном скрытого слоя и выход- ным нейроном, ? функция активации. Такая сеть может рассматриваться как ком- позиция алгоритмических операторов вида bt(x) = ???Pnj=1 wjtxjc линейной коррек- тирующей операцией F(b1, . . . , bT ) = PTt=1 wtbt и решающим правилом C(b) = sign b.
4 -5 -4 -3 -2 -1 0 1 2 3 4 5 012345 S L V E Q z Рис. 1. Гладкие верхние аппроксимации по- роговой функции потерь [z < 0]: S(z) = 2(1 + ez)?1 сигмоидная; L(z) = log2(1+e?z) логарифмическая; V (z) = (1 ? z)+ кусочно-линейная; E(z) = e?z экспоненциальная; Q(z) = (1 ? z)2 квадратичная. :1.2 Бустинг в задачах классификации Рассмотрим задачу классификации на два класса, Y = {?1,+1}. Допустим, что решающее правило фиксировано, C(b) = sign(b), базовые алгоритмы возвращают от- веты ?1, 0, +1. Ответ bt(x) = 0 означает, что базовый алгоритм bt отказывается от классификации объекта x, и ответ bt(x) не учитывается в композиции. Искомая алгоритмическая композиция имеет вид: a(x) = C??F(b1(x), . . . , bT (x))= signXT t=1 ?tbt(x), x ? X. (1.3) Определим функционал качества композиции как число ошибок, допускаемых ею на обучающей выборке: QT = X? i=1 yi XT t=1 ?tbt(xi) < 0. (1.4) Для упрощения задачи минимизации функционала QT введём две эвристики. Эвристика 1. При добавлении в композицию слагаемого ?tbt(x) оптимизируется только базовый алгоритм bt и коэффициент при нём ?t, а все предыдущие слагаемые ?1b1(x), . . . , ?t?1bt?1(x) полагаются фиксированными. Эвристика 2. Пороговая функция потерь в функционале Qt аппроксимируется (заменяется) непрерывно дифференцируемой оценкой сверху. Вторая эвристика широко используется в теории классификации. В частности, логарифмическая функция связана с принципом максимума правдоподобия и при- меняется в нейронных сетях (см. ??) и логистической регрессии (см. ??). Кусочно- линейная аппроксимация связана с принципом максимизации зазора между класса- ми и применяется в методе опорных векторов (см. ??). Примеры других аппроксима- ций показаны на Рис. 1. Все эти функции можно использовать, получая различные варианты бустинга. Начнём с экспоненциальной аппроксимации, которая историче- ски была самой первой. 1.2.1 Алгоритм AdaBoost При использовании экспоненциальной аппроксимации yib(xi) < 06 e?yib(xi) эти две эвристики приводят к широко известному алгоритму AdaBoost [37].
5 Оценим функционал QT сверху: QT 6 eQT =X? i=1 exp?yi XT t=1 ?tbt(xi)= = X? i=1 exp?yi XT?1 t=1 ?tbt(xi)| {z } wi e?yi?T bT (xi). (1.5) Заметим, что введённые здесь веса объектов wi не зависят от ?T bT и могут быть вычислены перед построением базового алгоритма bT . Введём вектор нормированных весов fW? = ?? ? w1, . . . , ? w?, где ? wi = wi P?j=1 wj . Определим два функционала качества алгоритма классификации b на обуча- ющей выборке X?, Y ? с нормированным вектором весов объектов U? = (u1, . . . , u?): суммарный вес ошибочных (negative) классификаций N(b; U?) и суммарный вес пра- вильных (positive) классификаций P(b; U?): N(b; U?) = X? i=1 uib(xi) = ?yi; P(b; U?) = X? i=1 uib(xi) = yi. Заметим, что 1 ? N ? P есть суммарный вес отказов от классификации. Если отказов нет, то N + P = 1. Теорема 1.1. Пусть для любого нормированного вектора весов U? существует ба- зовый алгоритм b, классифицирующий выборку хотя бы немного лучше, чем наугад: P(b; U?) > N(b; U?). Тогда минимум функционала eQT достигается при bT = argmax b qP(b;fW?) ?qN(b;fW?). ?T = 12 ln P(bT ;fW?) N(bT ;fW?) . Доказательство. Воспользуемся тождеством e??b = e??[b=1] + e?[b=?1]+ [b=0], справедливым для любых ? ? R, b ? {?1, 0,+1}. Положим для краткости ? = ?T и bi = bT (xi). Тогда (1.5) примет вид eQT = e?? X? i=1 ? wi[bi=yi] | {z } P + e? X? i=1 ? wi[bi=?yi] | {z } N + X? i=1 ? wi[bi=0] | {z } 1?P?N X? i=1 wi | {z } eQT?1 = = ??e??P + e?N + (1 ? P ? N)eQT?1, Дифференцируя eQT по параметру ? и приравнивая нулю производную, полу- чим оптимальное значение ?T = 12 ln PN .
6 Подставляя его обратно в eQT , получим eQT = eQT?11 ? ??vP ? vN2. (1.6) Поскольку eQT?1 не зависит от ?T и bT , минимизация eQT эквивалентна либо максимизации vP ? vN при P > N, либо максимизации vN ? vP при P < N, од- нако второй случай исключён условием теоремы. Требование, чтобы каждый базовый алгоритм классифицировал объекты хо- тя бы немного лучше, чем наугад, является достаточно слабым, и на практике, как правило, выполняется. Более того, этого оказывается достаточно, чтобы гарантиро- вать сходимость алгоритма AdaBoost за конечное число шагов. Теорема 1.2. Если на каждом шаге метод обучения обеспечивает построение ба- зового алгоритма bt такого, что qP(bt;fW?) ? qN(bt;fW?) = ?t > ? при некотором ? > 0, то за конечное число шагов будет построен корректный алгоритм a(x). Доказательство. Непосредственно из (1.6) вытекает сходимость функционала QT к нулю со ско- ростью геометрической прогрессии: QT+1 6 eQT+1 6 eQ1(1 ? ?2)T . Наступит момент, когда значение eQT окажется меньше 1. Но тогда функционал QT обратится в нуль, поскольку он может принимать только целые неотрицательные значения. На практике сходимость может и не достигаться, если модель базовых алгорит- мов не достаточно ?богата?. В таких случаях значения ?t сходятся к нулю настолько быстро, что QT , наоборот, не успевает сойтись к нулю. Реализация AdaBoost показана в Алгоритме 1.1 для важного частного случая, когда базовые алгоритмы не отказываются от классификации (N + P = 1). Теорема 1.3. Пусть базовые алгоритмы не отказываются от классификации, и для любого нормированного вектора весов W? существует базовый алгоритм b, классифи- цирующий выборку хотя бы немного лучше, чем наугад: N(b; U?) < 12 . Тогда минимум функционала eQT достигается при bT = argmin b N(b;fW?); ?T = 12 ln 1 ? N(bT ;fW?) N(bT ;fW?) . В данном случае задача построения базового алгоритма bT по обучающей вы- борке X? решается путём минимизации функционала взвешенной частоты ошибок, который отличается от стандартного эмпирического риска (частоты ошибок) толь- ко тем, что объекты учитываются с весами wi. Стандартные методы минимизации эмпирического риска, как правило, легко обобщаются на этот случай. Некоторых комментариев заслуживает правило мультипликативного пересчёта весов на шаге 5. Оно вытекает непосредственно из определения wi в (1.5). Вес объ- екта увеличивается в e?t раз, когда bt допускает на нём ошибку, и во столько же раз уменьшается, когда bt правильно классифицирует xi. Таким образом, непосред- ственно перед настройкой базового алгоритма наибольший вес накапливается у тех объектов, которые чаще оказывались трудными для предыдущих алгоритмов.
7 Алгоритм 1.1. AdaBoost построение линейной комбинации классификаторов Вход: X?, Y ? обучающая выборка; T максимальное число базовых алгоритмов; Выход: базовые алгоритмы и их веса ?tbt, t = 1, . . . , T; 1: инициализация весов объектов: wi := 1/?, i = 1, . . . , ?; 2: для всех t = 1, . . . , T, пока не выполнен критерий останова 3: bt := argmin b N(b;W?); 4: ?t := 12 ln 1 ? N(bt;W?) N(bt;W?) ; 5: пересчёт весов объектов: wi := wi exp????tyibt(xi), i = 1, . . . , ?; 6: нормировка весов объектов: w0 := P?j=1 wj ; wi := wi/w0, i = 1, . . . , ?; Фильтрация выбросов. После построения некоторого количества базовых алго- ритмов (скажем, пары десятков) имеет смысл проанализировать распределение ве- сов объектов. Объекты с наибольшими весами wi, скорее всего, являются шумовы- ми выбросами, которые стоит исключить из выборки, после чего начать построение композиции заново. Вообще, бустинг можно использовать как универсальный метод фильтрации выбросов перед применением любого другого метода классификации. Обобщающая способность бустинга. В течение последних 10 лет бустинг остаётся одним из наиболее популярных методов машинного обучения, наряду с нейронны- ми сетями и машинами опорных векторов. Основные причины простота, универ- сальность, гибкость (возможность построения различных модификаций), и, главное, неожиданно высокая обобщающая способность. Бустинг над решающими деревьями считается одним из наиболее эффективных методов с точки зрения качества классификации. Во многих экспериментах наблю- далось практически неограниченное уменьшение частоты ошибок на независимой тестовой выборке по мере наращивания композиции. Более того, качество на тесто- вой выборке часто продолжало улучшаться даже после достижения безошибочного распознавания всей обучающей выборки [23]. Это перевернуло существовавшие дол- гое время представления о том, что для повышения обобщающей способности необ- ходимо ограничивать сложность алгоритмов. На примере бустинга стало понятно, что хорошим качеством могут обладать сколь угодно сложные композиции, если их ?правильно настраивать?. Впоследствии феномен бустинга получил теоретическое обоснование. Оказа- лось, что взвешенное голосование не увеличивает эффективную сложность алгорит- ма, а лишь сглаживает ответы базовых алгоритмов. Количественные оценки обобща- ющей способности бустинга формулируются в терминах отступа [18]. Эффективность бустинга объясняется тем, что по мере добавления базовых алгоритмов увеличивают- ся отступы обучающих объектов Mi = yiPTt=1 ?tbt(xi). Причём бустинг продолжает ?раздвигать? классы даже после достижения безошибочной классификации обуча- ющей выборки.
8 К сожалению, теоретические оценки обобщающей способности [18] дают лишь качественное обоснование феномену бустинга. Хотя они существенно точнее более общих оценок Вапника-Червоненкиса [42], всё же они сильно завышены, и требуемая длина обучающей выборки оценивается величиной порядка 104 . . . 106. Более основательные эксперименты показали, что иногда бустинг всё же пере- обучается [36, 35]. По мнению автора статьи [25] причины эффективности бустинга до конца ещё не поняты и его дальнейшее улучшение остаётся открытой проблемой. Достоинства AdaBoost. : Хорошая обобщающая способность. В реальных задачах (не всегда, но часто) удаётся строить композиции, превосходящие по качеству базовые алгоритмы. Обобщающая способность может улучшаться (в некоторых задачах) по мере увеличения числа базовых алгоритмов. : Простота реализации. : Накладные расходы бустинга невелики. Время построения композиции прак- тически полностью определяется временем обучения базовых алгоритмов. : Возможность идентифицировать выбросы. Это наиболее ?трудные? объекты xi, для которых в процессе наращивания композиции веса wi принимают наиболь- шие значения. Недостатки AdaBoost. : AdaBoost склонен к переобучению при наличии значительного уровня шума в данных. Экспоненциальная функция потерь слишком сильно увеличивает ве- са ?наиболее трудных? объектов, на которых ошибаются многие базовые ал- горитмы. Однако именно эти объекты чаще всего оказываются шумовыми вы- бросами. В результате AdaBoost начинает настраиваться на шум, что ведёт к переобучению. Проблема решается путём удаления выбросов или примене- ния менее ?агрессивных? функций потерь. В частности, алгоритм LogitBoost использует логистическую функцию [24]. : AdaBoost требует достаточно длинных обучающих выборок. Другие методы линейной коррекции, в частности, бэггинг, способны строить алгоритмы сопо- ставимого качества по меньшим выборкам данных. : Жадная стратегия последовательного добавления приводит к построению неоптимального набора базовых алгоритмов. Для улучшения композиции мож- но периодически возвращаться к ранее построенным алгоритмам и обучать их заново. Для улучшения коэффициентов ?t можно оптимизировать их ещё раз по окончании процесса бустинга с помощью какого-нибудь стандартного метода построения линейной разделяющей поверхности. Рекомендуется использовать для этой цели SVM машины опорных векторов [43]. : Бустинг может приводить к построению громоздких композиций, состоящих из сотен алгоритмов. Такие композиции исключают возможность содержатель- ной интерпретации, требуют больших объёмов памяти для хранения базовых алгоритмов и существенных затрат времени на вычисление классификаций.
9 1.2.2 Алгоритм AnyBoost Алгоритм бустинга несложно обобщается на тот случай, когда пороговая функ- ция потерь оценивается сверху произвольной невозрастающей функцией отсту- па L(M), не обязательно экспонентой, а базовые алгоритмы bt возвращают произ- вольные вещественные значения, не обязательно ±1. По-прежнему рассматривается взвешенное голосование (1.3), но вместо (1.5) записывается оценка QT 6 eQT =X? i=1 Lyi PT t=1 ?tbt(xi) | {z } MT (xi) = X? i=1 L??MT?1(xi) + yi?T bT (xi). (1.7) Рассмотрим функцию потерь L как функцию параметра ?T , ?(?T ) = L??MT?1(xi) + yi?T bT (xi), и линеаризуем её в окрестности значения ?T = 0, разложив в ряд Тейлора и отбросив старшие члены, начиная с квадратичного: ?(?T ) ? ?(0) + ?T?'(0). Это приведёт к линеаризации функционала eQT по параметру ?T : eQT ? X? i=1 L??MT?1(xi)? ?T X? i=1 ?L'??MT?1(xi)| {z } wi yibT (xi), где wi веса объектов. Если параметр ?T фиксирован, то для минимизации eQT необ- ходимо строить базовый алгоритм bT , исходя из принципа явной максимизации от- ступов (direct optimization of margin) [33, 32]: X? i=1 wiyib(xi) > max b . После того, как bT построен, параметр ?T определяется путём одномерной ми- нимизации функционала (1.7). Итерации этих двух шагов приводят к обобщённому алгоритму бустинга AnyBoost [17]. Его подробная запись приведена в Алгоритме 1.2. Утв. 1.4. AnyBoost переходит в AdaBoost при bt : X > {?1,+1} и L(M) = e?M. 1.2.3 Голосование по большинству Рассмотрим задачу классификации с двумя классами Y = {?1,+1}, простран- ством оценок R = R и решающим правилом C(b) = sign(b). В качестве корректи- рующей операции возьмём простое голосование. Рассмотрим функционал качества композиции a, равный числу ошибок на обучении: Q(a;X?) = X? i=1 yia(xi) < 0= X? i=1 |yib1(xi) + -{-z- + yibT (xi}) MiT < 0.
10 Алгоритм 1.2. AnyBoost обобщённый бустинг с произвольной функцией потерь Вход: X?, Y ? обучающая выборка; T максимальное число базовых алгоритмов; Выход: базовые алгоритмы и их веса ?tbt, t = 1, . . . , T; 1: инициализация отступов: Mi := 0, i = 1, . . . , ?; 2: для всех t = 1, . . . , T, пока не выполнен критерий останова 3: bt := argmax b P? i=1wiyib(xi), где wi = ?L'(Mi), i = 1, . . . , ?; 4: ?t := argmin ?>0 P? i=1L??Mi + ?bt(xi)yi; 5: пересчёт отступов: Mi := Mi + ?tbt(xi)yi; i = 1, . . . , ?; Обозначим через Mit отступ (margin) объекта xi, вычисленный для компози- ции из первых t базовых алгоритмов: Mit = yib1(xi) + - - - + yibt(xi). Если отступ отрицателен, Mit < 0, то композиция первых t базовых алгорит- мов допускает ошибку на объекте xi. Чтобы компенсировать ошибки композиции, будем обучать базовый алгоритм bt+1 не на всей выборке X?, а только на объек- тах с наименьшими значениями Mit. Или, что то же самое, будем минимизировать функционал Q(bt+1;W?) с весами объектов wi = [Mit 6 M0]. Выбирать параметр M0 следует так, чтобы в обучающую выборку попало не слишком мало объектов (иначе будут строиться базовые алгоритмы слишком низ- кого качества), но и не слишком много (иначе будут строиться почти одинаковые алгоритмы). Поэтому вместо M0 удобнее ввести параметр длины обучающих подвы- борок ?1 и подбирать его оптимальное значение. Фиксация длины обучения. Упорядочим объекты выборки X? по возрастанию значений отступов Mit. Объекты с одинаковыми отступами Mit, если таковые име- ются, договоримся располагать в случайном порядке. Возьмём первые ?1 объектов упорядоченной выборки, и положим для них wi = 1, для остальных объектов поло- жим wi = 0. Данный вариант представлен в Алгоритме 1.3. Параметр ?1 можно задавать априори или подбирать по критерию минимума ошибок на скользящем контроле. Увеличение ?1 повышает качество базовых алгорит- мов, но уменьшает их различность. В предельном случае, когда ?1 = ?, все базовые алгоритмы становятся одинаковыми и применение коррекции теряет смысл. Оптими- зация параметра ?1 позволяет найти компромисс между качеством и различностью базовых алгоритмов. Обратим внимание, что в описании алгоритма вместо Mit фигурирует Mi, так как при реализации можно записывать Mi,t+1 на место, занимаемое Mit. Оптимизация длины обучения. Вместо фиксации параметра ?1 можно форми- ровать несколько обучающих подвыборок различной длины, и на каждой итерации находить оптимальное значение ?1. Рассмотрим подробнее шаг 6 Алгоритма 1.3.
11 Алгоритм 1.3. Построение композиции для голосования по большинству Параметры: X?, Y ? обучающая выборка; ? метод обучения базовых алгоритмов; ?1 длина обучающих подвыборок; 1: инициализировать веса и отступы: wi := 1; Mi := 0 для всех i = 1, . . . , ?; 2: для всех t = 1, . . . , T, пока не выполнен критерий останова 3: bt := ?(X?, Y ?,W?); 4: Mi := Mi + yibt(xi) для всех i = 1, . . . , ?; 5: упорядочить выборку X? по возрастанию значений отступов Mi; 6: выбрать ?1; 7: wi := [i 6 ?1] для всех i = 1, . . . , ?; В качестве начального приближения разумно взять оптимальное значение ?1 с предыдущей итерации. Затем начать уменьшать ?1, удаляя по одному объекту в порядке убывания отступов Mit. Затем увеличивать ?1, добавляя по одному объекту в порядке возрастания Mit. По каждой подвыборке производится обучение нового ба- зового алгоритма. В итоге выбирается тот вариант базового алгоритма, для которого функционал качества всей композиции принимает оптимальное значение. Качество композиции предпочтительно оценивать на контрольных данных, если имеется такая возможность. Построение алгоритма путём удаления/добавления одного из обучающих объ- ектов для многих методов (в частности, для SVM) производится намного эффек- тивнее, чем перенастройка алгоритма заново по всей выборке. Для таких методов описанный способ позволяет довольно быстро находить оптимальное значение пара- метра ?1 на каждой итерации. Идентификация выбросов. В практических задачах выборка, как правило, содер- жит некоторое количество шумовых выбросов, на которых даже ?хорошие? алгорит- мы будут допускать ошибки. Такие объекты было бы разумно исключить из выборки, так как попытка настройки на шум приводит к искажению разделяющей поверхно- сти и ухудшению качества классификации. В нашем случае обучение базового ал- горитма bt+1 по объектам с наименьшими отступами как раз и означает ?настройку на шум?. Проблема решается путём введения ещё одного параметра ?0 < ?1. Обу- чающая подвыборка формируется на шаге 7 исходя из условия wi := [?0 6 i 6 ?1]. Параметр ?0 можно либо фиксировать, либо подбирать путём оптимизации на каж- дой итерации, аналогично ?1. Вещественные веса объектов. Альтернативная эвристика заключается в том, что- бы не менять состав обучающей выборки, а лишь увеличивать веса тех объектов, на которых часто ошибались предыдущие алгоритмы. Например, в методе взвешен- ного большинства (weighted majority) вместо шага 7 применяется мультипликатив- ный пересчёт весов [31]: wi = (wi/?, если yibt(xi) > 0; wi?, если yibt(xi) < 0.
12 Легко видеть, что тогда на t-й итерации wi = ??Mit . Здесь ? > 1 параметр метода настройки, который приходится задавать априори. Для применения мультипликативного пересчёта необходимо, чтобы метод обу- чения базовых алгоритмов минимизировал функционал Q(bt;W?) при произвольном векторе весов W?. Далеко не все стандартные методы способны учитывать веса, хотя соответствующее обобщение в большинстве случаев строится несложно. Преобразование простого голосования во взвешенное. Если T различных базо- вых алгоритмов уже построены, то вектор оценок ??b1(x), . . . , bT (x)можно принять за новое признаковое описание объекта x и построить линейную разделяющую ги- перплоскость в пространстве RT по той же обучающей выборке X?. Для этого годится любой стандартный метод обучения линейных классифика- торов: линейный дискриминант Фишера (раздел ??), логистическая регрессия (раз- дел ??), однослойный персептрон (раздел ??), или метод опорных векторов SVM (раздел ??). Последний имеет преимущество, поскольку он максимизирует величину зазора между классами, что способствует более надёжной классификации. Желательно, чтобы применяемый линейный метод допускал введение допол- нительного ограничения на коэффициенты ?t > 0. Отрицательный коэффициент ?t свидетельствует о том, что оператор bt выдаёт ответы настолько ненадёжные, что их надо было бы учитывать с противоположным знаком. Такие базовые алгоритмы лучше вовсе исключить из композиции, обнулив ?t. Пример 1.4. Самый простой линейный метод ?наивный? байесовский класси- фикатор (стр. ??). Он исходит из предположения, что b1(x), . . . , bT (x) являются неза- висимыми случайными величинами. Нетрудно доказать, что в этом случае коэффи- циенты взвешенного голосования вычисляются по явной формуле [30]: ?t = ln 1 ? pt pt , t = 1, . . . , T, где pt вероятность ошибок базового алгоритма bt на обучающей выборке. Чем меньше ошибок допускает алгоритм bt, тем больше его вес ?t. В качестве оценки вероятности часто берут частоту ошибок ?t, или ?t+1/?, чтобы знаменатель не обра- щался в нуль. Если алгоритм bt допускает более половины ошибок, то ?t < 0. Такой алгоритм лучше вовсе исключить из композиции, положив ?t = 0. Обобщение на большое число классов. Пусть теперь число классов произвольно, |Y | = M. Базовые алгоритмы bt : X > R всё равно будем строить так, чтобы они решали двухклассовую задачу, отделяя заданный класс ct от всех остальных классов. Обозначим через Ty = {t : ct = y} множество индексов всех базовых алгоритмов, предназначенных для отделения класса y. Запишем алгоритм простого голосования, применив решающее правило из Примера 1.2: a(x) = argmax y?Y 1 |Ty|Xt?Ty bt(x). Соответственно изменится в Алгоритме 1.3 и вычисление отступов Mit: Mit = 1 |Tyi | Xt?Tyi bt(x) ? max y?Y \{yi} 1 |Ty|Xt?Ty bt(x).
13 В остальном все рассуждения и Алгоритм 1.3 остаются теми же. 1.2.4 Голосование по старшинству Рассмотрим задачу классификации с произвольным числом классов, |Y | = M. Положим R = {0, 1}. Будем использовать базовые алгоритмы, осуществляющие классификацию на 2 непересекающихся класса, bt : X > {0, 1}. В качестве корректи- рующей операции возьмём голосование по старшинству, см. Алгоритм ??. Решающие правила использовать не будем. Рассмотрим, что происходит при добавлении базового алгоритма bt. Если bt(x) = 1, то говорят, что ?bt выделяет объект x?, и объект x относится к клас- су ct. Обозначим через Ut подмножество объектов выборки, не выделенных ни одним из предыдущих базовых алгоритмов: Ut = xi ? X? : b1(xi) = - - - = bt?1(xi) = 0. Если xi ? X?\Ut, то объект xi уже классифицирован, и значение bt(xi) не влияет на ответ композиции a(xi). Для таких объектов вес wi положим равным нулю. Если xi ? Ut и yi 6= ct, то ошибка базового алгоритма, bt(xi) = 1, приведёт к ошибке всей композиции: a(xi) = ct 6= yi. Положим для таких объектов wi = 1. Если xi ? Ut и yi = ct, то ошибка базового алгоритма, bt(xi) = 0, приведёт к тому, что композиция из первых t алгоритмов откажется от классификации xi. Эта ошибка ещё может быть исправлена следующими алгоритмами. Поэтому для таких объектов положим wi = ?, где ? ? [0, 1] величина штрафа за отказ. Итак, минимизация функционала Q(a) = Q??F(b1, . . . , bt)по базовому алгорит- му bt, относящему объекты к классу ct, эквивалентна минимизации функционала Q(bt) =X? i=1 wibt(xi) 6= [yi = ct] . Это стандартный функционал взвешенного числа ошибок. Для его минимиза- ции применим стандартный метод обучения bt = ?(X?, Z?,W?), передав ему вектор весов объектов W? = (w1, . . . ,w?) и бинарный вектор ответов Z? = (z1, . . . , z?), где zi = [yi = ct]. В результате базовый алгоритм bt будет стремиться выделить как можно больше объектов ?своего? класса ct и как можно меньше ?чужих? объектов. Алгоритм 1.4 описывает весь процесс построения композиции. Стратегии выбора параметра ?. Параметр ? позволяет выбрать ?золотую сере- дину? между двумя крайними стратегиями: выделить хоть сколько-нибудь объектов ?своего? класса (? = 0) и в точности отделить все ?свои? объекты от всех осталь- ных (? = 1). Первая задача, как правило, оказывается слишком простой, а втораяслишком сложной. При выборе параметра ? можно руководствоваться следующими соображениями. : Представляется разумным брать ? ? 1, поскольку покрытие ?чужого? объ- екта гарантирует ошибку, а не-покрытие своего объекта может быть скомпен- сировано последующими базовыми алгоритмами. Например, можно начинать со значения ? = 0.1, постепенно увеличивая его от итерации к итерации.
14 Алгоритм 1.4. Построение композиции для голосования по старшинству Параметры: X?, Y ? обучающая выборка; ? метод обучения базовых алгоритмов; ? штраф за отказ от классификации; 1: инициализировать веса объектов: wi := 1 для всех i = 1, . . . , ?; 2: для всех t = 1, . . . , T, пока не выполнен критерий останова 3: выбрать класс ct; 4: вычислить бинарный вектор ответов Z? для настройки bt: zi := [yi = ct] для всех i = 1, . . . , ?; 5: если wi 6= 0 то wi := (1 ? zi) + ?zi для всех i = 1, . . . , ?; 6: bt := ?(X?, Z?,W?); 7: если bt(xi) = 1 то wi := 0 для всех i = 1, . . . , ?; : Уменьшение ? способствует росту числа базовых алгоритмов и в конечном ито- ге может приводить к переобучению. С другой стороны, увеличение ? приводит к переупрощению композиции за счёт увеличения числа ошибок. Таким обра- зом, параметр ? позволяет управлять сложностью и обобщающей способностью композиции. Для практического определения оптимального значения ? можно использовать скользящий контроль. Стратегии формирования последовательности c1, . . . , cT . В Алгоритме 1.4 стра- тегия выбора класса ct на шаге 4 преднамеренно не фиксирована, так как возможны различные варианты, выбор которых определяется особенностями задачи. : Выбирается тот класс, в котором осталось больше непокрытых объектов. : Выбирается тот класс, для которого удаётся получить лучшее значение функ- ционала качества. При этом время работы алгоритма увеличивается в M раз. : Задаётся приоритетный порядок классов Y = {v1, . . . , vM}, разбивающий после- довательность базовых алгоритмов на списки по Tm алгоритмов для каждого из классов vm, m = 1, . . . ,M: b|v11(x), . {. z. , bv1T1(x}) за класс v1 , bv21(x), . . . , bv2T2(x) | {z } за класс v2 , . . . , bvM1(x), . . . , bvMTM(x) | {z } за класс vM . При этом базовые алгоритмы внутри блоков оказываются независимыми их можно свободно переставлять местами и интерпретировать по отдельности. : Задаётся приоритетный порядок классов Y = {v1, . . . , vM}, как в предыдущем случае. Однако теперь для каждого класса строится независимый список ба- зовых алгоритмов, способный отделять объекты данного класса от объектов всех остальных классов. Для этого перед построением списка для следующего класса все объекты с нулевыми весами возвращаются в обучающую выборку. Соответственно, модифицируется правило пересчёта весов на шаге 5: если wi 6= 0 или ct 6= ct?1 то wi := (1 ? zi) + ?zi;
15 При такой стратегии композиция становится ещё лучше интерпретируемой, по- скольку теперь и блоки можно переставлять местами и интерпретировать по от- дельности. Во многих приложениях независимость интерпретации базовых ал- горитмов от их положения в композиции является заметным преимуществом. О кусочно-линейных разделяющих поверхностях. Если базовые алгоритмы строят линейные разделяющие поверхности, то комитет старшинства является кусочно-линейной разделяющей поверхностью. Пример 1.5. Задача на плоскости: X = R2, Y = {*,?}, bt(x) полуплоскости. :1.3 Стохастические методы построения композиций 1.3.1 Бэггинг и метод случайных подпространств Базовые алгоритмы, составляющие линейную комбинацию, должны быть в до- статочной степени различными, чтобы их погрешности компенсировали друг друга. Нет никакого смысла складывать одинаковые (или почти одинаковые) алгоритмы. В бустинге и других последовательных методах различность достигается благо- даря пересчёту весов объектов. Но возможна и другая стратегия повышения различ- ности, когда базовые алгоритмы настраиваются независимо друг от друга на случай- но выбранных подмножествах обучающей выборки, либо на различных случайных подмножествах признаков. Ещё один способ обеспечить различность выбирать слу- чайные начальные приближения при оптимизации вектора параметров (обычно так поступают при настройке нейронных сетей), либо применять стохастические алго- ритмы оптимизации. Полученные базовые алгоритмы объединяются в композицию с помощью простого или взвешенного голосования. В случае взвешенного голосова- ния для настройки коэффициентов ?t применяются стандартные линейные методы. Бэггинг. Метод бэггинга (bagging, bootstrap aggregation) был предложен Л. Брей- маном в 1996 году [19]. Из исходной обучающей выборки длины ? формируются различные обучающие подвыборки той же длины ? с помощью бутстрепа случай- ного выбора с возвращениями. При этом некоторые объекты попадают в подвыборку по несколько раз, некоторые ни разу. Можно показать, что доля объектов, ока- завшихся в каждой подвыборке, стремится к 1 ? e?1 ? 0.632 при ? > ?. Базовые алгоритмы, обученные по подвыборкам, объединяются в композицию с помощью простого голосования. Эффективность бэггинга объясняется двумя обстоятельствами. Во-первых, благодаря различности базовых алгоритмов, их ошибки взаимно компенсируются при голосовании. Во-вторых, объекты-выбросы могут не попадать в некоторые обу- чающие подвыборки. Тогда алгоритм, построенный по подвыборке, может оказаться даже точнее алгоритма, построенного по полной выборке. Бэггинг особенно эффективен на малых выборках, когда исключение даже небольшой доли обучающих объектов приводит к построению существенно различ- ных базовых алгоритмов. В случае сверхбольших избыточных выборок приходится строить подвыборки меньшей длины ?0 ? ?, при этом возникает задача подбора оптимального значения ?0.
16 Алгоритм 1.5. Бэггинг и RSM Параметры: ?' длина обучающих подвыборок; n' длина признакового подописания; ?1 порог качества базовых алгоритмов на обучении; ?2 порог качества базовых алгоритмов на контроле; 1: для всех t = 1, . . . , T, пока не выполнен критерий останова 2: U := случайное подмножество X? длины ?'; 3: G := случайное подмножество F длины n'; 4: bt := ?(G , U); 5: если Q(bt, U) > ?1 или Q(bt,X? \ U) > ?2 то 6: не включать bt в композицию; RSM. В методе случайных подпространств (random subspace method, RSM) ба- зовые алгоритмы обучаются на различных подмножествах признакового описания, которые также выделяются случайным образом [39]. Этот метод предпочтителен в задачах с большим числом признаков и относительно небольшим числом объек- тов, а также при наличии избыточных неинформативных признаков. В этих случаях алгоритмы, построенные по части признакового описания, могут обладать лучшей обобщающей способностью по сравнению с алгоритмами, построенными по всем при- знакам. Обобщение бэггинга и RSM приводит к Алгоритму 1.5. Пусть объекты описы- ваются набором признаков F = {f1, . . . , fn} и метод обучения ?(G , U) строит алго- ритмический оператор по обучающей подвыборке U ? X?, используя только часть признакового описания G ? F. Выборка объектов на шаге 2 может производиться как с возвращениями, так и без возвращений; вообще говоря, это ещё один (бинар- ный) параметр алгоритма. Числа ?' = |U| 6 ? и n' = |G | 6 n являются параметрами метода. Алгоритм 1.5 соответствует бэггингу при G = F, и методу случайных под- пространств при U = X?. Шаги 5-6 осуществляют фильтрацию неудачных базовых алгоритмов. Базо- вый алгоритм bt признаётся неудачным, если его качество на обучающей подвыбор- ке хуже заданного порога ?1, либо качество на контрольных данных X? \ U хуже ?2. Это может происходить в тех случаях, когда в обучающей выборке случайно ока- залось слишком много шумовых выбросов, или среди признаков оказалось слишком мало информативных. Ни один из методов построения линейных композиций не является однозначно лучшим. Как обычно, для каждого метода можно найти прикладные задачи, на ко- торых он превосходит остальные. Приведём некоторые выводы, вытекающие из эм- пирического сравнения бустинга, бэггинга и RSM [39]. : Бустинг работает лучше на больших обучающих выборках. При этом он лучше воспроизводит границы классов сложной формы. : Бэггинг и RSM предпочтительны для коротких обучающих выборок.
17 : RSM безусловно предпочтительнее в тех случаях, когда признаков больше, чем объектов и/или когда среди признаков много неинформативных. : Бэггинг и RSM допускают эффективное распараллеливание, в то время как бустинг выполняется строго последовательно. 1.3.2 Кооперативная коэволюция Как и в предыдущем разделе, будем полагать, что объекты описываются набо- ром признаков F = {f1, . . . , fn}, и задан метод обучения ?, позволяющий строить базовые алгоритмы b = ?(G , U) по различным подвыборкам U ? X? и различным частям признакового описания G ? F. Общая идея применения генетических алгоритмов для глобальной оптимиза- ции функционала качества Q(a) в некотором сложно устроенном пространстве a ? A заключается в следующем. Формируется популяция индивидов конечное множе- ство (t) ? A. Над ними производятся генетические операции, порождающее новое поколение индивидов. Обычно это бинарная операция рекомбинации (скрещивания) и унарная мутации. Из большого числа порождённых индивидов в следующее поколение (t + 1) отбираются только наиболее адаптивныенаилучшие с точки зрения функционала качества Q(a). Эволюционный процесс смены поколений оста- навливается, когда качество лучшего индивида перестаёт улучшаться. Для построения композиции обучаемых алгоритмов хорошо подходит специфи- ческая модель эволюции, называемая кооперативной коэволюцией [34]. Как всякий эволюционный алгоритм, он представляет собой итерационный процесс смены поко- лений, см. Алгоритм 1.6. Инициализация нулевого поколения производится случайным образом. На t-м поколении строится не одна, а p(t) популяций 1(t), . . . ,p(t)(t). Каж- дая популяция j(t) представляет собой множество индивидов. Каждый индивид кодируется (? + n)-мерным бинарным вектором, составленным из характеристиче- ских векторов подмножества объектов X' ? {x1, . . . , x?} и подмножества признаков G' ? {g1, . . . , gn}. Таким образом, каждому индивиду vj ? j(t) соответствует па- ра подмножеств (G',X'), к которой можно применить метод обучения и получить базовый алгоритм bj = ?(G',X') ? ?(vj). Для оценки адаптивности (fitness) индивида vj вычисляется оценка качества композиции, в которой на j-м месте стоит алгоритм bj , на остальных местах наи- более адаптивные алгоритмы b?s, взятые по одному из каждой популяции s(t), s 6= j: ?(vj) = Q??F(b?1, . . . , b?j?1, ?(vj), b?j+1, . . . , b?p(t)),X?, Адаптивность оценивается для каждого индивида в каждой популяции. Затем производится селекция индивидов. В каждой популяции отбирается огра- ниченное количество наиболее адаптивных индивидов. К ним применяются генетиче- ские операции рекомбинации (crossover), мутации и селекции, в результате которых порождается новое поколение j(t + 1), j = 1, . . . , p(t). Из каждого поколения t от- бирается и запоминается лучшая композиция вида F(b1, . . . , bp(t)). В момент смены поколений может приниматься решение об увеличении или уменьшении числа популяций. Если популяция даёт слишком малый вклад в композицию в течение некоторого числа поколений, то она удаляется. Если про- цесс эволюции вошел в состояние стагнации, то есть качество лучших композиций
18 Алгоритм 1.6. Коэволюционное обучение алгоритмической композиции CCEL Вход: Tmax максимальное число поколений; N0 размер основной популяции; N1 размер промежуточной популяции; N2 размер элиты, переходящей в следующее поколение без изменений; Выход: композиция a = F(b1, . . . , bp); 1: начальное число популяций: p(1) := 1; 2: создать популяцию: 1(1) := Инициализация(N0); 3: для всех поколений t := 1, . . . , Tmax 4: для всех популяций j(t), j := 1, . . . , p(t) 5: породить промежуточную популяцию: 'j := Рекомбинация(j(t),N1); '' j := Мутация('j) ? Селекция(j(t),N2); 6: для всех vj ? '' j 7: оценить адаптивность индивида ?(vj); 8: Qt := min{Qt, ?(vj)}; 9: запомнить лучшего индивида в популяции: v?j := arg min v?'' j ?(v); b?j:= ?(v?j ); 10: отобрать лучших индивидов в следующее поколение: j(t + 1) := Селекция('' j ,N0); 11: если Вклад(j) < ? то 12: удалить популяцию j ; p(t + 1) := p(t) ? 1; 13: если Стагнация(Q, t) то 14: p(t + 1) := p(t) + 1; добавить p(t+1)(t + 1) := Инициализация(N0); 15: если Останов(Q, t) то 16: выход; 17: вернуть композицию F??b?1, . . . , b?p(t), на которой достигается min t Qt. перестало заметно изменяться, то создаётся новая популяция. Если и эти меры не по- могают выйти из стагнации, то процесс эволюции останавливается. Основное отличие кооперативной коэволюции от стандартных генетических ал- горитмов в том, что функция адаптивности оценивает не качество алгоритма bj в от- дельности, а его полезность для композиции. В ходе эволюции базовые алгоритмы обучаются кооперировать друг с другом с целью наилучшего решения поставленной задачи. При этом каждая популяция (следовательно, каждый базовый алгоритм) специализируется в своей области объектов и в своём подпространстве признаков. Описанный метод получил название CCEL Cooperative Coevolution Ensemble Learner [3]. Он имеет большое число параметров и большую свободу выбора различ- ных эвристик. Рассмотрим некоторые из них более подробно. Инициализация(N0) процедура, создающая N0 индивидов. Каждый индивид формируется случайным образом. Для этого задаются два параметра вероятность включения объекта qX и вероятность включения признака qG.
19 Селекция(,N) генетическая операция, отбирающая N наиболее адаптивных индивидов популяции . В методе CCEL она используется дважды. На шаге 5 для переноса лучших индивидов (элиты) из популяции родителей в популяцию потомков. На шаге 11 для естественного отбора, при котором из N1 потомков только N0 лучших переносятся в следующее поколение. Рекомбинация(,N1) генетическая операция, порождающая N1 новых инди- видов путём попарного скрещивания индивидов популяции . Родительские пары выбираются случайным образом, возможно, с поощрением наиболее адаптивных ин- дивидов. Для формирования потомка в методе CCEL используется так называемый равномерный кроссинговер (uniform crossover) каждый бит потомка равновероятно выбирается у одного из родителей. Мутация() генетическая операция, производящая случайные изменения в индивидах популяции . В качестве параметра алгоритма задаётся вероятность инверсии бита в бинарном коде индивида. Вклад(j) функция, оценивающая вклад популяции j в композицию. При использовании проверки изъятием строятся две композиции с участием и без уча- стия j-го базового алгоритма. Соответственно, вычисляются оценки их качества: Qjt и ?Qjt. Вклад j-й популяции вычисляется как средняя разность этих оценок за по- следние d итераций: 1d Pt?=t?d+1???Qj? ? Qj? . Если вклад слишком мал, популяция целиком удаляется. Метод проверки изъятием надёжный, но ресурсоёмкий. Воз- можен альтернативный приём: если строится линейная корректирующая операция, то вклад можно оценивать как среднее значение веса j-го базового алгоритма за по- следние d итераций: 1d Pt?=t?d+1 ?j(? ). Если это значение окажется меньше заданного достаточно малого порога, популяция целиком удаляется. Стагнация(Q, t) критерий, проверяющий наступление стагнации в последо- вательности Q = {Qt} в момент времени t. Например, это может быть отсутствие заметных улучшений качества на протяжении последних d поколений: Qt?d?Qt < ?, где d, ? параметры алгоритма. При наступлении стагнации создаётся новая по- пуляция, в надежде на то, что увеличение сложности композиции сможет привести к улучшению её качества. Останов(Q, t) критерий останова, проверяющий наступление длительной стагнации по условию: Qt?D ? Qt < ?, где D ? d параметр алгоритма. Долж- но состояться по меньшей мере несколько безуспешных попыток добавить ещё одну популяцию, прежде чем станет ясно, что дальнейшее изменение структуры компо- зиции не способно её улучшить. Преимущества метода CCEL. : Эксперименты на реальных данных показали, что качество классификации (обобщающая способность) CCEL не хуже, чем у бустинга или бэггинга [3, 28]. : CCEL строит очень короткие композиции. Как правило, от 3 до 6 базовых алгоритмов бывает достаточно, тогда как бустинг и бэггинг набирают сотни алгоритмов для достижения сопоставимого качества. : CCEL применим к любым базовым алгоритмам и методам их обучения. : Автоматически отбираются информативные объекты и признаки, что даёт до- полнительную информацию для понимания задачи.
20 : Процесс обучения CCEL является алгоритмом с произвольным временем ра- боты (anytime algorithm). Обучение может быть в любой момент прервано для получения лучшей из найденных композиций, и вновь возобновлено для поиска ещё лучшего решения. Применение таких алгоритмов предпочтительно в тех случаях, когда имеется простаивающий вычислительный ресурс. Недостатки метода CCEL. : Метод CCEL сложен для реализации и имеет большое количество параметров, которые приходится задавать из эвристических соображений. : Если не использовать распараллеливания, CCEL работает очень долго. Прак- тически применимыми оказываются только очень простые и быстрые методы обучения ?, например, наивный байесовский классификатор (стр. ??). :1.4 Квазилинейные композиции (смеси алгоритмов) Линейные корректирующие операции естественным образом обобщаются на тот случай, когда веса базовых алгоритмов не постоянны и зависят от положения объ- екта x в пространстве X. Поставим каждому базовому алгоритму bt(x) в соответствие функцию компе- тентности gt(x), принимающую значения из отрезка [0, 1]. Определим композицию так, чтобы ответ базового алгоритма bt(x) на объекте x учитывался с весом gt(x). Опр. 1.2. Квазилинейная корректирующая операция есть функция F : R2T > R, F??b1, . . . , bT , g1, . . . , gT =XT t=1 gtbt. (1.8) Соответственно, алгоритмическая композиция имеет вид a(x) = CXT t=1 gt(x)bt(x), где C фиксированное решающее правило. Чем больше значение gt(x), тем с б?оль- шим весом учитывается ответ алгоритма bt(x) на объекте x. Множество t = x ? X: gt(x) > gs(x), s = 1, . . . , T, s 6= tназывается областью компетентности базового алгоритма bt(x). Основная идея смесей заключается в применении принципа ?разделяй и власт- вуй?. Используя достаточно простые базовые алгоритмы bt(x) и функции компетент- ности gt(x), можно восстанавливать довольно сложные зависимости. Понятие области компетентности было введено Растригиным в [10]. В англо- язычной литературе композиции вида (1.8) принято называть смесями экспертов (mixture of experts, ME), базовые алгоритмы экспертами, функции компетентно- сти шлюзами (gates) [16]. Шлюзы определяют, к каким экспертам должен быть направлен объект x. По-русски ?смесь экспертов? звучит не очень удачно, поэтому
21 будем говорить о ?смесях алгоритмов?. Произведения gt(x)bt(x) называются компо- нентами смеси. Естественным требованием к шлюзам является условие нормировки: XT t=1 gt(x) = 1, для любого x ? X. (1.9) Если оно выполнено, то для любого объекта x коррекция сводится к усредне- нию ответов базовых алгоритмов с некоторыми весами, причём результат никогда не выходит за пределы отрезка min t bt(x),max t bt(x). Чтобы гарантировать выполнение условия нормировки (1.9), используют функ- цию ?мягкого максимума? SoftMax: RT > RT : ?gt(x) = SoftMaxt??g1(x), . . . , gT (x)= e?gt(x) e?g1(x) + - - - + e?gT (x) . Эта функция переводит вектор (g1, . . . , gT ) в нормированный вектор (?g1, . . . , ?gT ). При ? > ?, все компоненты ?gt стремятся к нулю, кроме одной, соответствующей максимальному значению maxt gt, которая стремится к единице. Чем больше значе- ние параметра ?, тем ?чётче? границы областей компетентности. В задачах классификации с пороговым решающим правилом C(b) = [b > 0] или C(b) = sign(b) делать нормировку, вообще говоря, не обязательно, поскольку для классификации важен только знак выражения (1.8). Задача обнаружения нетипичных объектов. Если значение gt(x) меньше некото- рого порога для всех t = 1, . . . , T, то можно полагать, что объект x попадает в ?об- ласть неуверенности?, где все алгоритмы не компетентны. Как правило, это связано с тем, что в данной области обучающих прецедентов просто не было. Таким образом, смеси алгоритмов позволяют решать задачу обнаружения нетипичных объектов или новизны (novelty detection). Иногда эту задачу называют классификацией с одним классом (one-class classification). Вероятностная интерпретация. Функции gt(x) можно интерпретировать как нечёткие множества, а при условии нормировки и как вероятностные распределе- ния. Если для байесовского классификатора расписать апостериорные вероятности классов, то функции компетентности приобретут смысл априорных вероятностей: a(x) = argmax y?Y ?y P{y|x} = argmax y?Y ?y XT t=1 |P{(zt}) gt(x) P| {y{|zt, x}} bty(x) . Здесь предполагается, что каждый базовый алгоритм bt(x) возвращает вектор апо- стериорных вероятностей ??P{y|t, x}y?Y . Затем квазилинейная корректирующая опе- ??рация переводит T таких векторов в один вектор апостериорных вероятностей P{y|x}y?Y , и к нему применяется решающее правило argmaxy. Вероятностная интерпретация приводит к ЕМ-алгоритму, который обрастает массой технических усложнений [16, 27, 44]. Мы рассмотрим более простые оптими- зационные методы, основанные на применении выпуклых функций потерь.
22 Вид функций компетентности определяется спецификой предметной области. На- пример, может иметься априорная информация о том, что при больших и малых значениях некоторого признака f(x) поведение целевой зависимости принципиально различно. Тогда имеет смысл использовать весовую функцию вида g(x; ?, ?) = ?(?f(x) + ?), где ?, ? ? R свободные параметры, ?(z) = (1 + e?z)?1 сигмоидная функция, позволяющая описать плавный переход между двумя областями компетентности. Если априорной информации нет, то в качестве ?универсальных? областей ком- петентности берут области простой формы. Например, в пространстве X = Rn можно взять полуплоскости g(x; ?, ?) = ?(xт? + ?) или сферические гауссианы g(x; ?, ?) = exp(??kx ? ?k2), где ? ? Rn, ? ? R свободные параметры, которые настраиваются по выборке аналогично тому, как настраиваются параметры базовых алгоритмов. 1.4.1 Выпуклые функции потерь Преимущество смесей в том, что они позволяют разбить всё пространство X на области, в каждой из которых задача решается относительно просто, и затем ?склеить? эти решения в единую композицию. Основной технический приём, поз- воляющий решить эти относительно простые подзадачи по-отдельности, независимо друг от друга, связан с использованием выпуклых функций потерь. Рассмотрим функционал (??), характеризующий качество алгоритмических операторов при заданном векторе весов объектов W? = (w1, . . . ,w?). Гипотеза 1.1. Функция потерь eL(b, y) является выпуклой по b, то есть для любых b1, b2 ? R, y ? Y и неотрицательных g1, g2, таких, что g1 + g2 = 1, выполняется eL(g1b1 + g2b2, y) 6 g1eL(b1, y) + g2eL(b2, y). Условие выпуклости имеет прозрачную интерпретацию: потери растут не мед- леннее, чем величина отклонения от правильного ответа y. Во многих задачах тре- бование выпуклости является естественным. В частности, ему удовлетворяет квад- ратичная функция eL(b, y) = (b?y)2, применяемая в регрессионных задачах. К сожа- лению, пороговая функция eL(b, y) = [by < 0], применяемая в задачах классификации при Y = {?1, 1}, не является выпуклой. Однако некоторые её непрерывные аппрок- симации выпуклы, см. Рис. 1 на стр. 4: eL(b, y) = [by < 0] 6??? ?? e?by экспоненциальная; log2(1 + e?by) логарифмическая; (1 ? by)+ кусочно-линейная.
23 Замена пороговой функции потерь на непрерывную является распространён- ной практикой. В частности, логарифмическая аппроксимация используется в логи- стической регрессии (см. ??), экспоненциальная в алгоритме AdaBoost (см. :1.2), кусочно-линейная в методе опорных векторов SVM (см. ??). Непрерывные функ- ции потерь имеют важное достоинство они штрафуют обучающие объекты за при- ближение к границе классов, что способствует увеличению зазора между классами и повышению надёжности классификации. Таким образом, требование выпуклости функции потерь не слишком обременительно и даже естественно как для задач ре- грессии, так и для классификации. Итак, пусть выполнено условие нормировки (1.9) и функция потерь eLвыпук- ла. Вместо функционала Q(a) будем минимизировать его верхнюю оценку, которая непосредственно вытекает из условия выпуклости: Q(a) =X? i=1 eL XT t=1 ?gt(xi)bt(xi), yi6 XT t=1 X? i=1 ?gt(xi)eL??bt(xi), yi| {z } Q(bt;W?) . (1.10) Функционал Q(a) распадается на сумму T функционалов, каждый из которых зависит только от bt и ?gt. Если зафиксировать функции компетентности ?gt, то все базовые алгоритмы bt можно настроить по-отдельности, независимо друг от друга. Это стандартная задача обучения базовых алгоритмов. Затем можно зафиксировать базовые алгоритмы и настроить их функции компетентности. Для настройки всей композиции организуется итерационный процесс, в котором эти два шага выполня- ются по очереди. Остаётся только понять, каким образом компоненты будут добав- ляться в смесь, как строить для них начальные приближения, и когда прекращать порождение новых компонент. Далее рассматриваются два итерационных метода построения смесей, отлича- ющиеся способом добавления компонент, последовательный и иерархический. 1.4.2 Последовательный метод построения смеси Алгоритм 1.7 реализует процесс последовательного построения смеси. Первый базовый алгоритм b1(x) настраивается по всей выборке с помощью стан- дартного метода обучения. Затем выполняется процедура LearnInitG, которая на- страивает функцию компетентности g1(x), пытаясь аппроксимировать область, на ко- торой b1(x) чаще даёт верные ответы: LearnInitG (b,X?, Y ?) = argmin g X? i=1 (g(xi) ? zi)2, где zi = ???L(b(xi), yi)величина потери, приведённая к отрезку [0, 1] с помощью некоторой монотонно невозрастающей функции ?. Например, можно полагать zi = [b(xi) = yi] в задачах классификации; zi = |b(xi) ? yi| < ?при некотором ? > 0 в задачах регрессии.
24 Алгоритм 1.7. Последовательное построение смеси алгоритмов Параметры: ?0 допустимое число ошибок; ? пороговое значение функции потерь; 1: начальное приближение первой компоненты смеси: b1 := ?(X?, Y ?); g1 := LearnInitG (b1,X?, Y ?); 2: для всех t = 1, . . . , T ? 1, пока не выполнен критерий останова: 3: подмножество объектов, на которых композиция at(x) допускает ошибки: X(t) := xi ? X? : L(at(xi), yi) > ?; 4: если |X(t)| 6 ?0 то 5: вернуть (at); 6: начальное приближение t-й компоненты смеси: bt+1 := ?(X(t), Y (t)); gt+1 := LearnInitG (bt+1,X?, Y ?); 7: для всех k = 1, 2, . . . , пока не стабилизируется значение Q(at+1;X?, Y ?) 8: для всех j = 1, . . . , t + 1 9: wi := gj(xi) для всех i = 1, . . . , ?; 10: перестройка j-й компоненты смеси на k-й итерации: bj := ?(X?, Y ?,W?); gj := LearnGj (X?, Y ?); 11: вернуть (aT ); Далее в цикле по t происходит добавление новых компонент. При входе в цикл на шаге 3 предполагается, что смесь из t компонент уже построена: at(x) = C??g1(x)b1(x) + - - - + gt(x)bt(x), x ? X. Начальное приближение для (t + 1)-й компоненты строится так же, как и на ша- ге 1, только теперь базовый алгоритм bt+1 обучается не на полном объёме данных, а на подвыборке X(t), составленной из ?самых плохих? объектов, на которых ком- позиция at(x) выдала наименее точные ответы. Если таких объектов набирается ме- нее ?0, построение смеси завершается. Затем внутренний цикл итераций поочерёдно подстраивает все базовые алго- ритмы и их функции компетентности (шаги 7-10). Согласно (1.10) обучение базового алгоритма bj сводится к минимизации функционала Q(bj ;W?) с помощью стандарт- ного метода обучения ?. Покажем, что функции компетентности также можно настраивать по отдель- ности, применяя для этого стандартные методы обучения. Зафиксируем все базовые алгоритмы и все функции компетентности, кроме gj(x), и введём обозначения: Aji = Xt+1 s=1, s6=jgs(xi)bs(xi); Gji = Xt+1 s=1, s6=jgs(xi); bji = bj(xi); i = 1, . . . , ?.
25 Тогда функционал качества Q будет зависеть только от функции gj , и его можно минимизировать по gj : LearnGj (X?, Y ?) = argmin g X? i=1 eL(Aji + bjigj(xi), yi). Рассмотрим более подробно процедуру настройки LearnGj , отдельно для задач классификации и регрессии. Настройка функций компетентности в задачах классификации. Допустим для простоты, что Y = {?1,+1}, и базовые алгоритмы возвращают только два возмож- ных значения ?1 и +1. Для настройки функции компетентности gj(x) в смеси at+1(x) будем минимизировать функционал Q с экспоненциальной функцией потерь: Q(at+1) = X? i=1 exp???Ajiyi ? gj(xi)bjiyi= = X? i=1 exp(?Ajiyi) | {z } ? wi exp???gj(xi) |bj{izy}i ?yi = X? i=1 ? wi exp(?gj(xi)?yi). Таким образом, настройка функции компетентности gj сводится к задаче классифи- кации, которая решается путём минимизации функционала качества Q с весами ? wi и экспоненциальной функцией потерь. Формулы для весов объектов ? wi = exp(?Ajiyi) и модифицированных ответов ?yi = bjiyi позволяют дать этой задаче очевидную ин- терпретацию: функция компетентности обучается выделению объектов, на которых базовый алгоритм bj(x) не допускает ошибки. При этом б?ольший вес получают ?наи- более трудные? объекты, на которых смесь всех остальных компонент имеет большой отрицательный отступ. Настройка функций компетентности в регрессионных задачах. Рассмотрим случай Y = R. Зафиксируем все базовые алгоритмы и все функции компетентно- сти кроме gj(x). Заметим, что в обозначениях, введённых выше, Aji/Gji = a(j) t (xi), где a(j) t композиция, полученная из at+1(x) путём исключения j-й компоненты. Будем называть a(j) t ?смесью всех остальных компонент?. Для настройки функции компетентности gj(x) в смеси at+1(x) будем миними- зировать функционал среднеквадратичного отклонения: Q(gj) = X? i=1 (at+1(xi) ? yi)2 = X? i=1 Aji + gj(xi)bji Gji + gj(xi) ? yi2 = = X? i=1 gj(xi) Gji + gj(xi) bji ? Aji Gji? yi ? Aji Gji2 = = X? i=1 bji ? Aji Gji2 | {z } ? wi gj(xi) Gji + gj(xi) ? yi ? Aji/Gji |bji ? A{zji/Gj}i ?yi 2.
26 Настройка функции компетентности gj(x) сводится к нелинейной регрессион- ной задаче со стандартным функционалом среднеквадратичной ошибки. Выполнен- ные выше несложные преобразования позволили выделить веса объектов ? wi и мо- дифицированные ответы ?yi. Их смысл достаточно очевиден. Веса ? wi близки к ну- лю на тех объектах xi, где базовый алгоритм bj(xi) мало отличается от смеси всех остальных компонент. Вполне разумно, что функционал Q остаётся нечувствитель- ным к значениям функции компетентности gj(xi) на таких объектах. Модифициро- ванные ответы ?yi представляют отношение отклонений правильного ответа yi и зна- чения bj(xi) от значения, которое даёт смесь всех остальных компонент a(j) t (xi). Если эти отклонения разного знака, то базовый алгоритм bj даёт менее точный ответ, чем смесь всех остальных компонент. В этом случае значение функции компетентно- сти gj(xi) должно быть близко к нулю. Если же эти отклонения одного знака, то ба- зовый алгоритм bj пытается компенсировать ошибку, допущенную всеми остальными компонентами. В этом случае его компетентность должна быть близка к единице. Недостатки последовательного метода. : Низкая скорость обучения. При добавлении каждой новой компоненты смеси приходится перестраивать все предыдущие компоненты, что ведёт к существен- ным затратам времени. Этого недостатка лишены иерархические методы. 1.4.3 Иерархический метод построения смеси Смесь двух алгоритмов. Рассмотрим сначала простой случай, когда композиция состоит из двух базовых алгоритмов, функции компетентности удовлетворяют тре- бованию нормировки, решающее правило фиксировано: a(x) = C??g1(x)b1(x) + g2(x)b2(x), g1(x) + g2(x) = 1, x ? X. Гипотеза 1.1 позволяет оценить сверху функционал Q(a;W?) суммой двух функционалов стандартного вида: Q(a;W?) 6 eQ(a;W?) =X? i=1 g1(xi)wieL??b1(xi), yi| {z } Q(b1;W? 1 ) + X? i=1 g2(xi)wieL??b2(xi), yi| {z } Q(b2;W? 2 ) . Если функции компетентности g1(x) и g2(x) известны, то минимизация функци- оналов Q(b1;W? 1 ) и Q(b2;W? 2 ) может быть выполнена порознь. Для этого достаточно применить стандартный метод обучения ?: b1 = ?(X?, Y ?,W? 1 ), W? 1 = ??wig1(xi)?i=1; b2 = ?(X?, Y ?,W? 2 ), W? 2 = ??wig2(xi)?i=1. Верно и обратное: если известны базовые алгоритмы b1(x) и b2(x), то можно оценить функции g1(x) и g2(x). В силу условия нормировки g2(x) = 1 ? g1(x) доста- точно найти функцию g1(x), доставляющую минимум функционалу eQ(g1) = X? i=1 g1(xi)wi??eL(b1(xi), yi) ? eL(b2(xi), yi)| {z } di=const(g1) . (1.11)
27 Алгоритм 1.8. M2E построение смеси двух базовых алгоритмов Вход: X?, Y ? обучающая выборка; W? = (w1, . . . ,w?) исходный вектор весов объектов; b0(x) начальное приближение одного из базовых алгоритмов; Выход: алгоритмическая композиция: a(x) = b1(x)g1(x) + b2(x)g2(x); 1: g1 := argmin g P?i=1 g(xi)wieL(b0(xi), yi); 2: повторять 3: настройка двух базовых алгоритмов: b1 := ?(X?, Y ?,W? 1 ) с весами w1i = wig1(xi); b2 := ?(X?, Y ?,W? 2 ) с весами w2i = wi(1 ? g1(xi)); 4: настройка функции компетентности: di := wi??eL(b1(xi), yi) ?eL(b2(xi), yi), для всех i = 1, . . . , ?; g1 := argmin g P?i=1 dig(xi); 5: оценка качества композиции: Q := P?i=1 wiL??b1(xi)g1(xi) + b2(xi)g2(xi), yi; 6: пока не стабилизируется значение Q; Если известен параметрический вид функции g1(x), то задача легко решается гра- диентными методами, аналогичными методам обучения нейронных сетей. Итак, знание функций компетентности позволяет настроить оба базовых ал- горитма, а знание базовых алгоритмов позволяет аппроксимировать функции ком- петентности. Остаётся только запустить итерационный процесс, в котором эти две задачи решаются поочерёдно. Итерации можно начинать с построения начального приближения b0(x) для одного из базовых алгоритмов. Алгоритм 1.8 описывает про- цедуру M2E (mixture of 2 experts) подробно. Иерархическая смесь алгоритмов. Метод M2E легко приспособить для построе- ния сколь угодно сложных смесей, состоящих из произвольного числа алгоритмов. Идея заключается в следующем. Сначала строится смесь двух алгоритмов и анализируется качество работы каждого из них на своей области компетентно- сти. Если качество алгоритма недостаточно, то он заменяется смесью двух новых алгоритмов, разбивающих его область g(x) на две новые области с функциями ком- петентности g(x)g1(x) и g(x)g2(x), причём g1(x) + g2(x) = 1, чтобы по-прежнему выполнялось условие нормировки. Процесс дробления областей компетентности про- должается до тех пор, пока в смеси остаются алгоритмы неудовлетворительного ка- чества. В результате получается бинарное дерево алгоритмов, называемое иерархи- ческой смесью алгоритмов (hierarchical mixture of experts, HME). Алгоритм 1.9 более подробно описывает детали рекурсивной реализации этой идеи. Способ построения HME напоминает синтез бинарного решающего дерева (см. раздел ??). Главное отличие в том, что здесь функции компетентности произво- дят нечёткое разделение пространства объектов на области. Ещё одно существенное отличие в применяемом критерии ветвления.
28 Алгоритм 1.9. Рекурсивный алгоритм построения иерархической смеси Вход: X?, Y ? обучающая выборка; 1: ПРОЦЕДУРА Разветвить (W?, b0): W? = (w1, . . . ,w?) веса обучающих объектов; b0 алгоритм, заменяемый смесью a(x) = b1(x)g1(x) + b2(x)g2(x); 2: b1, g1, b2, g2 := M2E(W?, b0); 3: W? 1 = ??wig1(xi)?i=1; 4: если КритерийВетвления (W? 1 , b1) то 5: Разветвить (W? 1 , b1); 6: W? 2 = ??wig2(xi)?i=1; 7: если КритерийВетвления (W? 2 , b2) то 8: Разветвить (W? 2 , b2); Основной алгоритм 9: W? := (1/?, . . . , 1/?); 10: b0 := ?(X?, Y ?,W?); 11: Разветвить (W?, b0); Критерии ветвления. Базовый алгоритм расщепляется на два, когда качество его работы оказывается неудовлетворительным. Существуют различные способы оце- нить качество алгоритма, но мы рассмотрим только два. : Относительная точность на обучающей выборке X? хуже заданного порога ?: КритерийВетвления (W?, b) := hQ(b;W?) > ?P?i=1 wii . Недостатком этого критерия является необходимость задания параметра ?. : Точность на заранее выделенной контрольной выборке Xk хуже, чем у роди- тельского алгоритма: КритерийВетвления (W?, b) := Q(b;Xk, Y k,Wk) > Q(b0;Xk, Y k,Wk). Данный критерий оценивает склонность рассматриваемой ветки иерархии к пе- реобучению. Недостатком этого критерия является необходимость выделения части объектов в контрольную выборку. :1.5 Нелинейные монотонные композиции Монотонная коррекция является ещё одним обобщением линейной. Произволь- ная линейная корректирующая операция F(b1, . . . , bT ) = ?1b1 + - - - + ?T bT с неот- рицательными коэффициентами ?t является монотонным отображением из RT в Y . Множество произвольных (не обязательно линейных) монотонных функций суще- ственно шире, поэтому монотонные корректирующие операции обладают б?ольшими
29 возможностями для настройки. В то же время, монотонность является более есте- ственным требованием к корректирующей операции, нежели линейность. Монотон- ность F как отображения RT > Y означает, что одновременное увеличение значе- ний b1(x), . . . , bT (x) не должно приводить к уменьшению значения F(b1(x), . . . , bT (x)). Например, в алгоритмах классификации значение bt(x) часто имеет смысл вероятно- сти того, что объект x принадлежит некоторому фиксированному классу. Было бы странно, если бы повышение этой оценки одновременно для всех базовых алгоритмов сопровождалось понижением значения F(b1(x), . . . , bT (x)), полученного в результате коррекции. Требование линейности связано с более жестким предположением, что веса базовых алгоритмов постоянны и не зависят от x весьма сомнительная эври- стика, если учесть, что базовые алгоритмы могут иметь различные области компе- тентности в пространстве объектов. Опр. 1.3. Пусть R и Y частично упорядоченные множества. Монотонные функ- ции вида F : RT > Y будем называть монотонными корректирующими операциями. Заметим, что в данном случае решающие правила не используются, и коррек- тирующие операции действуют непосредственно в Y . Соответственно, искомый ал- горитм a имеет вид a(x) = F(b1(x), . . . , bT (x)). Лемма о проведении монотонной функции через заданные точки. Опр. 1.4. Пусть U, V произвольные частично упорядоченные множества. Сово- купность пар (ui, vi)? i=1 из U ? V называется монотонной, если из uj 6 uk следует vj 6 vk для всех j, k = 1, . . . , ?. Лемма 1.5. Пусть U, V произвольные частично упорядоченные множества. Мо- нотонная функция f : U > V такая, что f(ui) = vi для всех i = 1, . . . , ?, существует тогда и только тогда, когда совокупность (ui, vi)? i=1 монотонна. Доказательство. Необходимость вытекает из определения монотонной функции: если f монотон- на, то совокупность (ui, f(ui))? i=1 монотонна. Докажем достаточность. Предполагая, что совокупность (ui, vi)? i=1 монотонна, построим функцию f в классе кусочно-постоянных функций. Определим для произ- вольного u ? U множество индексов I(u) = {k : ui 6 u} и положим f(u) =?? ? min i=1,...,? vi, если I(u) = ?; max i?I(u) vi, если I(u) 6= ?. Докажем, что функция f монотонна. Для произвольных u и u' из u 6 u' следует I(u) ? I(u'), значит f(u) 6 f(u'). Докажем, что f(ui) = vi для всех i = 1, . . . , ?. Множество I(ui) не пусто, так как i ? I(ui). Для любого k ? I(ui) в силу монотонности (ui, vi)? i=1 из uk 6 ui следует vk 6 vi. Но тогда max k?I(ui) vk достигается при k = i, откуда следует f(ui) = vi. Доказательство леммы конструктивно, однако предложенный способ построе- ния функции f мало пригоден для практических нужд. В регрессионных задачах
30 (когда Y = R) желательно, чтобы функция f была гладкой или хотя бы непрерыв- ной, здесь же f кусочно постоянна. В задачах классификации (когда Y = {0, 1}) желательно, чтобы разделяющая поверхность проходила как можно дальше от то- чек выборки, здесь же разделяющая полоса целиком относится к классу 0. Более практичные конструкции будут показаны ниже. 1.5.1 Оптимизация базовых алгоритмов Обозначим через ui вектор значений базовых алгоритмов на объекте xi, че- рез fi значение, выданное алгоритмом a(x) на объекте xi: ui = (b1(xi), . . . , bt(xi)); fi = a(xi) = F(b1(xi), . . . , bt(xi)) = F(ui); i = 1, . . . , ?. В новых обозначениях условие корректности алгоритма a(xi) = yi примет вид F(ui) = yi, i = 1, . . . , ?. (1.12) Опр. 1.5. Пусть V произвольное упорядоченное множество. Пара индексов (j, k) называется дефектной для функции b : X > V , если yj < yk и b(xj) > b(xk). Дефек- том функции b(x) называется множество всех её дефектных пар: D(b) = {(j, k) : yj < yk ? b(xj) > b(xk)} . Дефектная пара обладает тем свойством, что для любой монотонной функ- ции F выполняется F(b(xj)) > F(b(xk)), следовательно, алгоритм a(x) = F(b(x)) допустит ошибку хотя бы на одном из двух объектов xj , xk, какой бы ни была F. Опр. 1.6. Совокупным дефектом операторов b1, . . . , bt называется множество DT (b1, . . . , bt) = D(b1) ? . . . ? D(bt) = {(j, k) : yj < yk ? uj > uk}. Будем также пользоваться сокращённым обозначением Dt = Dt(b1, . . . , bt). Для любой пары (j, k) из совокупного дефекта и любой монотонной функции F выполняется F(uj) > F(uk), следовательно, алгоритм a(x) = F(b1(x), . . . , bt(x)) до- пустит ошибку хотя бы на одном из двух объектов xj , xk. Теорема 1.6. Монотонная функция F : Rt > Y , удовлетворяющая условию кор- ректности 1.12 существует тогда и только тогда, когда совокупный дефект операто- ров b1, . . . , bt пуст. При этом дефект алгоритма a = F(b1, . . . , bt) также пуст. Доказательство. Справедлива следующая цепочка равносильных утверждений: а) совокупный дефект пуст: Dt(b1, . . . , bt) = ?; б) для любых j, k не выполняется (uk 6 uj) ? (yj < yk) (согласно Опр. 1.6); в) для любых j, k справедлива импликация (uk 6 uj) > (yk 6 yj); г) совокупность пар (ui, yi)? i=1 монотонна (согласно Опр. 1.4); д) существует монотонная функция F : Rt > Y такая, что F(ui) = yi для всех i = 1, . . . , ? (согласно Лемме 1.5).
31 Из утверждения д) следует, что условия yj < yk и F(uj) > F(uk) не могут выполняться одновременно, значит, дефект D(F(b1, . . . , bt)) также пуст. Итак, чтобы гарантировать корректность композиции a = F(b1, . . . , bt), доста- точно построить операторы b1, . . . , bt, совокупный дефект которых пуст. Согласно определению 1.6 добавление каждого нового оператора в композицию может только уменьшать дефект, поскольку Dt ? Dt?1. Если пара (j, k) удовлетворяет условиям bt(xj) < bt(xk), (j, k) ? Dt?1, (1.13) то она уже не может принадлежать Dt, так как добавление оператора bt увеличивает размерность векторов uk и uj на единицу, при этом они становятся несравнимыми. Итак, выполнение условия (1.13) приводит к устранению дефектной пары (j, k). Теорема 1.7 (о сходимости). Пусть на первом шаге процесса (??) построен опе- ратор b1, и семейство операторов B выбрано так, что для любой подвыборки X2m длины 2m, m > 1, найдётся оператор b ? B и монотонная корректирующая опера- ция F, удовлетворяющие системе ограничений F(b(xi)) = yi, xi ? X2m. Тогда итерационный процесс (??-??) приводит к построению корректной композиции a = F(b1, . . . , bT ) за конечное число шагов T 6 D(b1)/m+ 1. Доказательство. Рассмотрим t-й шаг, t > 2, итерационного процесса (??). Если |Dt?1| > m, то выберем некоторое m-элементное подмножество совокупного дефекта t?1 ? Dt?1. Если |Dt?1| 6 m, то положим t?1 = Dt?1. Рассмотрим подмножество объектов выборки, образующих всевозможные дефектные пары из t?1: U = xi ? X? ?k : (k, i) ? t?1 или (i, k) ? t?1. Очевидно, мощность U не превышает 2m. Согласно условию теоремы существует опе- ратор bt ? B и монотонная корректирующая операция F, удовлетворяющие системе ограничений F(bt(xi)) = yi при всех xi ? U. Но тогда для оператора bt выполняется также система ограничений bt(xj) < bt(xk), (j, k) ? t?1. Докажем это от противного: пусть bt(xk) 6 bt(xj), тогда F(bt(xk)) 6 F(bt(xj)), сле- довательно, yk 6 yj , что противоречит условию yj < yk, входящему в определение дефектной пары (j, k). Если выбирать операторы bt, t = 2, 3, . . . указанным способом, то мощность совокупного дефекта будет уменьшаться, как минимум, на m на каждом шаге ите- рационного процесса: |Dt| 6 |Dt?1|?m. Для полного устранения дефекта потребуется не более D(b1)/mоператоров, не считая b1. Процесс последовательного построения базовых алгоритмов организуется по принципу наискорейшего устранения дефекта. Каждый следующий оператор оп- тимизируется таким образом, чтобы он устранял как можно больше дефектных пар из совокупного дефекта всех предыдущих операторов.
32 Проблема в том, что решение системы неравенств вида (1.13) не является стан- дартной задачей обучения, поскольку каждое неравенство в этой системе относится к паре объектов, а не к отдельному объекту. Тем не менее, задача может быть сведена к стандартной: оказывается, мощность совокупного дефекта можно оценить сверху обычным функционалом числа ошибок (??), если специальным образом задать веса обучающих объектов. Следующая теорема показывает, что в случае классификации вес i-го объекта можно положить равным числу пар из совокупного дефекта Dt?1, в которых участ- вует данный объект. Теорема 1.8. Если Y = {0, 1} и функция потерь имеет вид eL(b, y) = [b > 0] 6= y, то справедлива оценка |Dt(b1, . . . , bt)| 6X? i=1 wi eL(bt(xi), yi); (1.14) wi = |D(i)|; D(i) = xk ? X? (k, i) ? Dt?1 или (i, k) ? Dt?1; i = 1, . . . , ?. (1.15) Доказательство. Обозначим через ?i = bt(xi) значение t-го оператора на i-м обучающем объекте, через Li = eL(?i, yi) = [?i > 0] 6= yiзначение функции потерь, равное 1, если оператор bt допускает ошибку на i-м объекте, 0 в противном случае. Для любых действительных ?j , ?k справедливо неравенство [?j > ?k] 6 [?j > 0] + [?k 6 0]. Если yj < yk, то из двухэлементности множества Y следует: yj = 0; [?j > 0] = [?j > 0] 6= 0= [?j > 0] 6= yj= Lj ; yk = 1; [?k 6 0] = [?k > 0] 6= 1= [?k > 0] 6= yk= Lk. Используя представление Dt = Dt?1 ? D(bt), распишем мощность совокупного дефекта в виде суммы по парам объектов и применим оценку [?j > ?k] 6 Lj + Lk: |Dt| = X (j,k)?Dt?1 (j, k) ? D(bt)= X (j,k)?Dt?1 ?j > ?k6 X (j,k)?Dt?1 (Lj + Lk) = = X? j=1 yj=0 Lj X? k=1(j, k) ? Dt?1+ X? k=1 yk=1 Lk X? j=1 (j, k) ? Dt?1= = X? i?1 Li X? k=1(k, i) ? Dt?1 или (i, k) ? Dt?1= X? i?1 Li |D(i)|. В случае регрессии справедлива аналогичная теорема [2]. Теорема 1.9. Если Y = R и функция потерь имеет вид eL(b, y) = (b ? y)2, то спра- ведлива та же оценка (1.14), только веса определяются по-другому: wi = h?2 i |D(i)|, где hi = 12 min k?D(i) |yi ? yk|, D(i) определяется согласно (1.15).
33 Рис. 2. Верхний (M*i ) и нижний (M*i ) конусы вектора ui. Рис. 3. Расстояние от вектора u до ближайшего верхнего конуса. 1.5.2 Монотонная интерполяция и аппроксимация Если совокупный дефект операторов b1, . . . , bt пуст, то существует монотонная функция F такая, что F(ui) = yi для всех i = 1, . . . , ?. Задача построения такой функции называется задачей монотонной интерполяции. Если же дефект не пуст, то совокупность пар (ui, yi)? i=1 не является монотон- ной, и система ограничений F(ui) = yi несовместна. Задача построения монотонной функции F, приближенно удовлетворяющей условиям F(ui) = yi, называется зада- чей монотонной аппроксимации. Она решается в два этапа. На первом этапе находятся значения fi ? Y , i = 1, . . . , ?, наименее отклоняю- щиеся от yi, для которых последовательность (ui, fi)? i=1 монотонна: ??? ?? X? i=1 (fi ? yi)2 > min; fj 6 fk, для всех (i, j) : uj 6 uk. Это задача квадратичного программирования с линейными ограничениями-неравен- ствами. Для её решения могут быть применены стандартные методы, например, ме- тод активных ограничений. На втором этапе решается задача монотонной интерполяции строится моно- тонная функция, удовлетворяющая условиям F(ui) = fi для всех i = 1, . . . , ?. Таким образом, в обоих случаях приходится решать задачу монотонной интер- поляции. Рассмотрим её более подробно. Задача монотонной интерполяции. Задана выборка монотонная совокуп- ность пар (ui, fi)? i=1, где ui ? Rt, fi ? R. Требуется построить монотонную функ- цию F : Rt > R проходящую через все точки выборки: F(ui) = fi, i = 1, . . . , ?. Предполагается, что среди значений fi есть различные (задача не вырождена). Определим верхний конус M*i и нижний конус M*i для каждого из векторов ui, как показано на Рис. 2: M*i = {u ? Rt | ui 6 u}; M*i = {u ? Rt | u 6 ui}.
34 Пусть ?: Rt+ > R+ некоторая неубывающая функция, принимающая нулевое значение только в точке (0, . . . , 0). Например, можно взять одну из функций ?(z1, . . . , zt) =??? ?? max(z1, . . . , zt); zp1 + - - - + zt; z21 + - - - + z2t ; В то же время, функция min(z1, . . . , zt) не подходит, так как она принимает нулевое значение не только в нуле. Определим функции расстояния от произвольного вектора u = (u1, . . . , ut) до верхнего и нижнего конусов векторов ui = (u1i, . . . , uti): r*i (u) = ? ??(u1i ? u1)+, . . . , (uti ? ut)+; r*i (u) = ? ??(u1 ? u1i)+, . . . , (ut ? uti)+; где (z)+ = [z > 0]z. Расстояние r*i (u) монотонно не возрастает по u и обращается в нуль на верхнем конусе M*i . Расстояние r*i (u) монотонно не убывает по u и обра- щается в нуль на нижнем конусе M*i . Если функция ? непрерывна, то функции r*i и r*i также непрерывны. Для любого ? из полуинтервала [mini fi,maxi fi) определим расстояния от про- извольного вектора u = (u1, . . . , ut) до ближайшего верхнего и до ближайшего ниж- него конусов: h*(u, ?) = min i:fi>? r*i (u); h*(u, ?) = min i:fi6? r*i (u). Интерполяция бинарной монотонной функции. В задаче классификации на два класса Y = {0, 1} функции h*, h* сразу позволяют построить искомую монотон- ную корректирующую операцию F(u). Вектор u будет относиться к классу 1, если расстояние до ближайшего верхнего конуса класса 1 меньше, чем расстояние до бли- жайшего нижнего конуса класса 0. Теорема 1.10. Для задачи классификации, Y = {0, 1}, функция F(u) = [h*(u, ?) 6 h*(u, ?)] при любом ? ? [0, 1) определена на всём пространстве Rt, монотонно не убывает, принимает значения из Y и удовлетворяет условиям F(ui) = fi, для всех i = 1, . . . , ?. Доказательство можно найти в [2]. Рис. 4 поясняет геометрический смысл функции F(u): она представляет собой монотонную ?ступеньку?, равную единице на объединении верхних конусов класса 1, и нулю на объединении нижних конусов класса 0. Разделяющая поверхность прохо- дит посередине между этими областями. График на Рис. 4 построен для двумерного случая t = 2, при ?(z1, . . . , zt) = (z21 + - - - + z2t )?1/2.
35 Рис. 4. Дискретная монотонная ступенька F(u) для задачи классификации. Рис. 5. Непрерывная монотонная ступенька (u, ?) для задачи восстановления регрессии. Интерполяция непрерывной монотонной функции. В случае восстановления ре- грессии задача осложняется тем, что алгоритм a(x), а значит и корректирующая операция F(u), должны быть достаточно гладкими или хотя бы непрерывными. Это естественное требование возникает в большинстве практических задач. Введём вспомогательную функцию (u, ?) = h*(u, ?) h*(u, ?) + h*(u, ?), u ? Rt, ? ? R. Нетрудно показать, что эта функция непрерывна, монотонно не убывает, и на век- торах ui, i = 1, . . . , ? принимает значения либо 0, либо 1: (ui, ?) = [fi > ?]. Функция (u, ?) представляет собой непрерывный аналог дискретной монотонной ?ступеньки?, рассмотренный выше, что хорошо видно из сравнения Рис. 4 и Рис. 5. Идея построения непрерывной монотонно неубывающей функции, проходящей через заданные точки, заключается в том, чтобы ?поставить друг на друга? ? ? 1 непрерывных ступенек вида (u, ?). Теорема 1.11. Пусть Y = R и точки выборки пронумерованы по возрастанию зна- чений: f1 6 f2 . . . 6 f?. Тогда функция F(u) = f1 +X??1 i=1 (fi+1 ? fi)(u, fi) определена на всём пространстве Rt, монотонно не убывает и удовлетворяет условиям F(ui) = fi для всех i = 1, . . . , ?. Если функция ?(u) непрерывна, то функция F(u) также непрерывна. Доказательство можно найти в [2]. Заметим, что монотонная функция F(u) в общем случае не является гладкой, её производная может претерпевать разрывы в местах ?склейки? ступенек.
36 Рис. 6. Монотонная корректирующая операция F(u) в задаче восстановления регрессии. Рис. 7. Классический (немонотонный) гладкий сплайн, построенный по монотонной выборке. На Рис. 6 показан пример функции F(u), построенной по двумерным модель- ным данным. Для сравнения на Рис. 7 показан классический гладкий интерполяци- онный сплайн, построенный по той же монотонной выборке. Заметим, что он не яв- ляется монотонной функцией. :1.6 Краткий обзор литературы Общая теория алгоритмических композиций над произвольными моделями ал- горитмов и произвольными семействами корректирующих операций была впервые предложена Журавлёвым в алгебраическом подходе к проблеме распознавания [4, 5]. До этого были известны только наиболее простые методы комбинирования алгорит- мов, такие как взвешенное голосование и комитетные системы [8]. При этом, как правило, рассматривались вполне конкретные модели базовых алгоритмов, а кор- ректирующие операции не обладали возможностью настройки. Фактически, эти ра- боты оставались на уровне обычных эвристических приёмов и не носили характера систематической научной теории. Большое разнообразие методов комбинирования алгоритмов также появилось существенно позже. Методы, основанные на идее областей компетентности, были предложены Растригиным [10] и позже Джорданом и Джакобсом и др. в [16]. В 1988 в работах Кернса и Валианта [29] была поставлена следующая пробле- ма. Будем под слабой обучаемостью (weak learnability) понимать возможность по- строения (за полиномиальное время) алгоритма, вероятность ошибок которого лишь немного меньше 50%; под сильной обучаемостью (strong learnability) будем понимать возможность построения (опять-таки, за полиномиальное время) алгоритма, вероят- ность ошибок которого сколь угодно мало отличается от нуля при ? > ?. Была вы- двинута гипотеза, что понятия сильной и слабой обучаемости эквивалентны, то есть что любую слабую модель можно усилить (boost). Эта гипотеза была теоретически подтверждена в работеШапира [38], который предложил первый алгоритм бустинга (boosting). Годом позже Фройнд предложил свой алгоритм [21]. Оба алгоритма ос- новывались на взвешенном голосовании, но были неудобны для практического при- менения. Лишь пятью годами позже им удалось разработать алгоритм AdaBoost, получивший впоследствии широкую известность благодаря простоте и высокой эф-
37 фективности [22]. Аналогичные методы, но с несколько иной стратегией оптимизации базовых операторов, были разработаны Уолпертом [45] и Брейманом [19]. Следую- щим обобщением стало введение нелинейных весовых функций в [41]. Затем были предложены нелинейные монотонные корректирующие операции [1, 2, 15] По отношению к алгебраическому подходу перечисленные методы являются частными случаями, отличаясь, главным образом, видом корректирующей операции. Алгебраический подход позволяет ?порождать? такого рода методы с общих теоре- тических позиций. Наиболее абстрактным разделом алгебраического подхода явля- ется теория универсальных и локальных ограничений Рудакова. Она даёт критерии полноты, позволяющие строить семейства базовых алгоритмов и корректирующих операций минимальной достаточной сложности [13, 11, 12, 14]. В современных обзорах по методам распознавания [26] и алгоритмическим ком- позициям [40] подчеркивается, что построение композиций, в которых различные алгоритмы компенсируют недостатки друг друга, является одним из наиболее пер- спективных направлений машинного обучения. Резюме 1. Основные свойства композиций, отличающие их от обычных алгоритмов обу- чения по прецедентам. : Алгоритмическая композиция объединяет базовые алгоритмы, способные самостоятельно решать ту же исходную задачу. : Композиция не знает внутреннего устройства базовых алгоритмов. Для неё это ?чёрные ящики?, имеющие только две функции: обучения по заданной выборке и вычисления ответа для заданного объекта. Это свойство удобно с технологической точки зрения, так как для построения базовых алгорит- мов можно задействовать уже имеющиеся стандартные методы обучения. : Композиция позволяет получать высокое качество обучения, недостижи- мое для отдельных базовых алгоритмов. 2. Два основных принципа построения алгоритмических композиций. : Специализация. Пространство объектов делится на области, в каждой из которых строится свой алгоритм, специализирующийся на объектах только этой области. Исходная задача разбивается на более простые под- задачи по принципу ?разделяй и властвуй?. К таким методам относятся комитеты старшинства [9] и смеси алгоритмов [27]. : Усреднение. В этом случае корректирующая операция не получает инфор- мации о том, в какой области пространства находится объект, и работает только с ответами, выданными базовыми алгоритмами. Если базовые ал- горитмы достаточно различны, то их погрешности компенсируются в ре- зультате усреднения. Причём усреднение следует понимать в обобщённом смысле, это не обязательно среднее арифметическое, и даже не обязатель- но линейная операция. На идее усреднения основаны комитеты большин- ства, бустинг [23], бэггинг [19], монотонная коррекция [2]. 3. Основные стратегии построения алгоритмических композиций.
38 : Последовательная оптимизация. Базовые алгоритмы строятся по очере- ди, и каждый следующий старается компенсировать недостатки предыду- щих. Это жадная стратегия. Она не гарантирует построения наилучшей композиции, но на практике оказывается достаточно удобной. К таким ме- тодам относятся простейшие методы построения комитетов большинства и старшинства, бустинг [37], монотонная коррекция [1]. : Параллельная оптимизация. Базовые алгоритмы настраиваются независи- мо друг от друга. Чтобы они не получались слишком похожими, настрой- ка производится по различным частям обучающей выборки, либо по раз- личным частям признакового описания, либо при различных начальных приближениях. Типичными представителями этого подхода являются бэг- гинг [20], метод случайных подпространств (random subspace method) [39] и генетические алгоритмы [3]. В отличие от последовательной оптимиза- ции, эти алгоритмы допускают эффективную реализацию на параллель- ных вычислительных устройствах. : Глобальная оптимизация одновременно всех базовых алгоритмов являет- ся тяжёлой многоэкстремальной задачей. К тому же, она требует знания внутреннего устройства алгоритмов, что затрудняет применение стандарт- ных методов обучения. На практике применяются разнообразные усовер- шенствования параллельных и последовательных методов, которые не яв- ляются ?глобальными? в полном смысле слова. Например, при построении смесей экспертов базовые алгоритмы и их функции компетентности пере- страиваются поочерёдно и многократно с помощью итерационного процес- са, напоминающего EM-алгоритм [27]. В другом методе с помощью специ- ального генетического алгоритма оптимизируются подмножества объектов и признаков, на которых настраиваются базовые алгоритмы [3]. Фактиче- ски, это развитие идей бэггинга и метода случайных подпространств. : Алгебраический подход, описанный в теоретических работах Журавлёва и его учеников [6, 7], позволяет строить корректные алгоритмические ком- позиции чисто алгебраическими методами, вообще не прибегая к оптимиза- ции. Этот подход крайне продуктивен при исследовании вопросов полноты моделей алгоритмов вида (1.1). Однако он плохо приспособлен для прак- тического построения алгоритмов, так как не позволяет управлять слож- ностью композиции и склонен к переобучению. Более практичные схемы, разработанные в рамках алгебраического подхода, используют упомяну- тую выше стратегию последовательной оптимизации [1, 2]. Упражнения Упр. 1.1. Вывести формулу для коэффициентов взвешенного голосования при ?наивном байесов- ском? предположении, что базовые алгоритмы являются независимыми случайными величинами, см. 1.4. Упр. 1.2. Доказать, что при случайном выборе с возвращениями ? раз из ? объектов отобранными окажутся 1 ? e?1 объектов при ? > ?.