 Г Л А В А  5
ТОЧЕЧНОЕ ПАРАМЕТРИЧЕСКОЕ ОЦЕНИВАНИЕ

В этой и следующей главах рассматриваются задачи получения оценок параметров распределений вероятностей, фигурирующих в той или иной вероятностной модели, по реализациям выборок соответствующих случайных величин, получаемых эмпирическим путем. Процедуры такого оценивания называют иногда "обучением" вероятностных моделей, а используемые выборки - обучающими. Эти выборки (точнее - их реализации) служат исходным "сырьем", превращающим вероятностные модели в рабочий инструмент для исследования описываемых ими реальных явлений.
:5.1. Точечные оценки и их свойства
Рассмотрим постановку и методы решения задач следующего содержания.
Пусть распределение случайной величины Х известно с точностью до типа, т.е.  априори известен вид функции распределения , зависящей, однако, от неизвестного скалярного или векторного неслучайного параметра ( (например, от скаляра ( в показательном распределении , вектора () - в нормальном распределении  и т.д.).
Задача обучения состоит в оценке неизвестного (но остающегося в процессе оценивания неизменным) параметра ( по реализации  простой выборки  случайной величины  X 
,
т.е. в нахождении статистики , которая могла бы быть использована в качестве оценки неизвестного параметра (, удовлетворяя некоторым требованиям, выражающим приемлемость такой оценки. Для каждой реализации выборки  значение  статистики Т представляется точкой в пространстве значений (; поэтому  называется точечной оценкой параметра (.
Для любого параметра ( можно рассматривать ряд статистик, претендующих на роль его точечной оценки. Так, например, в качестве точечной оценки параметра, совпадающего с математическим ожиданием случайной величины  X , можно рассматривать следующие статистики:

(здесь  - i-я порядковая статистика выборки ,  - срединный элемент - медиана - вариационного ряда в предположении, что N - нечетно).
Статистика от выборки объема N, рассматриваемая как оценка параметра ( в общем случае будет обозначаться TN  или Т (для оценок конкретных параметров будут использоваться и иные обозначения).
Заметим, что во всех (специально не оговоренных) случаях неизвестный параметр ( полагается неслучайной величиной, в то время как его оценка  является случайной величиной. 
Выбор той или иной статистики в качестве оценки параметра ( производится с учетом удовлетворения ею следующих требований.
Состоятельность оценки. Естественным требованием к точечной оценке TN  параметра ( является ее сходимость по вероятности с ростом объема выборки  N  к оцениваемому параметру, т.е., выполнение условия (для скалярного ():
  или, короче, .
Оценка, удовлетворяющая этому требованию, называется состоятельной.
Заметим, что термин "состоятельная оценка величины a" применяется в общем случае к любой статистике ZN , сходящейся по вероятности к а при N ( (.
Состоятельность используемой оценки гарантирует возможность сколь угодно точного  (в вероятностном смысле) оценивания неизвестного параметра, если объем обучающей выборки достаточно велик.
Состоятельность оценки  векторного параметра  означает, что каждая компонента  вектора   является состоятельной оценкой соответствующей компоненты вектора .
Несмещенность оценки. Поскольку на практике приходится использовать оценку при фиксированном N, целесообразно позаботиться, чтобы ошибка оценивания не содержала систематической составляющей, т.е. чтобы оценка в среднем была равна оцениваемому параметру. Это требование для скалярного параметра ( выражается в равенстве математического ожидания оценки значению оцениваемого параметра:
.
Оценка, удовлетворяющая этому требованию, называется несмещенной. Ясно, конечно, что значение математического ожидания   должно здесь вычисляться при том фиксированном значении (, при котором формируется реализация выборки , т.е.
.
Наряду со строго несмещенными оценками можно рассматривать асимптотически несмещенные оценки, для которых выполняется равенство
,			      (5.1)
где bN  ( 0 при N ( (.
Пусть дисперсия  оценки TN  для (((( существует и удовлетворяет условию
.			      (5.2)
Тогда нетрудно убедиться, что из несмещенности или асимптотической несмещенности оценки следует ее состоятельность. Действительно, пусть справедливы (5.1) и (5.2). Выберем произвольно ( ( (( ( ( (. Неравенство Чебышева дает
,
. 
Отсюда
, т.е. 
и TN - достаточная оценка  параметра (.
Все сказанное без труда переносится и на случай векторного параметра, если под несмещенностью (асимптотической несмещенностью) оценки векторного параметра понимать удовлетворение этому условию всеми компонентами оценки. 
Параметры распределения случайных величин обычно совпадают или связаны простой зависимостью с их числовыми характеристиками. В связи с этим задачи параметрического оценивания совпадают, как правило, с задачами оценивания числовых характеристик.
Рассмотрим несколько примеров.
Пример 1. Пусть Х - случайная величина с распределением Бернулли с параметром р: , . Примем в качестве оценки р статистику 
.
Несмещенность  очевидна:
.
Дисперсия  равна
  и   при N ( (, 
откуда следует состоятельность оценки .
Пример 2. Рассмотрим две часто встречающиеся статистики
  и  .
Первая из них носит название выборочного среднего и обычно используется как оценка математического ожидания случайной величины Х, а  вторая, именуемая выборочной дисперсией -как оценка её дисперсии (заметим, что для нормального распределения здесь имеет место совпадение параметров распределения и числовых характеристик).
 Пусть Х - случайная величина с конечной дисперсией DX . Тогда  и  при N ( (, что означает несмещенность и состоятельность  как оценки МХ. Далее, легко проверить, что  и 

где  - четвертый начальный момент случайной величины Х. Если он существует и конечен, то  при N ( (, т.е. S 2  - несмещенная состоятельная оценка дисперсии D X .

Эффективность и оптимальность оценок. Состоятельность и несмещенность оценки параметра не исключает, конечно, ошибки оценивания, которая вызвана и зависит от дисперсии оценки: согласно неравенству Чебышева при фиксированном N и любом ( ( ( вероятность отклонения несмещенной оценки TN  от истинного значения скалярного параметра ( более, чем на (, тем больше, чем больше дисперсия оценки  При некотором обобщении понятия дисперсии оценки (что далее и делается) такое положение имеет место и для векторного параметра.
Рассмотрим две несмещенные оценки  и  скалярного параметра ( (опуская индекс  N , указывающий на объем используемых выборок, который принимается равным для обеих оценок). Оценка  считается эффективнее оценки  , если 
для и  
Пусть теперь оцениваемый параметр - вектор, . Обозначим  и  две конкурирующие несмещенные оценки этого параметра , полагая, что он может иметь любое возможное значение из (. Сравнение дисперсионных свойств оценок  и будем теперь проводить, сравнивая значения дисперсий проекций этих векторных оценок на всевозможные направления, задаваемые единичными векторами   в пространстве  (, т.е. дисперсий
,  .
Обозначим  E множество всех единичных векторов  в пространстве ( . Тогда, если выполняются условия
для  и  ,  (5.3)
то оценка эффективнее оценки  .
(Напомним, что , где - корреляционная матрица вектора ).
Условия (5.3) означают, в частности, что значения дисперсий всех компонент оценки  не превышают значений дисперсии соответствующих компонент .
Из приведенного определения сравнительной эффективности двух оценок легко заметить, что их упорядочение по эффективности не всегда возможно, поскольку значения фигурирующих в этих определениях дисперсий зависят от значений оцениваемого параметра. 
Рассмотрим подробнее вопрос о существовании наиболее эффективных несмещенных оценок.
Пусть  T  множество несмещенных оценок параметра ( и существует оценка (  T  такая, что выполняется условие:
для , 
где , .

Тогда оценка Т 0 называется оптимальной.
Докажем справедливость утверждения:
Если оптимальная оценка параметра (  существует, то она единственна.
(Единственность понимается здесь в том смысле, что две оптимальные оценки равны друг другу с вероятностью 1).
Допустим обратное и пусть  - две оптимальные оценки параметра . Образуем третью статистику . Из  следует 
Корреляционная матрица статистики  равна
,
где	 - корреляционные матрицы оценок  и , . Далее получаем

(поскольку ).
 Из оптимальности  следует, что
,
откуда, ввиду 
, 
получаем
. 
Для набора Е0 всех несовпадающих единичных векторов  (r - размерность параметра ), каждый из которых имеет по одной отличной от нуля (т.е. равной единице) компоненте, получим r неравенств
    (5.4)
где - i-е компоненты векторов ,  - их корреляционный момент,   -  их дисперсии: 
.
С другой стороны, имеет место неравенство Коши-Буняковского:
,	     (5.5)
вследствие чего
       ,		      (5.6)
что выполняется лишь в том случае, если (с вероятностью 1)
	                  (5.7)
(это легко проверить, вспомнив, как получается неравенство (5.5)). Из несмещенности оценок  получим
,
где  - i-я компонента параметра , или
.
Но в силу равенства (5.7)
,
откуда  и т.е. с вероятностью 1.
При выполнении определенных условий, налагаемых на распределение случайной величины  X , существует нижняя грань дисперсии D T несмещенной  оценки  T  скалярного параметра ( или обобщенной дисперсии оценки векторного параметра  в введенном выше смысле.
Это следует из теоремы Рао-Крамера, доказательство которой для векторного параметра проведем в предположении о непрерывном распределении случайной величины Х с плотностью  (доказательство для дискретного случая осуществляется аналогично с заменой интегралов суммами или рядами).
Обозначим, как обычно,  X(N) простую выборку случайной величины X,   - функцию правдоподобия для  X(N) = x(N) , ( - пространство значений параметра ,  T  - множество несмещенных оценок T  параметра ,  E  - множество всех единичных векторов   в пространстве (.
Пусть выполнены условия:
а) выборочное пространство X( N ) (множество значений выборки X(N), для которого P{X(N )( X} = 1) не зависит от значения оцениваемого параметра ;
б) для  допускается дифференцирование по компонентам ( i  параметра  под знаком интегралов:
;
это условие будем называть условием  регулярности функции правдоподобия  (которую для краткости будем ниже обозночать  L) ;
в) матрица  - неособенная. 
Тогда для  имеет место неравенство, именуемое неравенством Рао-Крамера: 
.		     (5.8)
Доказательство. Введем случайный вектор
,
для которого, в силу тождества ),

и .
Для корреляционной матрицы вектора  получим
.
Образуем вектор

с математическим ожиданием 

и с корреляционной матрицей
          (5.9)
(здесь для вычисления матриц  B 1 и  B 2, равных, соответственно, 

использованы равенства
 ,
из которых следует, что эти матрицы - единичные).
В силу неотрицательной определенности корреляционной матрицы RZ получаем
,
откуда и следует (5.8).
Если ( - скаляр, то левая часть неравенства (5.8) оказывается равной дисперсии оценки и примет вид
.		    (5.10)
(далее дисперсия статистики  T будет изображаться DT  или  DT  в зависимости от удобства записи).
 Вернемся к случаю векторного параметра. Пусть функция правдоподобия  дополнительно к указанным выше условиям допускает повторное дифференцирование под знаком интеграла:
.
Тогда возможны тождественные преобразования:

или
,
т.е. матрица  A   в (5.8) представима в виде
,
а в случае скалярного параметра ( (5.10) принимает вид
.	    (5.11)
Интересны случаи, когда (5.8) и (5.10) превращаются в равенства. Если (5.8) выполняется в виде равенств для всех векторов  из Е0, то
,			    (5.12)
где  - дисперсия i-й компоненты оценки  - i-й диагональный элемент матрицы  A --1; при этом, следовательно, дисперсии оценок компонент векторного параметра  достигают минимума. Для скалярного параметра это соответствует оценке Т, обладающей дисперсией, равной нижней ее границе.
Несмещенные оценки, удовлетворяющие (5.12), называются эффективными. Ясно, что эффективная оценка одновременно оптимальна и, соответственно, единственна. Из этого, однако, не следует непременная эффективность оптимальных оценок, поскольку эффективные оценки не всегда существуют (что, впрочем, относится и к оптимальным оценкам).
Для скалярного параметра ( (5.12) представимо (с учетом (5.11)) в виде
.
С другой стороны, ввиду равенства

получим  
,
т.е. неравенство Коши-Буняковского превращается в равенство:
,
что имеет место лишь в том случае, если
,
т.е. если функция правдоподобия может быть представлена в виде
, 	    (5.13)
где функции  и , зависящие, соответственно, только от выборки  и от значения параметра (, определяются содержанием решаемой задачи, конкретно -типом распределения случайной величины  X .
Равенство (5.13) является, следовательно, необходимым и достаточным условием эффективности оценки Т скалярного параметра (.
Следует заметить, что при векторном параметре  отдельные его компоненты могут иметь эффективные оценки при отсутствии таковых для других его компонент. Так, например, в случае нормального распределения  с неизвестным векторным параметром  выборочное среднее

является эффективной оценкой математического ожидания, в то время как эффективная оценка дисперсии (2 отсутствует.
Полезно ввести понятие асимптотически эффективной оценки  компоненты параметра , при условии (ср. (5.12)):

или для скалярного параметра
.
В случае нормального распределения (при неизвестном ) асимптотически эффективной оценкой дисперсии (2 является выборочная дисперсия, т.е. статистика
. 

Достаточные оценки параметров распределений. Важным свойством, которым может обладать статистика, используемая  как оценка параметра распределения, является её достаточность относительно оцениваемого параметра. Рассмотрим это свойство подробнее.
Прежде всего заметим, что оценка параметра распределения ( с помощью выборки X (N) имеет смысл лишь в том случае, если распределение X (N) зависит от значения ( (лишь в этом случае, собственно, и можно считать ( параметром распределения Х и, следовательно, X (N)). 
Пусть существует статистика T = T(X, ., XN ), такая, что при фиксированном T = t распределение X (N ) перестает зависеть от (, т.е.

или
		.		    (5.14)
Тогда можно утверждать, что в t содержится вся информация о ( как о параметре распределения Х. Статистика Т, удовлетворяющая (5.14), называется достаточной  относительно параметра (.
Справедливо следующее утверждение, называемое критерием факторизации:
 Необходимым и достаточным условием достаточности статистики Т относительно параметра ( является представимость функции правдоподобия  в виде
,		    (5.15)
где  непосредственно не зависит от  x  (N ), а   h ( x  (N )) непосредственно  не зависит от (.
Покажем, что это действительно так в случае дискретного распределения Х. Имеет место равенство

(здесь , поскольку ).
Вместе с тем
.
Но  - функция правдоподобия для дискретного случая. Если она удовлетворяет (5.15), то

(достаточность условия (5.15)).
Необходимость условия (5.15) следует из записи (5.14) в виде
.
Доказательство критерия факторизации для непрерывного случая несколько сложнее и здесь не приводится.
Интересно сопоставить свойства эффективности и достаточности оценок. Мы видели, что эффективность оценки (в случае скалярного параметра) имеет место, когда функция правдоподобия представима в виде (5.13), что является частным случаем (5.15). Следовательно, эффективная оценка всегда достаточна. Обратное утверждать нельзя: существуют достаточные, но не эффективные оценки параметров.


:5.2. Методы точечного оценивания 
неслучайного параметра

Перейдем к методам получения точечных оценок параметров распределения. Эти методы основаны обычно на определенных эвристических предпосылках, приемлемость которых проверяется затем на основе анализа свойств получаемых оценок.

Метод моментов. Этот метод основан на том, что параметры распределения случайной величины  часто связаны простой функциональной зависимостью с её моментами, что позволяет выражать оценки параметров распределений оценками и х моментов. 
Пусть существует конечный начальный момент случайной величины  X
 
Читатель легко убедится, что при существовании конечного начального момента  состоятельной несмещенной оценкой момента  служит  выборочный начальный момент  j -го порядка  
 ,
вычисляемый по простой выборке  случайной величины  X .
Пусть распределение случайной величины Х имеет известный аналитический вид с (неизвестным) векторным параметром и с конечным    моментом . Тогда, составляя  r  уравнений 
,		    (5.16)
можно попытаться разрешить их относительно. 
Пусть между  и  существует взаимно однозначное и взаимно непрерывное соответствие; тогда, разрешая (5.16) относительно , получим
,
причем  - непрерывные функции. Известно, что в этом случае при

имеет место сходимость
,
т.е. оценка  параметра  при сделанных предположениях состоятельна. Получаемые этим методом моментов оценки часто обладают асимптотической несмещенностью, причем введением соответствующих поправок (корректирующих множителей) можно добиться их несмещенности. Эффективность и асимптотическая эффективность оценок, получаемых этим методом, не гарантируется даже в тех случаях, когда оценки, отвечающие этим требованиям, в принципе существуют.
Тем не менее, метод моментов часто используется ввиду простоты его реализации.

Метод (2. В этом методе используется уже знакомая нам (см. (4.3)) статистика
,			    (5.17)
которая при  N  ( ( сходится по распределению к случайной величине  с распределением "хи-квадрат" с  k-1  числом степеней свободы.
Вероятности  в (5.17) зависят от неизвестного параметра :

и, следовательно,
.
Метод (2 сводится к подбору  таких значений  при которых , как мера несоответствия выборки  теоретическому распределению , достигает минимума, т.е.
;
в частности, когда функциональный вид распределения Х позволяет это сделать, оценка  находится из системы уравнений:
.
Получив , можно проверить гипотезу об истинности распределения  с помощью описанного выше критерия согласия (2. Метод (2 в большом числе случаев дает состоятельные несмещенные и асимптотически эффективные оценки. Однако ему свойственны аналитические трудности.

Метод наибольшего правдоподобия (МНП). Метод наибольшего правдоподобия занимает центральное место среди методов параметрического оценивания.
Идея МНП состоит в том, что в качестве оценки неизвестного параметра  распределения случайной величины Х выбирается то его значение  (называемое МНП-оценкой), которое для полученного значения выборки  соответствует нибольшему значению функции правдоподобия , т.е. при котором полученное значение  выборки  наиболее вероятно (если Х имеет дискретное распределение) или имеет наибольшую плотность распределения (если случайная величина Х распределена абсолютно непрерывно), т.е.

Такой подход к оценке неизвестного параметра распределения носит, несомненно, эвристический характер. Однако, как будет показано ниже, он дает хорошие результаты.
Поиск глобального максимума  не всегда прост. Однако во многих случаях он сводится к решению системы уравнений:
 
 или 
                  (5.18)
Перейдем к изучению свойств МНП-оценок. Покажем справедливость следующих двух утверждений.
Утверждение 1. Если существует эффективная оценка  параметра (, то МНП-оценка этого параметра  существует и равна .
Утверждение 2. Если Т - статистика, достаточная относительно параметра (, то МНП-оценка  есть функция от Т.
Ограничимся случаем скалярного параметра (; распространение результата на векторный случай не вызывает принципиальных затруднений.
Итак, пусть выполняются условия существования нижней границы дисперсии оценки ( и  - эффективная оценка, для которой, следовательно, 
.		(5.19)
С другой стороны,  есть корень уравнения
,			    (5.20)
причем по смыслу рассматриваемого метода нас интересуют лишь корни этого уравнения, зависящие от выборки .
Поэтому

есть единственный корень (5.20). Нетрудно убедиться, что  доставляет максимум :
,
но
,
отсюда
,
т.е. - точка максимума.
Для доказательства второго утверждения используем критерий факторизации
,
 из которого для реализаций оценки  и статистики  T  получаем
    
т.е. .
Докажем теперь следующее утверждение о состоятельности, асимптотической нормальности и асимптотической эффективности МНП-оценки.
Утверждение 3. Пусть плотность распределения  fX ( x ;  ( ) случайной величины Х удовлетворяет условиям: 
а) существуют производные
;
б) допустимо двукратное дифференцирование под знаком интеграла в выражениях
;
;

(С не зависит от ();
г) уравнение (5.18) имеет единственное решение.
При этих условиях МНП-оценка состоятельна, асимптотически нормальна и асимптотически эффективна.

Для доказательства этого утверждений сделаем несколько замечаний. 
Легко видеть, что условия a) и б) распространяются на функцию правдоподобия 
Заметим, также, что первое соотношение в условии в) можно записать в виде 
(см.5.11).

Пусть   -  значение  i- го элемента выборки X(N) . Обозначим (0 истинное значение ( и представим  разложением Тейлора относительно точки (0:

Но 

поэтому
где . 
Переходя к функции правдоподобия , запишем
,      (5.21)
где

     ,

Но

и, в силу закона больших чисел в форме Хинчина, при  N (( получим , , . 
Из (5.21) непосредственно видно, что знак производной в левой части этого равенства вблизи точки ( = (0  при достаточно большом  N  определяется знаком второго члена правой части равенства. 
Действительно, пусть ( = ( - (0  >0 , . Рассмотрим  события 
 и зададим произвольное (  > 0 .
Справедливо неравенство
.
Из обнаруженной выше сходимости В0, В1 и В2 следует

и
,
т.е. с вероятностью, превышающей 1- (, одновременно выполняются условия:
,
или . Поэтому, поскольку , . Пусть теперь  (при сохранении неравенства ). С вероятностью, превышающей 1 - (, , и поскольку , , т.е. . Следовательно, в силу непрерывности  (существования ) с вероятностью, превышающей 1 - (, единственный корень (N  уравнения (5.18), т.е. МНП-оценка , отличается от (0 не более, чем на (, причем ( и ((( могут быть сколь угодно малыми, если N достаточно велико; иначе говоря при , т.е. , это и означает состоятельность МНП-оценки  параметра (. 
Далее, поскольку  есть решение уравнения
,
то
 .
Здесь числитель в В0 представляет собой сумму SN  N  одинаково распределенных независимых случайных величин. Из центральной предельной теоремы следует
;
отсюда
.
Справедлива лемма: если , где  , а > 0 (а - неслучайная величина), то
.
Поэтому ввиду -
,

или
,	    (5.22)
что означает асимптотическую нормальность МНП-оценки  параметра (. Кроме того, из (5.22) непосредственно видно, что при N ( (

(см. (5.11)), т.е.  - асимптотически эффективная оценка (.
Отметим еще одну особенность МНП-оценки - т.н. свойство инвариантности. Пусть s = ((() - взаимно однозначная функция оцениваемого параметра ( и при   имеет глобальный максимум, т.е.  - МНП-оценка (. Тогда
.
Подставляя в  ( = (-1(s), получим . Ясно, что
,
где , т.е.  - МНП-оценка s. Итак

т.е. при указанных выше условиях МНП-оценка функции параметра распределения равна функции от МНП-оценки этого параметра.


5.3. Оценка случайного параметра

До сих пор предполагалось, что оцениваемый параметр распределения является неизвестной неслучайной величиной. Возможны, однако, модели, в которых параметр распределения сам является случайной величиной (обозначим её ), т.е. принимает значения из ( согласно распределению (функции распределения) . Предполагается, однако, что в процессе получения реализации выборки  значение  фиксировано и может изменяться согласно  лишь при переходе от выборки к выборке (иначе выборки перестали бы быть простыми).
В качестве оценки параметра  в этом случае обычно используют его апостериорное математическое ожидание:
,
где
,
 - условная функция правдоподобия,

Преимущество такой оценки заключается в том, что средний квадрат модуля отклонения от нее истинного значения параметра  достигает наименьшего значения по сравнению с другими оценками (для каждого  и, следовательно, в среднем по выборке).
Действительно, пусть  произвольная оценка параметра , не совпадающая с оценкой  на множестве значений  ненулевой меры.  Проверив соотношения 
 
 читатель убедится в справедливости сказанного.





