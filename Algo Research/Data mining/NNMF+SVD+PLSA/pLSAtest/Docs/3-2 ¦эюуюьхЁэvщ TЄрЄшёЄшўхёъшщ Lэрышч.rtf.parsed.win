3.2. Многомерный статистический анализ	В многомерном статистическом анализе выборка состоит из элементов многомерного пространства. Отсюда и название этого раздела прикладной статистики. Из многих задач многомерного статистического анализа рассмотрим основные - корреляцию, восстановление зависимости, классификацию, уменьшение размерности, индексы.3.2.1. Коэффициенты корреляции	Термин "корреляция" означает "связь". В эконометрике этот термин обычно используется в сочетании "коэффициенты корреляции". Рассмотрим линейный и непараметрические парные коэффициенты корреляции.	Обсудим способы измерения связи между двумя случайными переменными. Пусть исходными данными является набор случайных векторов  Выборочным коэффициентом корреляции, более подробно, выборочным линейным парным коэффициентом корреляции К. Пирсона, как известно, называется числоЕсли rn = 1, то  причем a>0. Если же rn = - 1, то  причем a<0. Таким образом, близость коэффициента корреляции к 1 (по абсолютной величине) говорит о достаточно тесной линейной связи. 	Если случайные вектора  независимы и одинаково распределены, то выборочный коэффициент корреляции сходится к теоретическому при безграничном возрастании объема выборки:(сходимость по вероятности).	Более того, выборочный коэффициент корреляции является асимптотически нормальным. Это означает, чтогде - функция стандартного нормального распределения с математическим ожиданием 0 и дисперсией 1, а - асимптотическая дисперсия выборочного коэффициента корреляции. Она имеет довольно сложное выражение, приведенное в монографии [1, с.393]:Здесь под  понимаются теоретические центральные моменты порядка k и m, а именно,.	Коэффициенты корреляции типа rn используются во многих алгоритмах многомерного статистического анализа. В теоретических рассмотрениях часто считают, что случайные вектора  имеют двумерное нормальное распределение. Распределения реальных данных, как правило, отличны от нормальных (см. главу 2.1). Почему же распространено представление о двумерном нормальном распределении? Дело в том, что теория в этом случае проще. В частности, равенство 0 теоретического коэффициента корреляции эквивалентно независимости случайных величин. Поэтому проверка независимости сводится к проверке статистической гипотезы о равенстве 0 теоретического коэффициента корреляции. Эта гипотеза принимается, если , где- некоторое граничное значение, зависящее от объема выборки n и уровня значимости .	Если предположение о двумерной нормальности не выполнено, то из равенства 0 теоретического коэффициента корреляции не вытекает независимость случайных величин. Нетрудно построить пример случайного вектора, для которого коэффициент корреляции равен 0, но координаты зависимы. Кроме того, для проверки гипотез о коэффициенте корреляции нельзя пользоваться таблицами, рассчитанными в предположении нормальности. Можно построить правила принятия решений на основе асимптотической нормальности выборочного коэффициента корреляции. Но есть и другой путь - перейти к непараметрическим коэффициентам корреляции, одинаково пригодным при любом непрерывном распределении случайного вектора.	Для расчета непараметрического коэффициента ранговой корреляции Спирмена необходимо сделать следующее. Для каждого xi рассчитать его ранг ri в вариационном ряду, построенном по выборке Для каждого yi рассчитать его ранг qi в вариационном ряду, построенном по выборке  Для набора из n пар вычислить линейный коэффициент корреляции. Он называется коэффициентом ранговой корреляции, поскольку определяется через ранги. В качестве примера рассмотрим данные из табл.1 (см. монографию [2]).Таблица 1. Данные для расчета коэффициентов корреляции?i12345??xi510152025??yi673081300??ri12345??qi12345?	Для данных табл.1 коэффициент линейной корреляции равен 0,83, непосредственной линейной связи нет. А вот коэффициент ранговой корреляции равен 1, поскольку увеличение одной переменной однозначно соответствует увеличению другой переменной. Во многих экономических задачах, например, при выборе инвестиционных проектов, достаточно именно монотонной зависимости одной переменной от другой.	Поскольку суммы рангов и их квадратов нетрудно подсчитать, то коэффициент ранговой корреляции Спирмена равенОтметим, что коэффициент ранговой корреляции Спирмена остается постоянным при любом строго возрастающем преобразовании шкалы измерения результатов наблюдений. Другими словами, он является адекватным в порядковой шкале (см. главу 2.1), как и другие ранговые статистики, например, статистики Вилкоксона, Смирнова, типа омега-квадрат для проверки однородности независимых выборок (глава 3.1). 	Широко используется также коэффициент ранговой корреляции Кендалла, коэффициент ранговой конкордации Кендалла и Б. Смита и др. Наиболее подробное обсуждение этой тематики содержится в монографии [3], необходимые для практических расчетов таблицы имеются в справочнике [4]. Дискуссия о выборе вида коэффициентов корреляции продолжается до настоящего времени [2].3.2.2. Восстановление линейной зависимости между двумя переменными	Начнем с задачи точечного и доверительного оценивания линейной функции одной переменной.	Исходные данные - набор n пар чисел (tk , xk), k = 1,2,.,n, где tk - независимая переменная (например, время), а xk - зависимая (например, индекс инфляции, курс доллара США, объем месячного производства или размер дневной выручки торговой точки). Предполагается, что переменные связаны зависимостьюxk = a (tk - tср)+ b + ek , k = 1,2,.,n, где a и b - параметры, неизвестные статистику и подлежащие оцениванию, а ek - погрешности, искажающие зависимость. Среднее арифметическое моментов времениtср = (t1 + t2 +.+tn )/nвведено в модель для облегчения дальнейших выкладок.	Обычно оценивают параметры a и b линейной зависимости методом наименьших квадратов. Затем восстановленную зависимость используют, например, для точечного и интервального прогнозирования. 	Как известно, метод наименьших квадратов был разработан великим немецким математиком К. Гауссом в 1794 г. Согласно этому методу для расчета наилучшей функции, приближающей линейным образом зависимость x от t, следует  рассмотреть функцию двух переменныхОценки метода наименьших квадратов - это такие значения a* и b*, при которых функция f(a,b) достигает минимума по всем значениям аргументов. 	Чтобы найти эти оценки, надо вычислить частные производные от функции f(a,b) по аргументам a и b, приравнять их 0, затем из полученных уравнений найти оценки: Имеем:Преобразуем правые части полученных соотношений. Вынесем за знак суммы общие множители 2 и (-1). Затем рассмотрим слагаемые. Раскроем скобки в первом выражении, получим, что каждое слагаемое разбивается на три. Во втором выражении также каждое слагаемое есть сумма трех. Значит, каждая из сумм разбивается на три суммы. Имеем:Приравняем частные производные 0. Тогда в полученных уравнениях можно сократить множитель (-2). Поскольку		(1)уравнения приобретают видСледовательно, оценки метода наименьших квадратов имеют вид  (2)	В силу соотношения (1) оценку а* можно записать в более симметричном виде:Эту оценку нетрудно преобразовать и к видуСледовательно, восстановленная функция, с помощью которой можно прогнозировать и интерполировать, имеет вид x*(t) = a*(t - tср)+ b*.	Обратим внимание на то, что использование tср  в последней формуле ничуть не ограничивает ее общность. Сравним с моделью видаxk = c tk+ d + ek , k = 1,2,.,n. Ясно, что Аналогичным образом связаны оценки параметров:	Для получения оценок параметров и прогностической формулы нет необходимости обращаться к какой-либо вероятностной модели. Однако для того, чтобы изучать погрешности оценок параметров и восстановленной функции, т.е. строить доверительные интервалы для a*, b* и x*(t), подобная модель необходима.	Непараметрическая вероятностная модель. Пусть значения независимой переменной t детерминированы, а погрешности ek , k = 1,2,.,n, - независимые одинаково распределенные случайные величины с нулевым математическим ожиданием и дисперсией неизвестной статистику.	В дальнейшем неоднократно будем использовать Центральную Предельную Теорему (ЦПТ) теории вероятностей для величин ek , k = 1,2,.,n (с весами), поэтому для выполнения ее условий необходимо предположить, например, что погрешности ek , k = 1,2,.,n, финитны или имеют конечный третий абсолютный момент. Однако заострять внимание на этих внутриматематических "условиях регулярности" нет необходимости.	Асимптотические распределения оценок параметров. Из формулы (2) следует, что   (5)Согласно ЦПТ оценка b* имеет асимптотически нормальное распределение с математическим ожиданием b и дисперсией оценка которой приводится ниже. 	Из формул (2) и (5) вытекает, чтоПоследнее слагаемое во втором соотношении при суммировании по i обращается в 0, поэтому из формул (2-4) следует, что    (6)Формула (6) показывает, что оценка  является асимптотически нормальной с математическим ожиданием и дисперсиейОтметим, что многомерная нормальность имеет быть, когда каждое слагаемое в формуле (6) мало сравнительно со всей суммой, т.е. 	Из формул (5) и (6) и исходных предположений о погрешностях вытекает также несмещенность оценок параметров.	Несмещенность и асимптотическая нормальность оценок метода наименьших квадратов позволяют легко указывать для них асимптотические доверительные границы (аналогично границам в предыдущей главе) и проверять статистические гипотезы, например, о равенстве определенным значениям, прежде всего 0. Предоставляем читателю возможность выписать формулы для расчета доверительных границ и сформулировать правила проверки упомянутых гипотез.	Асимптотическое распределение прогностической функции. Из формул (5) и (6) следует, чтот.е. рассматриваемая оценка прогностической функции является несмещенной. Поэтому При этом, поскольку погрешности независимы в совокупности и , тоТаким образом, Итак, оценка является несмещенной и асимптотически нормальной. Для ее практического использования необходимо уметь оценивать остаточную дисперсию 	Оценивание остаточной дисперсии. В точках tk , k = 1,2,.,n, имеются исходные значения зависимой переменной xk  и восстановленные значения x*(tk). Рассмотрим остаточную сумму квадратовВ соответствии с формулами (5) и (6)Найдем математическое ожидание каждого из слагаемых:Из сделанных ранее предположений вытекает, что при имеем следовательно, по закону больших чисел статистикаSS/n является состоятельной оценкой остаточной дисперсии .	Получением состоятельной оценкой остаточной дисперсии завершается последовательность задач, связанных с рассматриваемым простейшим вариантом метода наименьших квадратов. Не представляет труда выписывание верхней и нижней границ для прогностической функции:где погрешность имеет видЗдесь p - доверительная вероятность, U(p), как и в главе 3.1 - квантиль нормального распределения порядка (1+р)/2, т.е.При p= 0,95 (наиболее применяемое значение) имеем U(p) = 1,96. Для других доверительных вероятностей соответствующие значения квантилей можно найти в статистических таблицах (см., например, наилучшее в этой сфере издание [4]).	Сравнение параметрического и непараметрического подходов. Во многих литературных источниках рассматривается параметрическая вероятностная модель метода наименьших квадратов. В ней предполагается, что погрешности имеют нормальное распределение. Это предположение позволяет математически строго получить ряд выводов. Так, распределения статистик вычисляются точно, а не в асимптотике, соответственно вместо квантилей нормального распределения используются квантили распределения Стьюдента, а остаточная сумма квадратов SS делится не на n, а на (n-2). Ясно, что при росте объема данных различия стираются. 	Рассмотренный выше непараметрический подход не использует нереалистическое предположение о нормальности погрешностей (см. главу 2.1). Платой за это является асимптотический характер результатов. В случае простейшей модели метода наименьших квадратов оба подхода дают практически совпадающие рекомендации. Это не всегда так, не всегда два подхода дают близкие результаты. Напомним, что в задаче обнаружения выбросов методы, опирающиеся на нормальное распределение, нельзя считать обоснованными, и обнаружено было это их свойство с помощью непараметрического подхода (см. главу 2.3).	Общие принципы. Кратко сформулируем несколько общих принципов построения, описания и использования методов прикладной статистики. Во-первых, должны быть четко сформулированы исходные предпосылки, т.е. полностью описана используемая вероятностно-статистическая модель. Во-вторых, не следует принимать предпосылки, которые редко выполняются на практике. В-третьих, алгоритмы расчетов должны быть корректны с точки зрения математико-статистической теории. В-четвертых, алгоритмы должны давать полезные для практики выводы. 	Применительно к задаче восстановления зависимостей это означает, что целесообразно применять непараметрический подход, что и сделано выше. Однако предположение нормальности, хотя и очень сильно сужает возможности применения, с чисто математической точки зрения позволяет продвинуться дальше. Поэтому для первоначального изучения ситуации, так сказать, "в лабораторных условиях", нормальная модель может оказаться полезной.	Пример оценивания по методу наименьших квадратов. Пусть даны n = 6 пар чисел (tk , xk), k = 1,2,.,6, представленных во втором и третьем столбцах табл.2. В соответствии с формулами (2) и (4) выше для вычисления оценок метода наименьших квадратов достаточно найти суммы выражений, представленных во втором, третьем, четвертом и пятом столбцах табл.2.Таблица 2. Расчет по методу наименьших квадратов при восстановлении линейной функции одной переменной?itixi()2??11121123,1412,17-0,170,03??23209609,4218,451,552,40??3420168012,5621,59-1,592,53??47324922421,9831,010,990,98??59358131528,2637,29-2,295,24??6104210042031,4040,431,572,46??3416125611110,0613,64??5,6726,8342,67185,17?	В соответствии с формулой (2) b* =26,83, а согласно формуле (4)Следовательно, прогностическая формула имеет вид	Следующий этап анализа данных - оценка точности приближения функции методом наименьших квадратов. Сначала рассматриваются т.н. восстановленные значенияЭто те значения, которые полученная в результате расчетов прогностическая функция принимает в тех точках, в которых известны истинные значения зависимой переменной xi . 	Вполне естественно сравнить восстановленные и истинные значения. Это и сделано в шестом - восьмом столбцах табл. 2. Для простоты расчетов в шестом столбце представлены произведения , седьмой отличается от шестого добавлением константы 9,03 и содержит восстановленные значения. Восьмой столбец - это разность третьего и седьмого. 	Непосредственный анализ восьмого столбца табл.2 показывает, что содержащиеся в нем числа сравнительно невелики по величине по сравнению с третьим столбцом (на порядок меньше по величине). Кроме того, знаки "+" и "-" чередуются. Эти два признака свидетельствуют о правильности расчетов. При использовании метода наименьших квадратов знаки не всегда чередуются. Однако если сначала идут только плюсы, а потом только минусы (или наоборот, сначала только минусы, а потом только плюсы), то это верный показатель того, что в вычислениях допущена ошибка. 	Верно следующее утверждение.	Теорема.	Доказательство этой теоремы оставляем читателю в качестве упражнения. 	Однако сумма по восьмому столбцу дает 0,06, а не 0. Незначительное отличие от 0 связано с ошибками округления при вычислениях. Близость суммы значений зависимой переменной и суммы восстановленных значений - практический критерий правильности расчетов.	В последнем девятом столбце табл.2 приведены квадраты значений из восьмого столбца. Их сумма - это остаточная сумма квадратов SS = 13,64. В соответствии со сказанным выше оценками дисперсии погрешностей и их среднего квадратического отклонения являются	Рассмотрим распределения оценок параметров. Оценка b* имеет асимптотически нормальное распределение с математическим ожиданием b и дисперсией, которая оценивается как 2,27/6=0,38 (здесь считаем, что 6 - "достаточно большое" число, что, конечно, можно оспаривать). Оценкой среднего квадратического отклонения является 0,615. Следовательно, при доверительной вероятности 0,95 доверительный интервал для параметра b имеет вид (26,83 - 1,96.0,615; 26,83 + 1,96.0,615) = (25,625; 28,035).	В формулах для дисперсий участвует величинаПодставив численные значения, получаем, чтоДисперсия для оценки а* коэффициента при линейном члене прогностической функции оценивается как 2,27/63,1=0,036, а среднее квадратическое отклонение - как 0,19. Следовательно, при доверительной вероятности 0,95 доверительный интервал для параметра а имеет вид (3,14 - 1,96.0,19; 3,14 + 1,96,0,19) = (2,77; 3,51).	Прогностическая формула с учетом погрешности имеет вид (при доверительной вероятности 0,95)В этой записи сохранено происхождение различных составляющих. Упростим:Например, при t = 12 эта формула даетСледовательно, нижняя доверительная граница - это 44,095, а верхняя доверительная граница - это 49,325.	Насколько далеко можно прогнозировать? Обычный ответ таков - до тех пор, пока сохраняется тот стабильный комплекс условий, при котором справедлива рассматриваемая зависимость. Изобретатель метода наименьших квадратов Карл Гаусс исходил из задачи восстановления орбиты астероида (малой планеты) Церера. Движение подобных небесных тел может быть рассчитано на сотни лет. А вот параметры комет (например, срок возвращения) не поддаются столь точному расчету, поскольку за время пребывания в окрестности Солнца сильно меняется масса кометы. В социально-экономической области горизонты надежного прогнозирования еще менее определены. В частности, они сильно зависят от решений центральной власти.	Чтобы выявить роль погрешностей в прогностической формуле, рассмотрим формальный предельный переход  Тогда слагаемые 9,03; 1/6; 5,67 становятся бесконечно малыми, и Таким образом, погрешности составляют около от тренда (математического ожидания) прогностической функции. В социально-экономических исследованиях подобные погрешности считаются вполне приемлемыми.3.2.3. Основы линейного регрессионного анализа	Метод наименьших квадратов, рассмотренный в простейшем случае, допускает различные обобщения. Например, метод наименьших квадратов дает алгоритм расчетов, если исходные данные - по-прежнему набор n пар чисел (tk , xk), k = 1,2,.,n, где tk - независимая переменная (например, время), а xk - зависимая (например, индекс инфляции), а восстанавливать надо не линейную зависимость, а квадратическую:Следует рассмотреть функцию трех переменныхОценки метода наименьших квадратов - это такие значения параметров a*, b* и с*, при которых функция  f(a,b,с) достигает минимума по всем значениям аргументов. Чтобы найти эти оценки, надо вычислить частные производные от функции f(a,b,с) по аргументам a, b и с, приравнять их 0, затем из полученных уравнений найти оценки: Имеем:Приравнивая частную производную к 0, получаем линейное уравнение относительно трех неизвестных параметров a,b,c:Приравнивая частную производную по параметру b к 0, аналогичным образом получаем уравнениеНаконец, приравнивая частную производную по параметру с к 0, получаем уравнениеРешая систему трех уравнений с тремя неизвестными, находим оценки метода наименьших квадратов. 	Другие задачи, рассмотренные в предыдущем подразделе (доверительные границы для параметров и прогностической функции и др.), также могут быть решены. Соответствующие алгоритмы более громоздки. Для их записи полезен аппарат матричной алгебры (см., например, одну из лучших в этой области монографий [5]). Для реальных расчетов используют соответствующие компьютерные программы. 	Раздел прикладной статистики, посвященный восстановлению зависимостей, называется регрессионным анализом. Термин "линейный регрессионный анализ" используют, когда рассматриваемая функция линейно зависит от оцениваемых параметров (от независимых переменных зависимость может быть произвольной). Теория оценивания неизвестных параметров хорошо развита именно в случае линейного регрессионного анализа. Если же линейности нет и нельзя перейти к линейной задаче, то, как правило, хороших свойств от оценок ожидать не приходится.	Продемонстрируем подходы в случае зависимостей различного вида. Если зависимость имеет вид многочлена (полинома)то коэффициенты многочлена могут быть найдены путем минимизации функцииФункция от t не обязательно должна быть многочленом. Можно, например, добавить периодическую составляющую, соответствующую сезонным колебаниям. Хорошо известно, например, что инфляция (рост потребительских цен) имеет четко выраженный годовой цикл. А именно, в среднем цены быстрее всего растут зимой, в декабре - январе, а медленнее всего (иногда в среднем даже падают) летом, в июле - августе. Пусть для определенноститогда неизвестные параметры могут быть найдены путем минимизации функции	Пусть I(t) -индекс инфляции в момент t. Принцип стабильности условий приводит к гипотезе о постоянстве темпов роста средних цен, т.е. индекса инфляции. Таким образом, естественная модель для индекса инфляции - этоЭта модель не является линейной, метод наименьших квадратов непосредственно применять нельзя. Однако если прологарифмировать обе части предыдущего равенства:то получим линейную зависимость, рассмотренную выше.	Независимых переменных может быть не одна, а несколько. Пусть, например, по исходным данным требуется оценить неизвестные параметры a и b в зависимостигде  - погрешность. Это можно сделать, минимизируя функцию	Зависимость от х и у не обязательно должна быть линейной. Предположим, что из каких-то соображений известно, что зависимость должна иметь видтогда для оценки пяти параметров необходимо минимизировать функцию	Более подробно рассмотрим пример из микроэкономики. В одной из оптимизационных моделей поведения фирмы используется т.н. производственная функция f(K,L), задающая объем выпуска в зависимости от затрат капитала K и труда L. В качестве конкретного вида производственной функции часто используется так называемая функция Кобба-ДугласаОднако откуда взять значения параметров  и ? Естественно предположить, что они - одни и те же для предприятий отрасли. Поэтому целесообразно собрать информацию где fk - объем выпуска на k-ом предприятии, Kk- объем затрат капитала на k-ом предприятии, Lk - объем затрат труда на k-ом предприятии (в кратком изложении не пытаемся дать точных определений используемым понятиям из экономики предприятия). По собранной информации естественно попытаться оценить параметры  и . Но они входят в зависимость нелинейно, поэтому сразу применить метод наименьших квадратов нельзя. Помогает логарифмирование:Следовательно, целесообразно сделать замену переменныха затем находить оценки параметров  и , минимизируя функцию	Найдем частные производные:Приравняем частные производные к 0, сократим на 2, раскроем скобки, перенесем свободные члены вправо. Получим систему двух линейных уравнений с двумя неизвестными:Таким образом, для вычисления оценок метода наименьших квадратов необходимо найти пять суммДля упорядочения расчета этих сумм может быть использована таблица типа той, что применялась выше. Отметим, что рассмотренная в предыдущем подразделе постановка переходит в разбираемую сейчас при 	Подходящая замена переменных во многих случаях позволяет перейти к линейной зависимости. Например, еслито замена z=1/y приводит к линейной зависимости z = a + bx. Если y=(a+bx)2, то замена  приводит к линейной зависимости z = a + bx. 	Основной показатель качества регрессионной модели. Одни и те же данные можно обрабатывать различными способами. На первый взгляд, показателем отклонений данных от модели может служить остаточная сумма квадратов SS. Чем этот показатель меньше, тем приближение лучше, значит, и модель лучше описывает реальные данные. Однако это рассуждение годится только для моделей с одинаковым числом параметров. Ведь если добавляется новый параметр, по которому можно минимизировать, то и минимум, как правило, оказывается меньше.	В качестве основного показателя качества регрессионной модели используют оценку остаточной дисперсии скорректированную на число m параметров, оцениваемых по наблюдаемым данным. В случае задачи восстановления линейной функции одной переменной, рассмотренной в предыдущем подразделе, оценка остаточной дисперсии имеет видпоскольку число оцениваемых параметров m=2. 	Почему эта формула отличается от приведенной в предыдущем подразделе? Там в знаменателе n, а здесь - (n-2). Дело в том, что там была рассмотрена непараметрическая теория при большом объеме данных (при . А при безграничном возрастании n разница между n и (n-2) сходит на нет. 	Однако при подборе вида модели знаменатель дроби, оценивающей остаточную дисперсию, приходится корректировать на число параметров. Если этого не делать, то придется заключить, что всегда многочлен второй степени лучше соответствует данным, чем линейная функция, многочлен третьей степени лучше приближает исходные данные, чем многочлен второй степени, и т.д. В конце концов доходим до многочлена степени (n-1) с n коэффициентами, который проходит через все заданные точки. Но его прогностические возможности, скорее всего, существенно меньше, чем у линейной функции. Излишнее усложнение статистических моделей вредно.	Типовое поведение скорректированной оценки остаточной дисперсиив зависимости от параметра m в случае расширяющейся системы моделей выглядит так. Сначала наблюдаем заметное убывание. Затем оценка остаточной дисперсии колеблется около некоторой константы (теоретического значения дисперсии погрешности).	Поясним ситуацию на примере модели восстановления зависимости, выраженной многочленом:Пусть эта модель справедлива при  При  в скорректированной оценке остаточной дисперсии учитываются не только погрешности измерений, но и соответствующие (старшие) члены многочлена (предполагаем, что коэффициенты при них отличны от 0). При  имеемСледовательно, скорректированная оценка остаточной дисперсии будет колебаться около указанного предела. Поэтому в качестве оценки неизвестной статистику степени многочлена (полинома) можно использовать первый локальный минимум скорректированной оценки остаточной дисперсии, т.е.	В работе [6] найдено предельное распределение этой оценки степени многочлена.	Теорема. При справедливости некоторых условий регулярностигде	Таким образом, предельное распределение оценки m* степени многочлена (полинома) является геометрическим. Это означает, в частности, что оценка не является состоятельной. При этом вероятность получить меньшее значение, чем истинное, исчезающе мала. Далее имеем:	Разработаны и иные методы оценивания неизвестной степени многочлена, например, путем многократного применения процедуры проверки адекватности регрессионной зависимости с помощью статистики Фишера (см. работу [7]). Предельное поведение оценок - таково же, как в приведенной выше теореме, только значение параметра  иное.	Пример практического использования линейного регрессионного анализа. Руководитель маркетинговой службы новгородского завода ГАРО А.А. Пивень применил его для построения математической модели рынка легковых подъемников. Требуется выявить факторы (показатели), оказывающие наибольшее влияние на объем продаж подъемников, найти зависимость объема продаж от этих факторов и использовать эту зависимость для прогнозирования объема продаж.	Зависимая переменная - объем продаж V, независимые переменные:грузоподъемность (X1), цена (X2)наличие напольной рамы (X3),наличие синхронизации (X4),количество двигателей (X5), суммарная мощность двигателей (X6),высота подхвата в нижнем положении (X7),  максимальная высота подъема (X8), скорость подъема (X9), гарантийный срок (X10),срок службы (X11), время на рынке (X12), внешний вид (X13),срок поставки (X14), уровень сервисного обслуживания (X15),наличие системы смазки (X16), масса (X17).	Для восстановления зависимости использовалась линейная регрессионная модель. По результатам пошагового анализа из рассмотрения последовательно исключались независимые переменные (параметры подъемника), имеющие (в линейной модели) коэффициенты, незначимо отличающиеся от нуля, иными словами, мало отличающиеся в сравнении с их дисперсией. Для этого использовался пакет STATISTICA 6.0, конкретно модуль "Множественная регрессия" (Multiple regression).	В результате расчетов получена зависимость объема продаж подъемника П3-Т от 12 факторов:V = - 1769.77 - 65.09 X1 - 0.03X2 + 68.79X3 + 147.54X4 + 156.28X5 + 2.53X7 + 1.06X8  + 25.75X12 - 132.26X13 - 12.41X14 + 107.78X15 + 397X16 .Влияние остальных пяти факторов оказалось незначимым.	Исходя из расчетов, прогнозное значение продаж подъемников на второй год продаж составит ориентировочно 1010 шт. С вероятностью 95% можно утверждать, что объем продаж будет лежать в границах [695, 1332] шт.	Оценивание условного математического ожидания. Рассмотрим общее понятие регрессии как условного математического ожидания. Пусть случайный вектор имеет плотность p(x,y). Как известно из любого курса теории вероятностей, плотность условного распределения  при условии  имеет видУсловное математическое ожидание, т.е. регрессионная зависимость y от x, имеет видТаким образом, для нахождения оценок регрессионной зависимости достаточно найти оценки совместной плотности распределения вероятности  такие, что при  Тогда непараметрическая оценка регрессионной зависимостипри  является состоятельной оценкой регрессии как условного математического ожиданияОбщий подход к построению непараметрических оценок плотности распределения вероятностей развит в главе 2.1 выше.	Регрессионному анализу (т.е. методам восстановления зависимостей) посвящена огромная литература. Он хорошо представлен в программных продуктах по анализу данных, особенно та его часть, которая связана с методом наименьших квадратов. Обзор современных методов и моделей дан в учебнике [6].3.2.4. Основы теории классификации  	При внедрении современных статистических методов в практику фундаментальных и прикладных научно-технических, социально-экономических, медицинских и иных исследований, при разработке соответствующих программных продуктов невозможно обойтись без классификации самих этих методов. Естественно исходить из вида обрабатываемых данных. В соответствии с современными воззрениями делим прикладную статистику на четыре области: - статистика случайных величин (одномерная статистика); многомерный статистический анализ; статистика временных рядов и случайных величин; статистика объектов нечисловой природы. В первой области элемент выборки - число, во второй - вектор, в третьей - функция, в четвертой - объект нечисловой природы. 	Как известно, математический аппарат статистики объектов нечисловой природы базируется на использовании расстояний (мер близости, показателей различия) в пространствах таких объектов. Это вызвано отсутствием в таких пространствах операций суммирования, на которых основано большинство методов других областей статистики. Любые методы, использующие только расстояния (меры близости, показатели различия) между объектами, следует относить к статистике объектов нечисловой природы, поскольку такие методы могут работать с объектами произвольного пространства, если в нем задана метрика или ее аналоги. Таким образом, весьма многие методы прикладной статистики следует включать в статистику объектов нечисловой природы. 	В настоящем пункте рассматривается важное направление   прикладной статистики - математические методы классификации. Значительную их часть следовало бы отнести к статистике объектов нечисловой природы, а именно, методы классификации, основанные на расстояниях между объектами. Однако исторически теория классификации рассматривается в основном в рамках многомерного статистического анализа, поскольку многие ее методы используют специфику конечномерного евклидова пространства. 	Основные направления в математической теории классификации. Какие научные исследования относить к этой теории? Исходя из потребностей специалиста, применяющего математические методы классификации, целесообразно принять, что сюда входят исследования, во-первых, отнесенные самими авторами к этой теории; во вторых, связанные с ней общностью тематики, хотя бы их авторы и не упоминали термин "классификация". Это предполагает ее сложную внутреннюю структуру.	В литературных источниках наряду с термином "классификация" в близких смыслах используются термины "группировка", "распознавание образов", "диагностика", "дискриминация", "сортировка" и др. Терминологический разнобой связан прежде всего с традициями научных кланов, к которым относятся авторы публикаций, а также с внутренним делением самой теории классификации.	В научных исследованиях по современной теории классификации можно выделить два относительно самостоятельных направления. Одно из них опирается на опыт таких наук, как биология, география, геология, и таких прикладных областей, как ведение классификаторов продукции и библиотечное дело. Типичные объекты рассмотрения - классификация химических элементов (таблица Д.И. Менделеева), биологическая систематика, универсальная десятичная классификация публикаций (УДК), классификатор товаров на основе штрих-кодов. 	Другое направление опирается на опыт технических исследований, экономики, маркетинговых исследований, социологии, медицины. Типичные задачи - техническая и медицинская диагностика, а также, например, разбиение на группы отраслей промышленности, тесно связанных между собой, выделение групп однородной продукции. Обычно используются такие термины, как "распознавание образов" или "дискриминантный анализ". Это направление обычно опирается на математические модели; для проведения расчетов интенсивно используется ЭВМ. Однако относить его к математике столь же нецелесообразно, как астрономию или квантовую механику. Рассматриваемые математические модели можно и нужно изучать на формальном уровне, и такие исследования проводятся. Но направление в целом сконцентрировано на решении конкретных задач прикладных областей и вносит вклад в технические или экономические науки, медицину, социологию, но, как правило, не в математику. Использование математических методов как инструмента исследования нельзя относить к чистой математике.	В 60-х годах XX века внутри прикладной статистики достаточно четко оформилась область, посвященная методам классификации. Несколько модифицируя формулировки М. Дж. Кендалла и А. Стьюарта 1966 г. (см. русский перевод [8, с.437]), в теории классификации выделим три подобласти: дискриминация (дискриминантный анализ), кластеризация (кластер-анализ), группировка. Опишем эти подобласти.	В дискриминантном анализе классы предполагаются заданными - плотностями вероятностей или обучающими выборками. Задача состоит в том, чтобы вновь поступающий объект отнести в один из этих классов. У понятия "дискриминация" имеется много синонимов: диагностика, распознавание образов с учителем, автоматическая классификация с учителем, статистическая классификация и т.д.	При кластеризации и группировке целью является выявление и выделение классов. Синонимы: построение классификации, распознавание образов без учителя, автоматическая классификация без учителя, типология, таксономия и др. Задача кластер-анализа состоит в выяснении по эмпирическим данным, насколько элементы "группируются" или распадаются на изолированные "скопления", "кластеры" (от cluster (англ.) - гроздь, скопление). Иными словами, задача - выявление естественного разбиения на классы, свободного от субъективизма исследователя, а цель - выделение групп однородных объектов, сходных между собой, при резком отличии этих групп друг от друга.	При группировке, наоборот, "мы хотим разбить элементы на группы независимо от того, естественны ли границы разбиения или нет" [8, с.437]. Цель по-прежнему состоит в выявлении групп однородных объектов, сходных между собой (как в кластер-анализе), однако "соседние" группы могут не иметь резких различий (в отличие от кластер-анализа). Границы между группами условны, не являются естественными, зависят от субъективизма исследователя. Аналогично при лесоустройстве проведение просек (границ участков) зависит от специалистов лесного ведомства, а не от свойств леса.	Задачи кластеризации и группировки принципиально различны, хотя для их решения могут применяться одни и те же алгоритмы. Важная для практической деятельности проблема состоит в том, чтобы понять, разрешима ли задача кластер-анализа для конкретных данных или возможна только их группировка, поскольку совокупность объектов достаточно однородна и не разбивается на резко разделяющиеся между собой кластеры.	Как правило, в математических задачах кластеризации и группировки основное - выбор метрики, расстояния между объектами, меры близости, сходства, различия. Хорошо известно, что для любого заданного разбиения объектов на группы и любого e > 0 можно указать метрику такую, что расстояния между объектами из одной группы будут меньше e, а между объектами из разных групп - больше 1/e. Тогда любой разумный алгоритм кластеризации даст именно заданное разбиение.  	Понимание и обсуждение постановок задач осложняется использованием одного и того же термина в разных смыслах. Термином "классификация" (и термином "диагностика") обозначают, по крайней мере, три разные вещи: процедуру построения классификации (и выделение классов, используемых при диагностике), построенную классификацию (систему выделенных классов) и процедуру ее использования (правила отнесения вновь поступающего объекта к одному из ранее выделенных классов). Другими словами, имеем естественную триаду: построение - изучение - использование классификации.	Как уже отмечалось, для построения системы диагностических классов используют разнообразные методы кластерного анализа и группировки объектов. Наименее известен второй член триады (отсутствующий у Кендалла и Стьюарта [8]) - изучение отношений эквивалентности, полученных в результате построения системы диагностических классов. Статистический анализ полученных, в частности экспертами, отношений эквивалентности - часть статистики бинарных отношений и тем самым - статистики объектов нечисловой природы (см. главу 3.4).  	Диагностика в узком смысле слова (процедура использования классификации, т.е. отнесения вновь поступающего объекта к одному из выделенных ранее классов) - предмет дискриминантного анализа. Отметим, что с точки зрения статистики объектов нечисловой природы дискриминантный анализ является частным случаем общей схемы регрессионного анализа, соответствующим ситуации, когда зависимая переменная принимает конечное число значений, а именно - номера классов, а вместо квадрата разности стоит функция потерь от неправильной классификации. Однако есть ряд специфических постановок, выделяющих задачи диагностики среди всех регрессионных задач.	О построении диагностических правил. Начнем с краткого обсуждения одного распространенного заблуждения. Иногда рекомендуют сначала построить систему диагностических классов, а потом в каждом диагностическом классе отдельно проводить регрессионный анализ (в классическом смысле) или применять иные методы многомерного статистического анализа. Однако обычно забывают, что при этом нельзя опираться на вероятностную модель многомерного нормального распределения, так как распределение результатов наблюдений, попавших в определенный кластер, будет отнюдь не нормальным, а усеченным нормальным (усечение определяется границами кластера).	Процедуры построения диагностических правил делятся на вероятностные и детерминированные. К первым относятся так называемые задачи расщепления смесей. В них предполагается, что распределение вновь поступающего случайного элемента является смесью вероятностных законов, соответствующих диагностическим классам. Как и при выборе степени полинома в регрессии (см. предыдущий подраздел), при анализе реальных социально-экономических данных встает вопрос об оценке числа элементов смеси, т.е. числа диагностических классов. Были изучены результаты применения обычно рекомендуемого критерия Уилкса для оценки числа элементов смеси. Оказалось (см. статью [9]), что оценка с помощью критерия Уилкса не является состоятельной, асимптотическое распределение этой оценки - геометрическое, как и в случае задачи восстановления зависимости в регрессионном анализе. Итак, продемонстрирована несостоятельность обычно используемых оценок. Для получения состоятельных оценок достаточно связать уровень значимости в критерии Уилкса с объемом выборки, как это было предложено и для задач регрессии [7].	Как уже отмечалось, задачи построения системы диагностических классов целесообразно разбить на два типа: с четко разделенными кластерами (задачи кластер-анализа) и с условными границами, непрерывно переходящими друг в друга классами (задачи группировки). Такое деление полезно, хотя в обоих случаях могут применяться одинаковые алгоритмы. Сколько же существует алгоритмов построения системы диагностических правил? Иногда называют то или иное число. На самом же деле их бесконечно много, в чем нетрудно убедиться.	Действительно, рассмотрим один определенный алгоритм - алгоритм средней связи. Он основан на использовании некоторой меры близости d(x,y) между объектами x и у. Как он работает? На первом шаге каждый объект рассматривается как отдельный кластер. На каждом следующем шаге объединяются две ближайших кластера. Расстояние между объектами рассчитывается как средняя связь (отсюда и название алгоритма), т.е. как среднее арифметическое расстояний между парами объектов, один из которых входит в первый кластер, а другой - во второй. В конце концов все объекты объединяются вместе, и результат работы алгоритма представляет собой дерево последовательных объединений (в терминах теории графов), или "Дендрограмму". Из нее можно выделить кластеры разными способами. Один подход - исходя из заданного числа кластеров. Другой - из соображений предметной области. Третий - исходя из устойчивости (если разбиение долго не менялось при возрастании порога объединения - значит, оно отражает реальность). И т.д. 	К алгоритму средней связи естественно сразу добавить алгоритм ближайшего соседа (когда расстоянием между кластерами называется минимальное из расстояний между парами объектов, один из которых входит в первый кластер, а другой - во второй). А также и алгоритм дальнего соседа (когда расстоянием между кластерами называется максимальное из расстояний между парами объектов, один из которых входит в первый кластер, а другой - во второй). 	Каждый из трех описанных алгоритмов (средней связи, ближайшего соседа, дальнего соседа), как легко проверить, порождает бесконечное (континуальное) семейство алгоритмов кластер-анализа. Дело в том, что величина da(x,y), a>0, также является мерой близости между x и у и порождает новый алгоритм. Если параметр а пробегает отрезок, то получается бесконечно много алгоритмов классификации.	Каким из них пользоваться при обработке данных? Дело осложняется тем, что практически в любом пространстве данных мер близости различных видов существует весьма много. Именно в связи с обсуждаемой проблемой следует указать на принципиальное различие между кластер-анализом и задачами группировки.	Если классы реальны, естественны, существуют на самом деле, четко отделены друг от друга, то любой алгоритм кластер-анализа их выделит. Следовательно, в качестве критерия естественности классификации следует рассматривать устойчивость относительно выбора алгоритма кластер-анализа.	Проверить устойчивость можно, применив к данным несколько подходов, например, столь непохожие алгоритмы, как "ближнего соседа" и "дальнего соседа". Если полученные результаты содержательно близки, то они адекватны действительности. В противном случае следует предположить, что естественной классификации не существует, задача кластер-анализа не имеет решения, и можно проводить только группировку.	Как уже отмечалось, часто применяется т.н. агломеративный иерархический алгоритм "Дендрограмма", в котором вначале все элементы рассматриваются как отдельные кластеры, а затем на каждом шагу объединяются два наиболее близких кластера. Для работы "Дендрограммы" необходимо задать правило вычисления расстояния между кластерами. Оно вычисляется через расстояние d(x,у) между элементами х и у. Поскольку da(x,y) при 0<a<1 также расстояние, то, как правило, существует бесконечно много различных вариантов этого алгоритма. Представим себе, что они применяются для обработки одних и тех же реальных данных. Если при всех а получается одинаковое разбиение элементов на кластеры, т.е. результат работы алгоритма устойчив по отношению к изменению а (в смысле общей схемы устойчивости, рассмотренной в главе 1.4), то имеем "естественную" классификацию. В противном случае результат зависит от субъективно выбранного исследователем параметра а, т.е. задача кластер-анализа неразрешима (предполагаем, что выбор а нельзя специально обосновать). Задача группировки в этой ситуации имеет много решений. Из них можно выбрать одно по дополнительным критериям.	Следовательно, получаем эвристический критерий: если решение задачи кластер-анализа существует, то оно находится с помощью любого алгоритма. Целесообразно использовать наиболее простой.  	Проблема поиска естественной классификации. Существуют различные точки зрения на эту проблему. Естественная классификация обычно противопоставляется искусственной. На Всесоюзной школе-семинаре "Использование математических методов в задачах классификации" (г. Пущино, 1986 г.), в частности, были высказаны мнения, что естественная классификация:	- закон природы;	- основана на глубоких закономерностях, тогда как искусственная классификация - на неглубоких;	- для конкретного индивида та, которая наиболее быстро вытекает из его тезауруса;	 - удовлетворяет многим целям; цель искусственной классификации задает человек;	- классификация с точки зрения потребителя продукции;	- классификация, позволяющая делать прогнозы;	- имеет критерием устойчивость.Приведенные высказывания уже дают представление о больших расхождениях в понимании "естественной классификации". Этот термин следует признать нечетким, как, впрочем, и многие другие термины, и профессиональные - социально-экономические, научно-технические, и используемые в обыденном языке. Нетрудно подробно обоснована нечеткость естественного языка и тот факт, что "мы мыслим нечетко", что, однако, не слишком мешает нам решать производственные и жизненные проблемы. Кажущееся рациональным требование выработать сначала строгие определения, а потом развивать науку - невыполнимо. Следовать ему - значит отвлекать силы от реальных задач. При системном подходе к теории классификации становится ясно, что строгие определения можно надеяться получить на последних этапах построения теории. Мы же сейчас находимся чаще всего на первых этапах. Поэтому, не давая определения понятиям "естественная классификация" и "естественная диагностика", обсудим, как проверить на "естественность" классификацию (набор диагностических классов), полученную расчетным путем.	Можно выделить два критерия "естественности", по поводу которых имеется относительное согласие:	А. Естественная классификация должна быть реальной, соответствующей действительному миру, лишенной внесенного исследователем субъективизма;	Б. Естественная классификация должна быть важной или с научной точки зрения (давать возможность прогноза, предсказания новых свойств, сжатия информации и т.д.), или с практической.	Пусть классификация проводится на основе информации об объектах, представленной в виде матрицы "объект-признак" или матрицы попарных расстояний (мер близости). Пусть алгоритм классификации дал разбиение на кластеры. Как можно получить доводы в пользу естественности этой классификации? Например, уверенность в том, что она - закон природы, может появиться только в результате ее длительного изучения и практического применения. Это соображение относится и к другим из перечисленных выше критериев, в частности к Б (важности). Сосредоточимся на критерии А (реальности).	Понятие "реальности" кластера требует специального обсуждения. (оно начато в работе [9]). Рассмотрим существо различий между понятиями "классификация" и "группировка". Пусть, к примеру, необходимо деревья, растущие в определенной местности, разбить на группы находящихся рядом друг с другом. Ясна интуитивная разница между несколькими отдельными рощами, далеко отстоящими друг от друга и разделенными полями, и сплошным лесом, разбитым просеками на квадраты с целью лесоустройства. 	Однако формально определить эту разницу столь же сложно, как определить понятие "куча зерен", чем занимались еще в Древней Греции. Ясно, что одно зерно не составляет кучи, два зерна не составляют кучи,. Если к тому, что не составляет кучи, добавить еще одно зерно, то куча не получится. Значит - по принципу математической индукции - никакое количество зерен не составляет кучи. Но ясно, что миллиард зерен - большая куча зерен - подсчитайте объем!.	Переформулируем сказанное в терминах "кластер-анализа" и "методов группировки". Выделенные с помощью первого подхода кластеры реальны, а потому могут рассматриваться как кандидаты в "естественные". Группировка дает "искусственные" классы, которые не могут быть "естественными".	Выборку из унимодального распределения можно, видимо, рассматривать как "естественный", "реальный" кластер. Применим к ней какой-либо алгоритм классификации ("средней связи", "ближайшего соседа" и т.п.). Он даст какое-то разбиение на классы, которые, разумеется, не являются "реальными", поскольку отражают прежде всего свойства алгоритма, а не исходных данных. Как отличить такую ситуацию от противоположной, когда имеются реальные кластеры и алгоритм классификации более или менее точно их выделяет? Как известно, "критерий истины - практика", но слишком много времени необходимо для применения подобного критерия. Поэтому представляет интерес критерий, оценивающий "реальность" выделяемых с помощью алгоритма классификации кластеров одновременно с его применением.	Такой показатель существует - это критерий устойчивости. Устойчивость - понятие широкое. Общая схема формулирования и изучения проблем устойчивости рассмотрена в главе 1.4. В частности, поскольку значения признаков всегда измеряются с погрешностями, то "реальное" разбиение должно быть устойчиво (т.е. не меняться или меняться слабо) при малых отклонениях исходных данных. Алгоритмов классификации существует бесконечно много, и "реальное" разбиение должно быть устойчиво по отношению к переходу к другому алгоритму. Другими словами, если "реальное" разбиение на классы возможно, то оно находится с помощью любого алгоритма автоматической классификация. Следовательно, критерием естественности классификации может служить совпадение результатов работы двух достаточно различающихся алгоритмов, например "ближайшего соседа" и "дальнего соседа".	Выше рассмотрены два типа "глобальных" критериев "естественности классификации", касающихся разбиения в целом. "Локальные" критерии относятся к отдельным кластерам. Простейшая постановка такова: достаточно ли однородны два кластера (две совокупности) для их объединения:? Если объединение возможно, то кластеры не являются "естественными". Преимущество этой постановки в том, что она допускает применение статистических критериев однородности двух выборок. В одномерном случае (классификация по одному признаку) разработано большое число подобных критериев - Крамера-Уэлча, Смирнова, омега-квадрат (Лемана - Розенблатта), Вилкоксона, Ван-дер-Вардена, Лорда, Стьюдента и др. (см. главу 3.1 и справочник [4]). Имеются критерии и для многомерных данных. Для одного из видов объектов нечисловой природы - люсианов - статистические методы выделения "реальных" кластеров развиты в работе [10].	Что касается глобальных критериев, то для изучения устойчивости по отношению к малым отклонениям исходных данных естественно использовать метод статистических испытаний и проводить расчеты по "возмущенным" данным. Некоторые теоретические утверждения, касающиеся влияния "возмущений" на кластеры различных типов, получены в работе [9].	Опишем практический опыт реализации анализа устойчивости. Несколько алгоритмов классификации были применены к данным, полученным при проведении маркетинга образовательных услуг и приведенным в работе [11]. Для анализа данных были использованы широко известные алгоритмы "ближайшего соседа", "дальнего соседа" и алгоритм кластер-анализа из работы [12]. С содержательной точки зрения полученные разбиения отличались мало. Поэтому есть основания считать, что с помощью этих алгоритмов действительно выявлена "реальная" структура данных.	Идея устойчивости как критерия "реальности" иногда реализуется неадекватно. Так, для однопараметрических алгоритмов иногда предлагают выделять разбиения, которым соответствуют наибольшие интервалы устойчивости по параметру, т.е. наибольшие приращения параметра между очередными объединениями кластеров. Для данных работы [11] это предложение не дало полезных результатов - были получены различные разбиения: три алгоритма - три разбиения. И с теоретической точки зрения предложение этого специалиста несостоятельно. Покажем это.	Действительно, рассмотрим алгоритм "ближайшего соседа", использующий меру близости d(x,у), и однопараметрическое семейство алгоритмов с мерой близости da(x,y), а>0, также являющихся алгоритмами "ближайшего соседа". Тогда дендрограммы, полученные с помощью этих алгоритмов, совпадают при всех a, поскольку при их реализации происходит лишь сравнение мер близости между объектами. Другими словами, дендрограмма, полученная с помощью алгоритма "ближайшего соседа", является адекватной в порядковой шкале (измерения меры близости d(x,у)), т.е. сохраняется при любом строго возрастающем преобразовании этой меры. Однако выделенные по обсуждаемому методу "устойчивые разбиения" меняются. В частности, при достаточно большом а "наиболее объективным" в соответствии с рассматриваемым предложением будет, как нетрудно показать, разбиение на два кластера! Таким образом, разбиение, выдвинутое им как "устойчивое", на самом деле оказывается весьма неустойчивым.3.2.5. Статистические методы классификации	Рассмотрим с позиций прикладной статистики несколько конкретных вопросов теории классификации.	Вероятностная теория кластер-анализа. Как и для прочих статистических методов, свойства алгоритмов кластер-анализа необходимо изучать на вероятностных моделях. Это касается, например, условий естественного объединения двух кластеров.  	Вероятностные постановки нужно применять, в частности, при перенесении результатов, полученных по выборке, на генеральную совокупность. Вероятностная теория кластер-анализа и методов группировки различна для исходных данных типа таблиц "объект ? признак" и матриц сходства. Для первых параметрическая вероятностно-статистическая теория называется "расщеплением смесей". Непараметрическая теория основана на непараметрических оценках плотностей вероятностей и их мод. Основные результаты, связанные с непараметрическими оценками плотности, обсуждались в главе 2.1.	Если исходные данные - матрица сходства ||d(x,y)||, то необходимо признать, что развитой вероятностно-статистической теории пока нет. Подходы к ее построению намечены в работе [9]. Одна из основных проблем - проверка "реальности" кластера, его объективного существования независимо от расчетов исследователя. Проблема "реальности" кластера давно обсуждается специалистами различных областей. Типичное рассуждение таково. Предположим, что результаты наблюдений можно рассматривать как выборку из некоторого распределения с монотонно убывающей плотностью при увеличении расстояния от некоторого центра. Примененный к подобным данным какой-либо алгоритм кластер-анализа порождает некоторое разбиение. Ясно, что оно - чисто формальное, поскольку выделенным таксонам (кластерам) не соответствуют никакие "реальные" классы. Другими словами, задача кластер-анализа не имеет решения, а алгоритм дает лишь группировку. При обработке реальных данных мы не знаем вида плотности. Проблема состоит в том, чтобы определить, каков результат работы алгоритма (реальные кластеры или формальные группы).	Частный случай этой проблемы - проверка обоснованности объединения двух кластеров, которые мы рассматриваем как два множества объектов, а именно, множества {a1, a2,., ak} и {b1, b2,., bm}. Пусть, например, используется алгоритм типа "Дендрограмма". Естественной представляется следующая идея. Пусть есть две совокупности мер близости. Одна - меры близости между объектами, лежащими внутри одного кластера, т.е.  d(ai,aj), 1<i<j<k, d(ba,bb), 1<a<b<m.  Другая совокупность - меры близости между объектами, лежащими в разных кластерах, т.е. d(ai,ba), 1<i<k, 1<a<m. Эти две совокупности мер близости предлагается рассматривать как независимые выборки и проверять гипотезу о совпадении их функций распределения. Если гипотеза не отвергается, объединение кластеров считается обоснованным; в противном случае - объединять нельзя, алгоритм прекращает работу.  	В рассматриваемом подходе есть две некорректности (см. также работу [9, разд.4]). Во-первых, меры близости не являются независимыми случайными величинами. Во-вторых, не учитывается, что объединяются не заранее фиксированные кластеры (с детерминированным составом), а полученные в результате работы некоторого алгоритма, и их состав (в частности, количество элементов) оказывается случайным. От первой из этих некорректностей можно частично избавиться. Справедливо следующее утверждение.	Теорема 1. Пусть a1, a2,., ak, b1, b2,., bm - независимые одинаково распределенные случайные величины (со значениями в произвольном пространстве). Пусть случайная величина d(а1,а2) имеет все моменты. Тогда при k,тr?  распределение статистики (где U - сумма рангов элементов первой выборки в объединенной выборке; первая выборка составлена из внутрикластерных расстояний (мер близости) d(ai,aj), 1<i<j<k, и  d(ba,bb), 1<a<b<m, а вторая - из межкластерных расстояний d(ai,ba), 1<i<k, 1<a<m) сходится к стандартному нормальному распределению с математическим ожиданием 0 и дисперсией 1.	На основе теоремы 1 очевидным образом формулируется правило проверки обоснованности объединения двух кластеров. Другими словами, мы проверяем статистическую гипотезу, согласно которой объединение двух кластеров образует однородную совокупность. Если величина U слишком мала, статистическая гипотеза однородности отклоняется (на заданном уровне значимости), и возможность объединения отбрасывается. Таким образом, хотя расстояния между объектами в кластерах зависимы, но эта зависимость слаба, и доказана математическая теорема о допустимости применения критерия Вилкоксона для проверки возможности объединения кластеров. 	О вычислительной сходимости алгоритмов кластер-анализа. Алгоритмы кластер-анализа и группировки зачастую являются итерационными. Например, формулируется правило улучшения решения задачи кластер-анализа шаг за шагом, но момент остановки вычислений не обсуждается. Примером является известный алгоритм "Форель", в котором постепенно улучшается положение центра кластера. В этом алгоритме на каждом шаге строится шар определенного заранее радиуса, выделяются элементы кластеризуемой совокупности, попадающие в этот шар, и новый центр кластера строится как центр тяжести выделенных элементов. При анализе алгоритма "Форель" возникает проблема: завершится ли процесс улучшения положения центра кластера через конечное число шагов или же он может быть бесконечным. Она получила название "проблема остановки". Для широкого класса так называемых "эталонных алгоритмов" проблема остановки была решена в работе [9]: процесс улучшения остановится через конечное число шагов. 	Отметим, что алгоритмы кластер-анализа могут быть модифицированы разнообразными способами. Например, описывая алгоритм "Форель" в стиле статистики объектов нечисловой природы, заметим, что вычисление центра тяжести для совокупности многомерных точек - это нахождение эмпирического среднего для меры близости, равной квадрату евклидова расстояния. Если взять более естественную меру близости - само евклидово расстояние, то получим алгоритм кластер-анализа "Медиана", отличающийся от "Форели" тем, что новый центр строится не с помощью средних арифметических координат элементов, попавших в кластер, а с помощью медиан. 	Проблема остановки возникает не только при построении диагностических классов. Она принципиально важна, в частности, и при оценивании параметров вероятностных распределений методом максимального правдоподобия. Обычно не представляет большого труда выписать систему уравнений максимального правдоподобия и предложить решать ее каким-либо численным методом. Однако когда остановиться, сколько итераций сделать, какая точность оценивания будет при этом достигнута? Общий ответ, видимо, невозможно найти, но обычно нет ответа и для конкретных семейств распределения вероятностей. Именно поэтому  нет оснований рекомендовать решать системы уравнений максимального правдоподобия. Вместо них целесообразно использовать т.н. одношаговые оценки (подробнее см. об этих оценках главу 2.2). Эти оценки задаются конечными формулами, но асимптотически столь же хороши (на профессиональном языке - эффективны), как и оценки максимального правдоподобия.	О сравнении алгоритмов диагностики по результатам обработки реальных данных. Перейдем к этапу применения диагностических правил, когда классы, к одному из которых нужно отнести вновь поступающий объект, уже выделены.	В прикладных исследованиях применяют различные методы дискриминантного анализа, основанные на вероятностно-статистических моделях, а также с ними не связанные, т.е. эвристические, использующие детерминированные методы анализа данных. Независимо от "происхождения", каждый подобный алгоритм должен быть исследован как на параметрических и непараметрических вероятностно-статистических моделях порождения данных, так и на различных массивах реальных данных. Цель исследования - выбор наилучшего алгоритма в определенной области применения, включение его в стандартные программные продукты, методические материалы, учебные программы и пособия. Но для этого надо уметь сравнивать алгоритмы по качеству. Как это делать?	Часто используют такой показатель качества алгоритма диагностики, как "вероятность правильной классификации" (при обработке конкретных данных - "частота правильной классификации"). Чуть ниже мы покажем, что этот показатель качества некорректен, а потому пользоваться им не рекомендуется. Целесообразно применять другой показатель качества алгоритма диагностики - оценку специального вида т.н. "расстояния Махаланобиса" между классами. Изложение проведем на примере разработки программного продукта для специалистов по диагностике материалов. Прообразом является диалоговая система "АРМ материаловеда", разработанная Институтом высоких статистических технологий и эконометрики для ВНИИ эластомерных материалов.	При построении информационно-исследовательской системы диагностики материалов (ИИСДМ) возникает задача сравнения прогностических правил "по силе". Прогностическое правило - это алгоритм, позволяющий по характеристикам материала прогнозировать его свойства. Если прогноз дихотомичен ("есть" или "нет"), то правило является алгоритмом диагностики, при котором материал относится к одному из двух классов. Ясно, что случай нескольких классов может быть сведен к конечной последовательности  выбора между двумя классами.	Прогностические правила могут быть извлечены из научно-технической  литературы и практики. Каждое из них обычно формулируется в терминах небольшого числа признаков, но наборы признаков сильно меняются от правила к правилу. Поскольку в ИИСДМ должно фиксироваться лишь ограниченное число признаков, то возникает проблема их отбора. Естественно отбирать лишь те их них, которые входят в наборы, дающие наиболее "надежные" прогнозы. Для придания точного смысла термину "надежный" необходимо иметь способ сравнения алгоритмов диагностики по прогностической "силе".	Результаты обработки реальных данных с помощью некоторого алгоритма диагностики в рассматриваемом случае двух классов описываются долями: правильной диагностики в первом классе ; правильной диагностики во втором классе ; долями классов в объединенной совокупности 	При изучении качества алгоритмов классификации их сравнивают по результатам дискриминации вновь поступающей контрольной выборки. Именно по контрольной выборке определяются величины . Однако иногда вместо контрольной используют обучающую выборку, т.е. указанные величины определяются ретроспективно, в результате анализа уже имеющихся данных. Обычно это связано с трудоемкостью получения данных. Тогда ? и ? зависимы. Однако в случае, когда решающее правило основано на использовании дискриминантной поверхности, параметры которой оцениваются по обучающим выборкам, величины ? и ? асимптотически (при безграничном росте объемов выборок) независимы [9], что позволяет использовать приводимые ниже результаты и в этом случае. 	Нередко как показатель качества алгоритма диагностики (прогностической "силы") используют долю правильной диагностики	Однако показатель  определяется, в частности, через характеристики  и ,  частично заданные исследователем (например, на них влияет тактика отбора образцов для изучения). В аналогичной медицинской задаче величина  оказалась больше для тривиального прогноза, согласно которому у всех больных течение заболевания будет благоприятно. Тривиальный прогноз сравнивался с алгоритмом выделения больных с прогнозируемым тяжелым течением заболевания. Он был разработан группы под руководством академика АН СССР И.М. Гельфанда. Применение этого алгоритма с медицинской точки зрения вполне оправдано [13].	Другими словами, по доле правильной классификации алгоритм академика И.М. Гельфанда оказался хуже тривиального - объявить всех больных легкими, не требующими специального наблюдения. Этот вывод очевидно нелеп. И причина появления нелепости вполне понятна. Хотя доля тяжелых больных невелика, но смертельные исходы сосредоточены именно в этой группе больных. Поэтому целесообразна гипердиагностика - рациональнее часть легких больных объявить тяжелыми, чем сделать ошибку в противоположную сторону. Применение теории статистических решений в рассматриваемой постановке вряд ли возможно, поскольку оценить количественно потери от смерти больного нельзя по этическим соображениям. Поэтому, на наш взгляд, долю правильной диагностики  нецелесообразно использовать как показатель качества алгоритма диагностики.	Применение теории статистических решений требует знания потерь от ошибочной диагностики, а в большинстве научно-технических и экономических задач определить потери, как уже отмечалось, сложно. В частности, из-за необходимости оценивать человеческую жизнь в денежных единицах. По этическим соображениям это, на наш взгляд, недопустимо. Сказанное не означает отрицания пользы страхования, но, очевидно, страховые выплаты следует рассматривать лишь как способ первоначального смягчения потерь от утраты близких.	Для выявления информативного набора признаков целесообразно использовать метод пересчета на модель линейного дискриминантного анализа, согласно которому статистической оценкой прогностической "силы" являетсягде  - функция стандартного нормального распределения вероятностей с математическим ожиданием 0 и дисперсией 1, а  - обратная ей функция.	Пример 1. Если доли правильной классификации ? = 0,90 и ? = 0,80, то ?-1(?) = 1,28 и ?-1(?) = 0,84, откуда d* = 2,12 и прогностическая сила ?* = ?-1(1,06) = 0,86. При этом доля правильной классификации ? может принимать любые значения между 0,80 и 0,90, в зависимости от доли элементов того или иного класса среди анализируемых данных. 	Если классы описываются выборками из многомерных нормальных совокупностей с одинаковыми матрицами ковариаций, а для классификации применяется классический линейный дискриминантный анализ Р.Фишера, то величина  представляет собой состоятельную статистическую оценку так называемого расстояния Махаланобиса между рассматриваемыми двумя совокупностями (конкретный вид этого расстояния сейчас не имеет значения), независимо от порогового значения, определяющего конкретное решающее правило. В общем случае показатель  вводится как эвристический.	Пусть алгоритм классификации применялся к совокупности, состоящей из т объектов первого класса и n объектов второго класса.	Теорема 2. Пусть т, пr?. Тогда для всех х,где  - истинная "прогностическая сила" алгоритма диагностики;  - ее эмпирическая оценка,;) - плотность стандартного нормального распределения вероятностей с математическим ожиданием 0 и дисперсией 1.	С помощью теоремы 2 по  и  обычным образом определяют доверительные границы для "прогностической силы" .	Пример 2. В условиях примера 1 при m = n = 100 найдем асимптотическое среднее квадратическое отклонение А(0,90; 0,80). 	Поскольку ?(?-1(?)) = ?(1,28) = 0,176, ?(?-1(?)) = ?(0,84) = 0,280, ?(d*/2) = ?(1,06) = 0,227, то подставляя в выражение для А2 численные значения, получаем, что(численные значения плотности стандартного нормального распределения с математическим ожиданием 0 и дисперсией 1 и функции, обратной к функции этого распределения, можно было взять, например, из справочника [4]).	При m = n = 100 имеем А(0,90; 0,80) = 0,0252. При доверительной вероятности ? = 0,95 имеем u(0,95) = ?-1(1,0,975) = 1,96, а потому нижняя доверительная граница для прогностической силы ? есть ?Н = 0,86 - 1,96 ? 0,0252 = 0,81, а верхняя доверительная граница такова: ?В = 0,86 + 1,96 ? 0,0252 = 0,91. Аналогичный расчет при m = n = 1000 дает ?Н = 0,845, ?В = 0,875.	Как проверить обоснованность пересчета на модель линейного дискриминантного анализа? Допустим, что классификация состоит в вычислении некоторого прогностического индекса у и сравнении его с заданным порогом с. Объект относят к первому классу, если у<с, ко второму, если у>с. Прогностический индекс - это обычно линейная функция от характеристик рассматриваемых объектов. Другими словами, от координат векторов, описывающих объекты.	Возьмем два значения порога с1 и c2. Если пересчет на модель линейного дискриминантного анализа обоснован, то , как можно показать, "прогностические силы" для обоих правил совпадают: . Выполнение этого равенства можно проверить как статистическую гипотезу.	Пусть  - доля объектов первого класса, для которых y<c1, а  - доля объектов первого класса, для которых c1<y<c2. Аналогично пусть  - доля объектов второго класса, для которых c1<y<c2, а  - доля объектов второго класса, для которых у>с2. Тогда можно рассчитать две оценки одного и того же расстояния Махаланобиса. Они имеют вид:	Теорема 3. Если истинные прогностические силы двух правил диагностики совпадают, то при  при всех х,где;.	Из теоремы 3 вытекает метод проверки рассматриваемой гипотезы: при выполнении неравенстваона принимается на уровне значимости, асимптотически равном , в противном случае - отвергается.	Пример 3. Пусть данные примеров 1 и 2 соответствуют порогу с1. Пусть порогу с2 соответствуют ?' = 0,95 и ?' = 0,70. Тогда в обозначениях теоремы 3 ?1 = 0,90, ?2 = 0,05, ?2 = 0,10, ?3 = 0,70. Далее d*(c1) = 2,12 (пример 1), d*(c2) = 2,17, T(?1, ?2) = 2,22, T(?3, ?2) = 0,89. Гипотеза о совпадении прогностических сил на двух порогах принимается на уровне значимости ? = 0,05 тогда и только тогда, когда ,т.е. когда.Так, гипотеза принимается при m = n = 1000 и отвергается при m = n = 5000. 	Подходы к построению прогностических правил. Для решения задач диагностики используют два подхода - параметрический и непараметрический. Первый из них обычно основан на использовании того или иного индекса и сравнения его с порогом. Индекс может быть построен по статистическим данным, например, как в уже упомянутом линейном дискриминантном анализе Фишера. Часто индекс представляет собой линейную функцию от характеристик, выбранных специалистами предметной области, коэффициенты которой подбирают эмпирически. Непараметрический подход связан с леммой Неймана-Пирсона в математической статистике и с теорией статистических решений. Он опирается на использование непараметрических оценок плотностей распределений вероятностей, описывающих диагностические классы. 	Обсудим ситуацию подробнее. Математические методы диагностики, как и статистические методы в целом, делятся на параметрические и непараметрические. Первые основаны на предположении, что классы описываются распределениями из некоторых параметрических семейств. Обычно рассматривают многомерные нормальные распределения, при этом зачастую принимают гипотезу о том, что ковариационные матрицы для различных классов совпадают. Именно в таких предположениях сформулирован классический дискриминантный анализ Фишера. Как известно, обычно нет оснований считать, что наблюдения извлечены из нормального распределения. 	Поэтому более корректными, чем параметрические, являются непараметрические методы диагностики. Исходная идея таких методов основана на лемме Неймана-Пирсона, входящей в стандартный курс математической статистики. Согласно этой лемме решение об отнесении вновь поступающего объекта (сигнала, наблюдения и др.) к одному из двух классов принимается на основе отношения плотностей f(x)/g(x), где f(x) - плотность распределения, соответствующая первому классу, а  g(x) - плотность распределения, соответствующая второму классу. Если плотности распределения неизвестны, то применяют их непараметрические оценки, построенные по обучающим выборкам. Пусть обучающая выборка объектов из первого класса состоит из n элементов, а обучающая выборка для второго класса - из  m объектов. Тогда рассчитывают значения непараметрических оценок плотностей fn(x) и gm(x) для первого и второго классов соответственно, а диагностическое решение принимают по их отношению. Таким образом, для решения задачи диагностики достаточно научиться строить непараметрические оценки плотности для выборок объектов произвольной природы.	Методы построения непараметрических оценок плотности распределения вероятностей в пространствах произвольной природы рассмотрены в главе 2.1.  3.2.6. Методы снижения размерности	В многомерном статистическом анализе каждый объект описывается вектором, размерность которого произвольна (но одна и та же для всех объектов). Однако человек может непосредственно воспринимать лишь числовые данные или точки на плоскости. Анализировать скопления точек в трехмерном пространстве уже гораздо труднее. Непосредственное восприятие данных более высокой размерности невозможно. Поэтому вполне естественным является желание перейти от многомерной выборки к данным небольшой размерности, чтобы "на них можно было посмотреть".	Кроме стремления к наглядности, есть и другие мотивы для снижения размерности. Те факторы, от которых интересующая исследователя переменная не зависит, лишь мешают статистическому анализу. Во-первых, на сбор информации о них расходуются ресурсы. Во-вторых, как можно доказать, их включение в анализ ухудшает свойства статистических процедур (в частности, увеличивает дисперсию оценок параметров и характеристик распределений). Поэтому желательно избавиться от таких факторов.	Обсудим с точки зрения снижения размерности пример использования регрессионного анализа для прогнозирования объема продаж, рассмотренный в подразделе 3.2.3. Во-первых, в этом примере удалось сократить число независимых переменных с 17 до 12. Во-вторых, удалось сконструировать новый фактор - линейную функцию от 12 упомянутых факторов, которая лучше всех иных линейных комбинаций факторов прогнозирует объем продаж. Поэтому можно сказать, что в результате размерность задачи уменьшилась с 18 до 2. А именно, остался один независимый фактор (приведенная в подразделе 3.2.3 линейная комбинация) и один зависимый - объем продаж. 	При анализе многомерных данных обычно рассматривают не одну, а множество задач, в частности, по-разному выбирая независимые и зависимые переменные. Поэтому рассмотрим задачу снижения размерности в следующей формулировке. Дана многомерная выборка. Требуется перейти от нее к совокупности векторов меньшей размерности, максимально сохранив структуру исходных данных, по возможности не теряя информации, содержащихся в данных. Задача конкретизируется в рамках каждого конкретного метода снижения размерности. 	Метод главных компонент является одним из наиболее часто используемых методов снижения размерности. Основная его идея состоит в последовательном выявлении направлений, в которых данные имеют наибольший разброс. Пусть выборка состоит из векторов, одинаково распределенных с вектором X = (x(1), x(2), . , x(n)). Рассмотрим линейные комбинации Y(?(1), ?(2), ., ?(n)) = ?(1)x(1) + ?(2)x(2) + . + ?(n)x(n),где?2(1) + ?2(2) + .+ ?2(n) = 1.Здесь вектор ? = (?(1), ?(2), ., ?(n)) лежит на единичной сфере в n-мерном пространстве. 	В методе главных компонент прежде всего находят направление максимального разброса, т.е. такое ?, при котором достигает максимума дисперсия случайной величины Y(?) = Y(?(1), ?(2), ., ?(n)). Тогда вектор ? задает первую главную компоненту, а величина Y(?) является проекцией случайного вектора Х на ось первой главной компоненты.	Затем, выражаясь терминами линейной алгебры,  рассматривают гиперплоскость в n-мерном пространстве, перпендикулярную первой главной компоненте, и проектируют на эту гиперплоскость все элементы выборки. Размерность гиперплоскость на 1 меньше, чем размерность исходного пространства. 	В рассматриваемой гиперплоскости процедура повторяется. В ней находят направление наибольшего разброса, т.е. вторую главную компоненту. Затем выделяют гиперплоскость, перпендикулярную первым двум главным компонентам. Ее размерность на 2 меньше, чем размерность исходного пространства. Далее - следующая итерация.	С точки зрения линейной алгебры речь идет о построении нового базиса в n-мерном пространстве, ортами которого служат главные компоненты.	 Дисперсия, соответствующая каждой новой главной компоненте, меньше, чем для предыдущей. Обычно останавливаются, когда она меньше заданного порога. Если отобрано k главных компонент, то это означает, что от n-мерного пространства удалось перейти к k-мерному, т.е. сократить размерность с n-до k, практически не исказив структуру исходных данных.  	Для визуального анализа данных часто используют проекции исходных векторов на плоскость первых двух главных компонент. Обычно хорошо видна структура данных, выделяются компактные кластеры объектов и отдельно выделяющиеся вектора. 	Метод главных компонент является одним из методов факторного анализа [14]. Различные алгоритмы факторного анализа объединены тем, что во всех них происходит переход к новому базису в исходном n-мерном пространстве. Важным является понятие "нагрузка фактора", применяемое для описания роли исходного фактора (переменной) в формировании определенного вектора из нового базиса. 	Новая идея по сравнению с методом главных компонент состоит в том, что на основе нагрузок происходит разбиение факторов на группы. В одну группу объединяются факторы, имеющие сходное влияние на элементы нового базиса. Затем из каждой группы рекомендуется оставить одного представителя. Иногда вместо выбора представителя расчетным путем формируется новый фактор, являющийся центральным для рассматриваемой группы. Снижение размерности происходит при переходе к системе факторов, являющихся представителями групп. Остальные факторы отбрасываются. 	Описанная процедура может быть осуществлена не только с помощью факторного анализа. Речь идет о кластер-анализе признаков (факторов, переменных). Для разбиения признаков на группы можно применять различные алгоритмы кластер-анализа. Достаточно ввести расстояние (меру близости, показатель различия) между признаками. Пусть Х и У - два признака. Различие d(X,Y) между ними можно измерять с помощью выборочных коэффициентов корреляции:d1(X,Y) = 1 - rn(X,Y),   d2(X,Y) = 1 - ?n(X,Y),где rn(X,Y) - выборочный линейный коэффициент корреляции Пирсона, ?n(X,Y) - выборочный коэффициент ранговой корреляции Спирмена. 	Многомерное шкалирование. На использовании расстояний (мер близости, показателей различия) d(X,Y) между признаками Х и У основан обширный класс методов многомерного шкалирования [15, 16]. Основная идея этого класса методов состоит в представлении каждого объекта точкой геометрического пространства (обычно размерности 1, 2 или 3), координатами которой служат значения скрытых (латентных) факторов, в совокупности достаточно адекватно описывающих объект. При этом отношения между объектами заменяются отношениями между точками - их представителями. Так, данные о сходстве объектов - расстояниями между точками, данные о превосходстве - взаимным расположением точек [17]. 	В практике используется ряд различных моделей многомерного шкалирования. Во всех них встает проблема оценки истинной размерности факторного пространства. Рассмотрим эту проблему на примере обработки данных о сходстве объектов с помощью метрического шкалирования. 	Пусть имеется n объектов О(1), О(2), ., O(n), для каждой пары объектов О(i), O(j) задана мера их сходства s(i,j). Считаем, что всегда s(i,j) = s(j,i). Происхождение чисел s(i,j) не имеет значения для описания работы алгоритма. Они могли быть получены либо непосредственным измерением, либо с использованием экспертов, либо путем вычисления по совокупности описательных характеристик, либо как-то иначе. 	В евклидовом пространстве рассматриваемые n объектов должны быть представлены конфигурацией n точек, причем в качестве меры близости точек-представителей выступает евклидово расстояние d(i,j) между соответствующими точками. Степень соответствия между совокупностью объектов и совокупностью представляющих их точек определяется путем сопоставления матриц сходства ||s(i,j)|| и расстояний ||d(i,j)||. Метрический функционал сходства имеет вид.Геометрическую конфигурацию надо выбирать так, чтобы функционал S достигал своего наименьшего значения [17].	Замечание. В неметрическом шкалировании вместо близости самих мер близости и расстояний рассматривается близость упорядочений на множестве мер близости и множестве соответствующих расстояний. Вместо функционала S используются аналоги ранговых коэффициентов корреляции Спирмена и Кендалла. Другими словами, неметрическое шкалирование исходит из предположения, что меры близости измерены в порядковой шкале. 	Пусть евклидово пространство имеет размерность m. Рассмотрим минимум среднего квадрата ошибки,где минимум берется по всем возможным конфигурациям n точек в m-мерном евклидовом пространстве. Можно показать, что рассматриваемый минимум достигается на некоторой конфигурации. Ясно, что при росте m величина ?m монотонно убывает (точнее, не возрастает). Можно показать, что при  m > n - 1 она равна 0 (если s(i,j) - метрика). Для увеличения возможностей содержательной интерпретации желательно действовать в пространстве возможно меньшей размерности. При этом, однако, размерность необходимо выбрать так, чтобы точки представляли объекты без больших искажений. Возникает вопрос: как рационально выбирать размерность, т.е. натуральное число m?	В рамках детерминированного анализа данных обоснованного ответа на этот вопрос, видимо, нет. Следовательно, необходимо изучить поведение ?m в тех или иных вероятностных моделях. Если меры близости s(i,j) являются случайными величинами, распределение которых зависит от "истинной размерности" m0 (и, возможно, от каких-либо еще параметров), то можно в классическом математико-статистическом стиле ставить задачу оценки m0, искать состоятельные оценки и т.д.	Начнем строить вероятностные модели. Примем, что объекты представляют собой точки в евклидовом пространстве размерности k, где k достаточно велико. То, что "истинная размерность" равна m0, означает, что все эти точки лежат на гиперплоскости размерности m0. Примем для определенности, что совокупность рассматриваемых точек представляет собой выборку из кругового нормального распределения с дисперсией ?2(0). Это означает, что объекты О(1), О(2), ., O(n) являются независимыми в совокупности случайными векторами, каждый из которых строится как ?(1)e(1) + ?(2)e(2) + . + ?(m0)e(m0), где e(1), e(2), . , e(m0) - ортонормальный базис в подпространстве размерности m0, в котором лежат рассматриваемые точки, а ?(1), ?(2), . , ?(m0) - независимые в совокупности одномерные нормальные случайные величины с математическим ожиданием ) и дисперсией ?2(0).	Рассмотрим две модели получения мер близости s(i,j). В первой из них s(i,j) отличаются от евклидова расстояния между соответствующими точками из-за того, что точки известны с искажениями. Пусть с(1), с(2), . , с(n) - рассматриваемые точки. Тогда s(i,j) = d(c(i) + ?(i), c(j) + ?(j)),  i,j = 1, 2, . , n,где d - евклидово расстояние между точками в k-мерном пространстве, вектора ?(1), ?(2), . , ?(n) представляют собой выборку из кругового нормального распределения в k-мерном пространстве с нулевым математическим ожиданием и ковариационной матрицей ?2(1)I, где I - единичная матрица. Другими словами, ?(i) = ?(1)e(1) + ?(2)e(2) + . + ?(k)e(k), где e(1), e(2), ., e(k) - ортонормальный базис в k-мерном пространстве, а {?(i,t), i = 1, 2, . , n, t = 1, 2, . , k} - совокупность независимых в совокупности одномерных случайных величин с нулевым математическим ожиданием и дисперсией ?2(1).	Во второй модели искажения наложены непосредственно на сами расстояния:s(i,j) = d(c(i), c(j)) + ?(i,j),  i,j = 1, 2, . , n, i ? j, где {?(i,j), i,j = 1, 2, . , n} - независимые в совокупности нормальные случайные величины с математическим ожиданием ) и дисперсией ?2(1).	В работе [18] показано, что для обеих сформулированных моделей минимум среднего квадрата ошибки ?m  при n > ? сходится по вероятности к f(m) = f1(m) + ?2(1)(k - m),  m = 1, 2, ., k,гдеТаким образом, функция f(m) линейна на интервалах [1, m0] и [m0, k], причем на первом интервале она убывает быстрее, чем на втором. Отсюда следует, что статистикаявляется состоятельной оценкой истинной размерности m0.	Итак, из вероятностной теории вытекает рекомендация - в качестве оценки размерности факторного пространства использовать m*. Отметим, что подобная рекомендация была сформулировано как эвристическая одним из основателей многомерного шкалирования Дж. Краскалом [15]. Он исходил из опыта практического использования многомерного шкалирования и вычислительных экспериментов. Вероятностная теория позволила обосновать эту эвристическую рекомендацию.3.2.7. Индексы и их применение	Индекс (лат. index - показатель, список) -  статистический относительный показатель, характеризующий соотношение во времени (динамический индекс) или в пространстве (территориальный индекс) социально-экономических явлений. Речь идет о ценах на товары и услуги, объемах производства, себестоимости, объемах продаж и др. Индексы делятся на индивидуальные и сводные. Так, индивидуальный динамический индекс описывает изменение тех или иных явлений во времени. Например, изменения цены на отдельный товар, объема выплавки стали, урожайности картофеля. Для вычисления индивидуального индекса значение измеряемой величины в текущем периоде делят на ее значение в базисном периоде. Сводный индекс служит для сопоставления непосредственно несоизмеримых, разнородных явлений. Например, объемов продаж различных продовольственных товаров (в килограммах). Для требуемого сопоставления необходимо составные элементы несоизмеримых явлений сделать соизмеримыми, выразив их общей мерой: стоимостью, трудовыми затратами и т.д. Сводные индексы обычно имеют один из трех видов:где х - индексируемая величина, f - веса индексов, 0 и 1 - знаки соответственно базисного и текущего периодов [19, с.154]. Таким образом, индексы, как и коэффициенты корреляции, зависят от двух переменных - индексируемой величины х и весов индексов f.	В качестве примера построения и использования индексов рассмотрим индекс потребительских цен, он же - индекс инфляции.	Под инфляцией понимаем рост (изменение) цен [6]. При анализе экономических процессов, протяженных во времени, необходимо переходить к сопоставимым ценам. Это невозможно сделать без расчета индекса роста цен, т.е. индекса инфляции. Проблема состоит в том, что цены на разные товары растут с различной скоростью, и необходимо эти скорости усреднять. 	Рассмотрим конкретного покупателя товаров и услуг, т.е. конкретного экономического субъекта: физическое лицо, домохозяйство или фирму. Он покупает не один товар, а много. Обозначим через n количество типов товаров или услуг (далее кратко - товаров), которые он хочет и может купить. Пусть  Qi = Qi(t), i=1,2,...,n,- объемы покупок этих товаров в момент времени t по ценам:ri = ri(t), i=1,2,...,n(имеется в виду цена за единицу измерения соответствующего товара, например, за штуку или килограмм...).	Подход к измерению роста цен основан на выборе и фиксации потребительской корзины (Q1(t), Q2(t), ...,  Qn(t)), не меняющейся со временем, т.е. (Q1(t), Q2(t), ...,  Qn(t)) ? (Q1, Q2, ...,  Qn).   Затем необходимо сравнить стоимости потребительской корзины (Q1, Q2, ...,  Qn) в старых ri(t1), i=1,2,.,n,  и новых ri(t2), i=1,2,.,n, ценах.	Определение. Индексом инфляции называется 	Таким образом, каждой потребительской корзине соответствует свой индекс инфляции. Однако согласно теореме сложения для индекса инфляции [6] он является средним взвешенным арифметическим роста цен на отдельные товары. Поэтому индексы инфляции, рассчитанные по разным достаточно обширным и представительным потребительским корзинам, достаточно близки между собой (см. конкретные данные в [6]).  	Институт высоких статистических технологий и эконометрики (ИВСТЭ) использовал для измерения инфляции минимальную потребительскую корзину физиологически необходимых продовольственных товаров [6]. Она была разработана на основе исходных данных Института питания Российской академии медицинских наук (РАМН). Данные о динамике индекса инфляции приведены в табл.3.Таблица 3. Индекс инфляции и стоимость потребительской корзины ?№ п/пДата снятия ценСтоимость потребительской корзины S(t) (руб.)Индекс инфляции I(31.3.91;t)??131.3.9126.601.00??214.8.9317,691.00665.08??315.11.9328,050.001054.51??414.3.9440,883.001536.95??514.4.9444,441.001670.71??628.4.9447,778.001796.17??726.5.9452,600.001977.44??88.9.9458,614.002203.53??96.10.9455,358.002081.13??1010.11.9472,867.002739.36??111.12.9478,955.002968.23??1229.12.9497,897.003680.34??132.2.95129,165.004855.83??142.3.95151,375.005690.79??1530.3.95160,817.006045.75??1627.4.95159,780.006006.77??171.6.95167,590.006300.38??1829.6.95170,721.006418.08??1927.7.95175,499.006597.71??2031.8.95173,676.006529.17??2228.9.95217,542.008178.27??2326.10.95243,479.009153.35??2430.11.95222,417.008361.54??2528.12.95265,716.009989.32??261.2.96287,472.5510,807.24??275.3.96297,958.0011,201.43??285.4.96304,033.4411,429.83??298.5.96305,809.5511,496.60??305.6.96302,381.6911,367.73??313.7.96306,065.2111,506.21??323.8.96308,963.4211,615.17??337.9.96288,835.0710,858.46??341.10.96278,235.3510,459.98??355.11.96287,094.7710,793.04??364.12.96298,024.7611,203.94??373.1.97314,287.1611,815.31??384.2.97334,738.2412,584.14??394.1.98345.7212.997??403.1.99622.3023.395??415.1.00851.3232.004??423.1.01949.2135.684??432.7.011072.6140.323 ??443.1.021125,7643,321??452.7.021247.7746.908??463.1.031295.7548.712??471.7.031398.1152.558?	Примечание 1. В таблице целая часть отделяется от дробной десятичной точкой, а запятая используется для деления числа по разрядам (на западный манер). Учитывается проведенная деноминация рубля. Если ее не учитывать, то за 12 лет (1991-2003) цены (в Москве) выросли примерно в 50 тысяч раз. Поскольку экономические связи между регионами ослабли, то темпы роста цен в регионах различаются, но, видимо, не более чем на 10-20%. 	Использования индекса инфляции в экономических расчетах при принятии решений. Хорошо известно, что стоимость денежных единиц со временем меняется. Например, на один доллар США полвека назад можно было купить примерно в восемь раз больше материальных ценностей (например, продовольствия), чем сейчас (см. таблицу пересчета в учебнике [20]), а если сравнивать с временами Тома Сойера - в 100 раз больше. Причем стоимость денежных единиц с течением времени, как правило, падает. Этому есть две основные причины - банковский процент и инфляция. В экономике есть инструменты для учета изменения стоимости денежных единиц с течением времени. Один из наиболее известных - расчет NPV (Net Present Value) - чистой текущей стоимости. Однако бухгалтерский учет и построенный на данных баланса предприятия экономический анализ финансово-хозяйственной деятельности предприятия пока что, как правило, игнорируют сам факт наличия инфляции. Обсудим некоторые возможности использования индекса инфляции в экономических расчетах в процессе подготовки и принятия решений.	Переход к сопоставимым ценам. Индекс инфляции даст возможность перехода к сопоставимым ценам, расходам, доходам и другим экономическим величинам. Например, по данным табл.7 индекс инфляции за 4 года - с 14.03.91 г. по 16.03.95 г. - составил 5936. Это означает, что покупательной способности 1 рубля марта 1991 г. соответствует примерно 6000 (а точнее 5936) рублей марта 1995 г.	Рассмотрим приведение доходов к неизменным ценам. Пусть Иван Иванович Иванов получал в 1990 г. 300 руб. в месяц, а в мае 1995 г. - 1 миллион руб. в месяц. Увеличились его доходы или уменьшились?	Номинальная заработная плата выросла в 1000000/300 = 3333 раза. Однако индекс инфляции на 18 мая 1995 г. составлял 7080. Это значит, что 1 руб. 1990 г. соответствовал по покупательной способности 7080 руб. в ценах на 18.05.95 г. Следовательно, в ценах 1990 г. доход  И.И. Иванова составлял 1000000/7080 = 142 руб. 24 коп., т.е. 47,4% от дохода в 1990 г.	Можно поступить наоборот, привести доход 1990 г. к ценам на 18 мая 1995 г. Для этого достаточно умножить его на индекс инфляции: доход 1990 г. соответствует 300 х 7080 = 2 миллиона 124 тыс. руб. в ценах мая 1995 г.	Средняя зарплата. По данным Госкомстата РФ средняя заработная плата составляла в 1990 г. 297 руб., в октябре 1993 г. - 93 тыс. руб., в январе 1995 г. - 303 тыс. руб. Поскольку зарплата тратится в основном в следующем месяце после получки, то рассмотрим индексы инфляции на 15.11.93 г. и 2.02.95 г., равные 1045 и 4811 соответственно. В ценах 1990 г. средняя зарплата составила 89 руб. и 62 руб.98 коп. соответственно, т.е. 30% и 21,2% от зарплаты 1990 г.	Средняя зарплата рассчитывается путем деления фонда оплаты труда на число работников. При этом объединяются доходы и низкооплачиваемых лиц и сравнительно высокооплачиваемых. Известно, что распределение доходов резко асимметрично, большому числу низкооплачиваемых работников соответствует малое число лиц с высокими доходами. За 1991-1995-е годы дифференциация доходов резко увеличилась. Это означает, что доходы основной массы трудящихся сдвинулись влево относительно средней зарплаты. По нашей оценке 50% получают не более 70% от средней зарплаты, т.е. не более 212100 руб. по состоянию на январь 1995 г., а наиболее массовой является оплата в 50% от средней, т.е. около 150 тыс. руб. в месяц.	Доходы отдельных слоев трудящихся снизились еще существеннее. Зарплата профессора Московского государственного института электроники и математики (технического университета) составляла  в марте 1994 г. - 42 руб.92 коп. (в ценах 1990 г.), в июле 1995 г. - 43 руб. 01 коп., т.е. с 1990 г. (400 руб.) снизилась в 9,3 раза, дошла до уровня прежней студенческой стипендии. А студенческие стипендии снизились примерно в той же пропорции и составляли 4-5 руб. в ценах 1990 г.	Кроме того, необходимо учесть, что  Госкомстат учитывает начисленную зарплату, а не выплаченную. В отдельные периоды отечественной истории выплата заработной платы откладывалась надолго.	Минимальная зарплата и прожиточный минимум.  Минимальная зарплата в сентябре 1994 г. (22500 руб.) и в мае 1995 г. (43700 руб.) составляла 38% и 23,4% соответственно от стоимости минимальной физиологически необходимой продовольственной корзины. После подъема до 55 тыс. руб. она в сентябре 1995 г. составляла около 26,34% от стоимости корзины, т.е. реально уменьшилась в 1,44 раза по сравнению с сентябрем 1994 г. В дальнейшем уменьшение стало еще более заметным.	Минимальная зарплата вместе с единой тарифной сеткой во многом определяла зарплату работников бюджетной сферы. Учитывая снижение коэффициентов тарифной сетки, проведенное весной 1995 г., снижение в 1,5 раза  покупательной способности минимальной зарплаты, необходимо заключить, что в сентябре 1995 г. доход бюджетников в 2 раза меньше, чем год назад.	Оценим прожиточный минимум. Бюджетные обследования  1990 года показали, что для лиц с низкими доходами расходы на продовольствие составляют около 50% всех расходов, т.е. на промтовары и услуги идет около 50% доходов. Это соотношение подтвердило и проведенное ИВСТЭ бюджетное обследование конца 1995 г. Исходя из него, среднедушевой прожиточный минимум можно оценить, умножая на 2,0 стоимость минимальной продовольственной корзины ИВСТЭ. Например, на 1 сентября 1995 г. - 418220 руб. Т.е. прожиточный уровень для семьи из трех человек - муж, жена и ребенок - должен был на 1 сентября 1995 г. составлять 1,25 миллиона руб. (в месяц). Например, муж должен получать 800 тыс. руб., жена - 450 тыс. руб. в месяц. Очевидно, доходы большинства трудящихся меньше прожиточного уровня. 	Численные значения стоимостей потребительских корзин и индексов инфляции рассчитаны ИВСТЭ в основном по ценам на продукты в Москве и Подмосковье. Однако для других регионов численные значения отличаются мало. Для Москвы индекс инфляции на 1.09.95 г. - 7759, а для Иванова на 1.08.95 г. - 7542. Поскольку потребительская корзина на 14.03.91 г. в Иванове была на 95 коп. дешевле, то и на 1.08.95 г. она несколько дешевле - 195337 руб., а прожиточный минимум равен  390673 руб. Приведенные выше численные значения для Москвы в качестве первого приближения можно использовать для различных регионов России. 	Индексы инфляции с помощью описанной выше методики можно рассчитать для любого региона, профессиональной или социальной группы, отдельного предприятия или даже конкретной семьи. Эти значения могут быть эффективно использованы на трехсторонних переговорах между профсоюзами, работодателями и представителями государства.	Проценты по вкладам в банк, плата за кредит и инфляция. Рассмотрим банк, честно выполняющий свои обязательства. Пусть он дает 10% в месяц по депозитным вкладам. Тогда 1 руб., положенный в банк, через месяц превращается в 1,1 руб., а через 2 - по формуле сложных процентов - в 1,12 = 1,21 руб., ..., через год - в 1,112 = 3,14 руб. Однако за год росли не только вклады, но и цены. Например, с 19.05.94 г. по 18.05.95 г. индекс инфляции составил 3,73. Значит, в ценах на момент оформления вкладов итог годового хранения равен 3,14 / 3,73 = 0,84 руб. Хранение оказалось невыгодным - реальная стоимость вклада уменьшилась на 16%, несмотря на, казалось бы, очень выгодные условия банка.	Пусть фирма получила кредит под 200% годовых. Значит, вместо 1 рубля, полученного в настоящий момент в кредит, через год ей надо отдать 3 рубля. Пусть она взяла кредит 19.05.94 г., а отдает 18.05.95 г. Тогда в ценах на момент взятия кредита она отдает 3/3,73 = 0,80 руб. за 1 руб. кредита. Таким образом, кредит частично превратился в подарок - возвращать надо на 20% меньше, чем получил, реальная ставка кредита отрицательна, она равна (- 20)%! Такова была типичная ситуация в России в течение ряда лет начиная с 1992 г., особенно в 1992-1994 гг. Но бесплатных подарков в бизнесе не бывает  - за них надо платить по другим каналам, как правило, криминальным.	Сколько стоит доллар? В июле 1995 г. индекс инфляции около 7000, а курс доллара США - около 4500 руб. за доллар. Следовательно, доллар США стоит 4500 / 7000 = 0,64 руб. в ценах 1990 г., т.е. примерно соответствует официальному обменному курсу в 1980-х годах. В сентябре 1994 г. курс доллара был около 2000, а индекс инфляции - около 2200, т.е. доллар стоил около 0,90 руб. в ценах 1990 г. Реальная покупательная способность доллара упала за 10 месяцев в 1,42 раза.	В середине 2003 г. курс доллара был несколько больше 30 руб. (30 руб. 38 коп.), индекс инфляции составлял 52,56, следовательно,  1 доллар США по своей покупательной способности в России на июль 2003 г. соответствовал 58 копейкам начала 1991 г. 	Инфляция, показатели работы предприятия и ВВП. Индексы инфляции используются для пересчета номинальных цен в неизменные (сопоставимые). Другими словами, для приведения доходов и расходов к ценам определенного момента времени. Потребительские корзины для промышленных предприятий, конечно, должны включать промышленные товары, а потому отличаться от потребительских корзин, ориентированных для изучения жизненного уровня. 	Сколько стоит предприятие? Важно оценить основные фонды. Для этого нужно взять их стоимость в определенный момент времени и умножить на индекс инфляции (и учесть амортизационные отчисления). 	Валовой внутренний продукт, валовой национальный продукт и другие характеристики экономического положения страны рассчитываются в текущих ценах. Для перехода к неизменным ценам, грубо говоря, надо поделить на индекс инфляции (т.е. умножить на дефлятор). 	Проблема учета инфляции при экономическом анализе финансово-хозяйственной деятельности предприятия. Как известно, разработана и широко применяется развернутая система коэффициентов, используемых при экономическом анализе финансово-хозяйственной деятельности предприятия [21]. Она основана на данных бухгалтерского баланса. Естественно, опирается на два столбца баланса - данные на "начало периода" и данные на "конец периода". Записывают в эти столбцы номинальные значения. В настоящее время инфляцию полностью игнорируют. Это приводит к искажению реального положения предприятия. Денежные средства преувеличиваются, а реальная стоимость основных фондов занижается. По официальной отчетности предприятие может считаться получившим хорошую прибыль, а по существу - не иметь средств для продолжения производственной деятельности. 	Ясно, что учитывать инфляцию надо. Вопрос в другом - как именно. Потребительская корзина должна, видимо, состоять из тех товаров и услуг, которые предприятие покупает. Стоимость основных фондов может не убывать в соответствии с амортизацией, а возрастать согласно отраслевому темпу инфляции, и т.д. Литература1. Крамер Г. Математические методы статистики. - М.: Мир, 1975. - 648 с.2. Красильников В.В. Статистика объектов нечисловой природы. - Набережные Челны: Изд-во Камского политехнического института, 2001. - 144 с.3. Кендэл М. Ранговые корреляции. - М.: Статистика, 1975. - 216 с.4. Большев Л.Н., Смирнов Н.В. Таблицы математической статистики. - М.: Наука, 1983. - 416 с.5. Себер Дж. Линейный регрессионный анализ. - М.: Мир, 1980. - 456 с.6. Орлов А.И. Эконометрика. Учебник для вузов. Изд. 2-е, исправленное и дополненное. - М.: Изд-во "Экзамен", 2003. - 576 с.7. Орлов А.И. Оценка размерности модели в регрессии. - В сб.: Алгоритмическое и программное обеспечение прикладного статистического анализа. Ученые записки по статистике, т.36. - М.: Наука, 1980. - С.92-99. 8. Кендалл М.Дж., Стьюарт А. Многомерный статистический анализ и временные ряды. - М.: Наука, 1976. - 736 с. 9. Орлов А.И. Некоторые вероятностные вопросы теории классификации. - В сб.: Прикладная статистика. Ученые записки по статистике, т.45. - М.: Наука, 1983. - С.166-179.10. Орлов А.И. Парные сравнения в асимптотике Колмогорова. - В сб.: Экспертные оценки в задачах управления. - М.: Изд-во ИПУ, 1982. - С. 58-66.11. Орлов А.И.; Гусейнов Г.А. Математические методы в изучении способных к математике школьников - В сб.: Исследования по вероятностно-статистическому моделированию реальных систем. - М.: ЦЭМИ АН СССР, 1977. - С.80-93.12. Куперштох B.JI., Миркин Б.Г., Трофимов В.А. Сумма внутренних связей как показатель качества классификации // Автоматика и телемеханика. 1976. № 3. С.91-98.13. Гельфанд И.М., Алексеевская М.А., Губерман Ш.А. и др. Прогнозирование исхода инфаркта миокарда с помощью программы "Кора-3" // Кардиология. 1977. Т.17. № 6. С.19-23.14. Харман Г. Современный факторный анализ. - М.: Статистика, 1972. - 488 с.15. Терехина А.Ю. Анализ данных методами многомерного шкалирования. - М.: Наука, 1986. -168 с.16. Перекрест В.Т. Нелинейный типологический анализ социально-экономической информации: Математические и вычислительные методы. - Л.: Наука, 1983. - 176 с.17. Тюрин Ю.Н., Литвак Б.Г., Орлов А.И., Сатаров Г.А., Шмерлинг Д.С. Анализ нечисловой информации. - М.: Научный Совет АН СССР по комплексной проблеме "Кибернетика", 1981. - 80 с. 18. Орлов А.И. Общий взгляд на статистику объектов нечисловой природы. - В сб.: Анализ нечисловой информации в социологических исследованиях. - М.: Наука, 1985. С.58-92. 19. Статистический словарь / Гл. ред. М.А.Королев. - М.: Финансы и статистика, 1989. - 623 с.20. Макконнелл К.Р., Брю С.Л. Экономикс: Принципы, проблемы и политика. В 2 т.: Пер. с англ. 11-го изд. - М.: Республика, 1992.21. Баканов М.И., Шеремет А.Д. Теория экономического анализа. - М.: Финансы и статистика, 2000. - 416 с. Контрольные вопросы и задачи 1. Имеются данные за несколько лет о торговом обороте Y западногерманского предприятия и его расходах на рекламу X. Данные представлены в табл. 4.Таблица 4.Расходы на рекламу и торговый оборот предприятия. ?Годы, t6869707172737475??Расходы на рекламу x(t), тыс. марок 4456881011??Торговый оборот y(t), млн.марок45668101213?	Вычислите линейный коэффициент корреляции между случайными величинами X и Y. С помощью метода наименьших квадратов определите коэффициенты линейной регрессии Y = aX + b. Постройте график (заданные точки (xi,yi) и прямую y= a*x+b*). Найдите доверительные границы для регрессионной зависимости (при доверительной вероятности ? = 0,95). Нанесите доверительные границы на график. Сделайте точечный и интервальный прогноз для торгового оборота при расходах на рекламу, равных 15 (тыс. марок ФРГ).	Аналогичным образом изучите зависимости расходах на рекламу X и торгового оборота Y от времени t (за начало отсчета целесообразно взять 1971 год). 2. Семь школьников выполняют несколько заданий по математике и физике, которые оцениваются баллами 1-5, затем вычисляется средний балл для каждого школьника по каждому предмету: по математике - xi,  по физике - yj. Данные представлены в табл.5. Определите, существует ли корреляция (т.е. связь) между этими оценками, вычислив коэффициент ранговой корреляции Спирмена. Таблица 5.Средние баллы по математике и физике.?ШкольникСредний баллпо математике xiСредний баллпо физике yi??АBCDEFG1,83,03,54,05,03,82,03,22,84,05,03,62,41,2? 3. Исходные данные (табл.6) - набор n пар чисел (tk , xk), k = 1,2,.,n, где tk - независимая переменная (например, время), а  xk - зависимая (например, индекс инфляции). Предполагается, что переменные связаны зависимостьюxk = a tk + b + ek , k = 1,2,.,n,где a и b - параметры, неизвестные статистику и подлежащие оцениванию, а ek - погрешности, искажающие зависимость.Таблица 6. Исходные данные для расчетов по методу наименьших квадратов.?tk1347910??xk122020323542?	Методом наименьших квадратов оцените параметры a и b линейной зависимости. Выпишите восстановленную зависимость.	Вычислите восстановленные значения зависимой переменной, сравните их с исходными значениями (найдите разности) и проверьте условие точности вычислений (при отсутствии ошибок в вычислениях сумма исходных значений должна равняться сумме восстановленных).	Найдите остаточную сумму квадратов и оцените дисперсию погрешностей.	Выпишите точечный прогноз, а также верхнюю и нижнюю доверительные границы для него  (для доверительной вероятности 0,95).	Рассчитайте прогнозное значение и доверительные границы для него для момента  t =  12.	Как изменятся результаты, если доверительная вероятность будет увеличена? А если она будет уменьшена?4. Как в методе наименьших квадратов используются преобразования переменных?5. Как соотносятся задачи группировки и задачи кластер-анализа?6. В табл.7 приведены попарные расстояния между десятью социально-психологическими признаками способных к математике школьников [11]. Примените к этим данным алгоритмы ближнего соседа, средней связи и дальнего соседа. Для каждого из трех алгоритмов выделите наиболее устойчивые разбиения на кластеры. Таблица 7.Попарные расстояния между социально-психологическими признаками.?1234567910??21028??31028608??41050688610??51012686636634??61006566538616562??710121026748692774732??8960108811441122112011301110??910268788748308368029041040??109907446747447185808141090830?7. Расскажите о динамике индекса инфляции в России. Темы докладов, рефератов, исследовательских работ1. Примеры практического использования методов многомерного статистического анализа.2. Для непараметрической модели метода наименьших квадратов в случае линейной функции одной переменной разработайте алгоритмы	а) расчета доверительных границ для коэффициентов модели;	б) проверки гипотез относительно этих коэффициентов.3. Докажите, что сумма исходных значений зависимой переменной должны быть равна сумме восстановленных значений. 4. Критерии качества регрессионной модели.5. Использование непараметрических оценок плотности для восстановления зависимости.6. Теоремы умножения и сложения для индекса инфляции.7. Экспериментальная работа: соберите данные о ценах и рассчитайте индекс инфляции для своего региона (данные о потребительской корзине ИВСТЭ и ценах на базовый момент времени приведены в [6]).8. Учет инфляции при проведении анализа финансово-хозяйственной деятельности предприятия.