
Berry-Esseen bounds for econometric time series Siegfried Hormann Departement de Mathematique, Universite Libre de Bruxelles, Campus Plaine, CP210, B-1050 Brussels -Belgium E-mail address: shormann@ulb.ac.be Abstract. We derive uniform and non{uniform error bounds in the normal approximation under a general dependence assumption. Our method is tailor made for dynamic time series models employed in the econometric literature but it is also applicable for many other dependent processes. Neither stationarity nor any smoothness conditions of the underlying distributions are required. If the introduced weak dependence coecient decreases with a geometric rate then we obtain, up to a multiplicative logarithmic factor, the same convergence rate as in the central limit theorem for independent random variables. 1. Introduction Let X1;X2; : : : be random variables with EXk = 0 and EX2k < 1. Further let Sn = X1++Xn and B2n= ES2n. One of the fundamental questions in probability and mathematical statistics is whether such a sequence satises the central limit theorem, i.e. whether P(Sn xBn) ! (x) as n ! 1, (1.1) where (x) is the standard normal distribution function. Many basic statistical procedures require more information, such as large deviation probabilities or precise error term estimates (see, e.g., Dufour and Hallin (1992)). Thus it is desirable to determine the speed of convergence in (1.1). Let n(x) = jP(Sn xBn) 􀀀 (x)j: In this paper we give bounds for the normal approximation error n(x) if the underlying sample fXkg is dependent. Our concept is tailor made for time series studied in nance and macroeconomics. As an application we obtain fairly sharp bounds (with an explicit constant) for ARCH/GARCH processes, threshold autoregressive processes, near epoch dependent (NED) sequences and linear processes with dependent errors, etc. Furthermore, the method is not limited to special time series and might have some general interest. A common way to measure dependence is to employ dierent mixing conditions and, as we will show below, several bounds for n(x) for mixing sequences already exist. Despite its prominent role and its various \ready to use theorems", mixing Received by the editors , accepted . 2000 Mathematics Subject Classication. 60F05, 91B84. Key words and phrases. Berry{Esseen, m{dependence, weak{dependence, dynamic nonlinear processes. 1
2 Siegfried Hormann theory is oftentimes of limited use for the practitioner. For example, many of the processes studied in modern time series literature satisfy mixing conditions only under restrictive smoothness and regularity assumptions. In the past decade this led several authors to develop new dependence concepts which are more convenient in applications (see, e.g., Andrews (1987), Doukhan and Louhichi (1999), Potscher and Prucha (1997), Wu (2005)). While these new methods have been used to obtain numerous central and empirical central limit theorems, only a few results exist for corresponding convergence rates. The purpose of this note is to study the convergence rate in the central limit theorem adopting a dependence measure which is tailor made for dynamic nonlinear models, i.e. models where the data generating process fXkg is of the form Xk = fk(: : : ; "k􀀀1; "k; "k+1; : : :); (1.2) where fk : RZ ! R is measurable, and f"kg are independent random variables. (Usually "k are real valued but our theory applies if the "k take values in some more general space.) In context of econometrics f"kg corresponds to a process of exogenous variables or disturbances. We would like to note that while in time series analysis the processes are often assumed to be causal, that is Xk = fk(: : : ; "k􀀀1; "k); non-causal processes appear in the theory of rational expectations models or in spatial statistics. In most practical examples causal fXkg are homogenous Markov processes obtained as stationary solutions of some stochastic recurrence equations. Oftentimes it is then possible to obtain geometric ergodicity and {mixing for fXkg by using the theory of Markov models. However, the application of this apparatus requires restrictive smoothness and moment conditions for the innovations. For example, to verify -mixing for GARCH sequences Carrasco and Chen (2002) require, among others, that the f"kg have a continuous density which is positive on the whole line and that E"2k < 1. More general assumptions were required by Boussama (1998). With our method we can circumvent mixing theory. In fact, our approach is much more general and has some further advantages over competitors: it does not require causality or stationarity, no smoothness assumptions and is easily veriable for processes that are given as in (1.2). We demonstrate applicability in Section 4 below by means of various examples. The presented dependence measure is closely related to NED and Lp{approximability which play an important role in the econometrics and nancial literature. For the convenience of the reader we will recall now some well known results for the convergence rate in the CLT if X1;X2; : : : are independent. The Berry{Esseen theorem (Berry (1941), Esseen (1945); see, e.g., Petrov (1995)) states that if the Xk have absolute third moments, then sup 􀀀1<x<1n(x) CB􀀀3 n Xn k=1EjXkj3: (1.3) Here and in the sequel C will denote an absolute constant which may have dierent values at dierent places. In case of i.i.d. random variables (1.3) implies a rate n􀀀1=2. Employing a symmetric Bernoulli sequence fXkg, i.e. Xk = 1 with probability 1=2, it can be easily seen (c.f. Petrov (1995, p. 150)) that this rate cannot be improved without additional conditions on the distribution of the random variables.
Berry-Esseen bounds for econometric time series 3 Under the more general assumption EjXkjp < 1 for some 2 < p 3 the following version of (1.3) is valid (see Petrov (1965, 1995)): sup 􀀀1<x<1n(x) C(p)B􀀀p n Xn k=1EjXkjp: (1.4) Here C(p) depends solely on p. In contrast to the uniform estimates (1.3) and (1.4), there are also non{uniform estimates available, which take into account not only the sample size, but also the value of x. Under EjX1jp < 1 for some 2 < p 3, Bikelis (1966) showed that n(x) C(p)B􀀀p n (1 + jxj)􀀀p Xn k=1EjXkjp for all x 2 R: (1.5) In what follows, we shall give a brief discussion on related results under dependence. For this purpose we recall some classical mixing concepts. Let fXkg be a random sequence and denote by Fba (􀀀1 a < b 1) the {algebra generated by Xa; : : : ;Xb. Then (n) = supfjP(A \ B) 􀀀 P(A) P(B)j : A 2 Fk􀀀1; B 2 F1k+ng; (1.6) (n) = 12 supnXI i=1 XJ j=1 jP(Ai \ Bj) 􀀀 P(Ai)P(Bj)j : (1.7) (Ai)Ii=1 and (Bj)Jj=1 are nite partitions of with Ai 2 Fk􀀀1, Bj 2 F1k+no, (n) = supfEjj : 2 Fk􀀀1; E= 0;E2 1; 2 F1k+n; E= 0; E2 1g; (1.8) '(n) = supfjP(BjA) 􀀀 P(B)j : A 2 Fk􀀀1; P(A) > 0;B 2 F1k+ng: (1.9) For stationary fXkg these are independent of k, otherwise the supremum in (1.6){ (1.9) is also taken also over k 2 Z. If the corresponding coecient goes to zero for n ! 1, we say that the sequence is either , , , or '{mixing. We have (n) (n) 2p'(n) and 2(n) (n) '(n) (for details see, e.g., Bradley (2007) or Doukhan (1994)). The following results apply to strictly stationary sequences. If (n) or (n) is Ke􀀀n (K; > 0) Tikhomirov (1980) proved that sup􀀀1<x<1 n(x) A(log n)p􀀀1n1􀀀p=2, where A depends solely on K; and p. Here and in the sequel the value of p 2 (2; 3] is related to the moment assumption EjXijp < 1. Under EjX1j3 < 1, Bentkus et. al (1997) obtain a bound of order O􀀀(log n)n􀀀1=2for a general class of asymptotically normal statistics which are functions of n observations of an absolute regular sequence. Uniform bounds for {mixing sequences with polynomial rate are also given in Zuparov (1992). For '{mixing sequences Grin obtained a rate of order O􀀀(log n)1=3n􀀀1=2. Convergence rates of order O(n􀀀1=2) so far have only been obtained under more restrictive regularity conditions. See for example Rio (1996) or Bolthausen (1982b). There exist much less results for non{stationary sequences. The following relaxation of stationarity is due to Sunklodas (1984). Assume that fXkg are {mixing with geometric rate, and that B2ncn for some c > 0. Then sup 􀀀1<x<1n(x) = Omax 1knEjXkjp(logBn)p􀀀1B2􀀀p n :
4 Siegfried Hormann One of the most seminal contributions to the theory of normal approximation is due to Stein (1972). He provides a method going without the previous Fourier analytic approaches, which are dicult to apply under dependence. Chen and Shao (2004) used Stein's method to obtain very sharp results under local dependence. In case of m{dependent sequences they show for example sup 􀀀1<x<1n(x) 75(10m + 1)p􀀀1B􀀀p n Xn k=1EjXkjp; (see Lemmas 5.2{5.3). Their results improve upon previous work for m{dependent sequences, as e.g. those of Tikhomirov (1980), Heinrich (1984) or Sunklodas (1999). Rates of convergence in the central limit theorem have also been obtained for dependent and not necessarily mixing processes. See e.g. Hall and Heyde (1981), Bolthausen (1982a), Rinott and Rotar (1999), Ouchti (2005) or El Machkouri and Ouchti (2007) for martingales and Birkel (1988) or Dewan and Pakasa Rao (2005) for associated sequences. The rest of the paper is organized as follows: in Section 2 below we introduce our dependence concept. The main theorems and several applications are stated in Section 3{4. The proofs are given in Section 5. 2. Dependence condition Despite their prominent role in probability theory, a major disadvantage of diverse mixing concepts is that their verication is dicult in practice. Hence, frequently additional and more restrictive assumptions than actually necessary are imposed on the underlying random sequence fXkg, in order to verify a certain mixing condition. Furthermore, in order to apply at all, mixing typically requires strong smoothness conditions on the process. For example, for the AR(1) process Xn = 12Xn􀀀1 + "n with independent Bernoulli innovations f"ng even the weakest mixing assumption, namely {mixing, fails to hold (cf. Andrews (1984)). We shall introduce now a dependence concept, which is on the one hand general enough to contain a fairly large class of important processes and which, on the other hand, is easy to verify in practice. The principal idea behind mixing and related weak dependence concepts is the assumption of a fading memory of the process fXkg. If the separation m between the two sets of random variables fXk; k ng and fXk; k > n+mg is large, then the mutual dependence of these sets should be small in some sense. Our idea to formalize this heuristics is given below. We dene for p 0 kXkp = (EjXjp)1=p. Hence for p 1 this is the usual Lp norm. We recall that a sequence fZkg is called m{dependent, if for each n the two sets of random variables fZk; k ng and fZk; k > n + mg are independent. Denition 2.1. Let p > 0 and let fmng be a sequence of non{decreasing natural numbers. A random process fXk; k 2 Zg is called fmng{approximable in Lp of size fang, if there exist m{dependent sequences fXkm; k 2 Zg (m = 1; 2; : : :) such that Xn k=1 kXk 􀀀 Xkmnkp = o(an): (2.1) We will write shortly fXkg 2W(Lp; fmng; fang).
Berry-Esseen bounds for econometric time series 5 Remark 2.2. By Lyapounov's inequality it follows for 0 < q p that kXk 􀀀 Xkmnkq kXk 􀀀 Xkmnkp. Hence, if an = O(a0n) and mn m0n, then it follows that W(Lp; fmng; fang) W(Lq; fm0ng; fa0ng): Remark 2.3. In this paper the most important case is when an = Bn. Then we shall solely write fXkg 2W(Lp; fmng). This alternative method to describe dependence is in the spirit of similar concepts as those in Ibragimov (1962), Billingsley (1968) or McLeish (1975a, 1975b). The crucial idea behind these methods is to approximate the original process with auxiliary processes whose asymptotic is known. In our case m{dependent processes (where m = mn) are used. Martingale approximations have for example been used by Gordin (1969) orWu (2006). If the approximation error is small enough, then the properties of the auxiliary processes carry over. For example Barbour et al. (2000) showed how iterates of expanding maps can be closely tied to an m{dependent sequence. Their construction also allows to obtain error bounds in the normal approximation for these specic processes. In order to apply our method, we need a simple way to construct m{dependent approximations for the original sequence. As it has been outlined in the introduction many important processes in the literature have a representation of the form Xk = fk(: : : ; "k􀀀1; "k; "k+1; : : :); (2.2) where f"k; k 2 Zg is a sequence of independent random variables and where fk : RZ ! R are Borel{measurable. (See also Section 4 for several examples.) Provided EjXkj < 1, a natural denition for the approximations is Xkm = E[XkjFk+m k􀀀m]; (2.3) where Fba = ("a; : : : ; "b). The so dened Xkm can be represented as Xkm = fkm("k􀀀m; : : : ; "k; : : : "k+m); where fkm : R2m+1 ! R is measurable and consequently, by the independence of f"kg the sequences fXkm; k 2 Zg are 2m{dependent. (Note that if Xkm are 2m{dependent, then X0km = Xkm0 with m0 = bm=2c are m{dependent. Thus, De-nition 2.1 formally applies.) In fact, for p 1 the conditional mean E[XkjFk+m k􀀀m] is (up to a constant multiplicative factor) the best possible approximation in Lp norm of all Fk+m k􀀀m measurable random variables. To see this, we note that if a random variable X 2 Lp(;A; P) then for every M A we have by Jensen's inequality EjXjp = EE[jXjpjM]EjE[XjM]jp. Thus by the Fk+m k􀀀m measurability of Xkm it follows that kXkm 􀀀 E[XkjFk+m k􀀀m]kp = kE[Xkm 􀀀 XkjFk+m k􀀀m]kp kXkm 􀀀 Xkkp: Therefore by the triangular inequality kXk 􀀀E[XkjFk+m k􀀀m]kp 2kXk 􀀀Xkmkp: For non{linear functionals the computation of the conditional mean in (2.3) might be dicult, and it is therefore convenient to allow for a more general denition of Xkm. A simple alternative construction is Xkm = fk(: : : ; 0; 0; "k􀀀m; : : : ; "k; : : : "k+m; 0; 0; : : :); (2.4) provided this functional is still well dened. (Of course any other constants could be chosen instead of 0 in the above construction.)
6 Siegfried Hormann Another very useful method to obtain Xkm in (2.1) is the following coupling method. For each ` 2 Z we dene an independent sequence f"(`) k ; k 2 Zg with "(`) k L="k such that the sequences ("k), ("(`) k ), ` 2 Z, are mutually independent. This is always possible by enlarging the original probability space. Now set Xkm = fk(: : : ; "(k) k􀀀m􀀀1; "k􀀀m; : : : ; "k; : : : ; "k+m; "(k) k+m+1; : : :): (2.5) Obviously the Xkm are again 2m{dependent. However, they are no longer Fk+m k􀀀m measurable and thus formally approximation concepts like Lp{approximability or NED (see Section 4.2) are not applicable. One advantage of the coupling method is that the random variables Xkm have the same marginal distributions as the Xk's. This will be useful here, since some of our results require conditions on the moments EjXkmjp. Furthermore, in contrast to (2.4), it is clear that the variables Xkm are well dened. The most important case of (2.2) is when fk = f and f"kg are i.i.d. Then fXkg is a stationary and ergodic sequence. In fact, most stationary and ergodic processes in practice can be represented as a shift process of i.i.d. random variables. See Rosenblatt (1959, 1961, 1971) for general sucient criteria for the representation (2.2). Especially it is well known that (2.2) holds for many popular time series models (cf. Priestley (1988), Stine (1997), Tong (1990)). We emphasize that in an abstract sense (2.2) is not required for our method, but it is (2.2) that gives the possibility for an easy construction of Xkm in (2.1). 3. Results For the rest of the paper we agree on the following notation: Sn = X1++Xn and B2n= Var(Sn). The \approximation{depth sequence" (mn) is assumed to be a sequence of positive and non{decreasing integers. Our results depend crucially on the order of magnitude of the constants ep;n;m = B􀀀1 n Xn k=1 kXk 􀀀 Xkmkp: (3.1) We will assume throughout that fXkg 2W(Lp; fmng), which implies that ep;n;mn ! 0 as n ! 1. We are now ready to formulate our main results. Theorem 3.1. Let fXkg 2 W(Lp; fmng) for some p 2 (2; 3]. Then if n is su- ciently large we have sup 􀀀1<x<1n(x) 2p 76 (10mn + 1)p􀀀1B􀀀p n Xn k=1EjXkjp + epp;n;mn+ 2 ep=(p+1) p;n;mn : (3.2) We note that the constants in Theorem 3.1 and also in sequel results could be slightly improved. For example 2 ep=(p+1) p;n;mn in (3.2) can be replaced with (1 + (2)􀀀1=2 + )ep=(p+1) p;n;mn , where > 0 can be chosen arbitrary small. For the sake of simplicity and ease of notation we work with slightly coarser estimates. Of course, the order of magnitude of ep;n;mn depends on the growth speed of mn. The faster mn grows the smaller is ep;n;mn. To get an optimal bound in (3.2) will thus require to correctly balance the speed of growth of ep;n;mn and mn. Our applications in Section 4 show that in many important special cases choosing
Berry-Esseen bounds for econometric time series 7 mn = bH log nc is optimal in the sense that for suciently large H the constants ep;n;mn satisfy ep=(p+1) p;n;mn _ mp􀀀1 n epp;n;mn = omp􀀀1 n B􀀀p n Xn k=1EjXkjp: (As usual bxc denotes the integer part of the real number x.) We obtain then up to a multiplicative factor (log n)p􀀀1 the same order in the normal approximation as for independent random variables. Our next result is a non-uniform version of Theorem 3.1. Here the (absolute) constant in the estimate remains undetermined. Theorem 3.2. Let fXkg 2 W(Lp; fmng) for some p 2 (2; 3]. Then if n is su- ciently large we have n(x) C(1 + jxj)􀀀p(mp􀀀1 n B􀀀p n Xn k=1EjXkjp + epp;n;mn+ (􀀀log ep;n;mn)(p+1)=2ep=(p+1) p;n;mn ); (3.3) where C is an absolute constant. As a matter of fact the computation of ep;n;mn might be dicult if p is not an integer. In order to get a simpler condition, we shall give now a version of Theorem 3.1 and Theorem 3.2 under the weaker assumption fXkg 2W(L2; fmng). Theorem 3.3. Let fXkg 2W(L2; fmng) and assume that EjXkjp < 1 for some p 2 (2; 3]. Assume further that there is a constant D such that Xn k=1EjXkmnjp D Xn k=1EjXkjp ultimately: (3.4) Then for suciently large n sup 􀀀1<x<1n(x) 76D(10mn + 1)p􀀀1B􀀀p n Xn k=1EjXkjp + 2 e2=3 2;n;mn andn(x) C(1 + jxj)􀀀2 (Dmp􀀀1 n B􀀀p n Xn k=1EjXkjp + 􀀀 􀀀 log e2;n;mn3=2e2=3 2;n;mn); where C is an absolute constant. In return for the weaker assumption fXkg 2W(L2; fmng) we have to require the additional condition (3.4) in Theorem 3.3. For example, if the Xkm are constructed via the coupling method (2.5) then (3.4) is trivially satised with D = 1. We also notice that if (3.4) holds in Theorem 3.1 or Theorem 3.2, then the factor B􀀀p n Xn k=1EjXkjp + epp;n;mn in (3.2) and (3.3) can be replaced with D2􀀀pB􀀀p n Xn k=1EjXkjp:
8 Siegfried Hormann In the following Theorem we consider the important special case where the sequences f(Xk;Xkm)g are stationary, for each m 1. Here condition (3.4) reduces to EjX1mnjp DEjX1jp ultimately. (3.5) We will further assume a logarithmic growth rate for mn, since this is the right approximation{depth for most of our examples in the next section. Corollary 3.4. Let fXkg 2 W(L2; fbH log ncg; fnhg), where H > 0 and h < 2􀀀3p=4. Assume that for each m 1 the sequence f(Xk;Xkm)g is stationary. Let EjX1jp < 1, 2 < p 3, and assume that (3.5) holds. Then 2 = EX21 + 2Xk2E(X1Xk) (3.6) converges absolutely and if 2 > 0, then for suciently large n sup 􀀀1<x<1n(x) 76EjX1=jp D􀀀10H log np􀀀1n1􀀀p=2; and n(x) C (1 + jxj)􀀀2 EjX1=jp D􀀀H log np􀀀1n1􀀀p=2; where C is an absolute constant. 4. Applications 4.1. Iterated random functions. We briey outline the construction of Markov chains via iterated random functions as it can be found in the paper of Diaconis and Freedman (1999). We also refer to Diaconis and Freedman (1999) for several interesting applications, ranging from fractal images to queuing theory. The theory is also applicable for many non{linear time series models, like threshold autoregressive models (Tong (1990)), bilinear autoregressive models (Haggan and Ozaki (1981)) or ARCH models (Engle (1982)). Let S be a complete separable metric space equipped with the metric and let (;A; ) be a probability space. Further let ff; 2 g be a parametric family of measurable functions from S onto itself. We consider now a Markov chain moving around in S according to the following rule: after starting in some x0 we pick a 1 2 at random from and set Y1(x0) = f1 (x0). Repeating this experiment independently with the new starting point Y1(x0) we obtain Y2(x0), etc. Hence the process at time n is Yn(x0) = fn fn􀀀1 f1 (x0): Assuming that the functions fare Lipschitz continuous, i.e. (f(x); f(y)) K(x; y) for all x; y 2 S, Theorem 1.1 in Diaconis and Freedman (1999) gives conditions that imply that the induced Markov chain has a stationary distribution . Alternative conditions were derived by Wu and Shao (2004). Lemma 4.1 below is immediate from Theorem 2 in Wu and Shao (2004). We let fng be an i.i.d. sequence with marginals n . Further we let f0ng be an independent copy of fng.
Berry-Esseen bounds for econometric time series 9 Lemma 4.1. Assume that there exist y0 2 S and > 0 such that E(y0; f(y0))< 1. Assume further that there is an x0 2 S, an > 0, and constants r = r() 2 (0; 1), C = C() > 0 such that E(Yn(x); Yn(x0))Crn(x; x0)for all x 2 S and n 1. Then for all x 2 S the limit lim k!1fn fn􀀀1 fn􀀀k (x) exists almost surely and does not dependent on x. If Yn denotes the limit, then Yn = M(: : : ; n􀀀1; n) with a measurable function M : N ! S. The sequence is strictly stationary and ergodic and satises Yn = fn(Yn􀀀1); Yn ; E(Yn;M(: : : ; 0n􀀀m􀀀1; 0n􀀀m; n􀀀m+1; : : : ; n))Crm: (4.1) Property (4.1) is called the geometric moment contraction property. In order to get a real valued sequence which inherits the moment contraction property we dene Xn = T(Yn), where T : S ! R is Lipschitz continuous, i.e. there is a constant L such that jT(x) 􀀀 T(y)j L(x; y) for all x; y 2 S. Proposition 4.2 below is an immediate consequence of Corollary 3.4. Proposition 4.2. Assume that the conditions of Lemma 4.1 hold with = 2. For some Lipschitz continuous function T : S ! R we dene Xn = T(Yn) and we assume that EjX0jp < 1, p 2 (2; 3]. Let H > (1 􀀀 3p=4)= log r. Then the series in (3.6) converges absolutely and for suciently large n sup 􀀀1<x<1n(x) 76 EjX1=jp (10H log n)p􀀀1n1􀀀p=2; and n(x) C (1 + jxj)􀀀2 EjX1=jp (H log n)p􀀀1n1􀀀p=2; where C is an absolute constant. 4.2. NED sequences. Near epoch dependence (NED) has been successfully used in the econometrics literature to establish weak dependence of many important dynamic time series models (see e.g. Potscher and Prucha (1997)). Denition 4.3 (Andrews (1987)). Let fXkg and f"kg be two random sequences dened on the same probability space. Then the process fXkg is called near epoch dependent (NED) on the basis process f"kg if m = sup k2Z kXk 􀀀 E[Xkj"k􀀀m; : : : ; "k+m]k2 (4.2) tends to zero for m ! 1. Under NED or the more general concept of Lp{approximability (see Potscher and Prucha (1997)) (functional) central limit theorems and laws of large numbers have been obtained. We refer to Potscher and Prucha (1997) for detailed results and further references. Lemma 4.4 below shows when our results apply to NED{sequences. Lemma 4.4. Let m be given as in (4.2). Assume that fXkg is NED on an inde- pendent basis sequence f"kg. For any positive sequence fng with n % 1 we have fXkg 2W(L2; fmng; fnmnng). If mn = o(Bn=n) then fXkg 2W(L2; fmng).
10 Siegfried Hormann Example 1. Let fykg be a GARCH(1,1) sequence. I.e. yk = "kk (4.3) where 2k = + 2k􀀀1 + y2k􀀀1; (4.4) with i.i.d. f"kg, > 0 and ; 0. Nelson (1990) showed that a strictly stationary solution of (4.3) and (4.4) with Ejy0jp < 1 exists if and only if %p := E(+ "20)p=2 < 1. The unique solution is given by yk = "kp1 + 1X`=1Y` i=1 􀀀+ "2k􀀀i1=2: Assume that %p < 1 for some p 2 (2; 3]. We notice that then also %q < 1 for all 0 < q p. Using the independence of the "k we obtain with some routine arguments m = ky0 􀀀 E[y0j"􀀀m; ; "0]k2 y0 􀀀 "0pXm `=1 Y` i=1 􀀀+ "2􀀀i1=22 pk"0k2E 1X `=m+1 Y` i=1 􀀀+ "2􀀀i1=2 = O􀀀%m=2 2 : Now let mn = bH log nc where H > 2(1􀀀3p=4)= log %2. Then Corollary 3.4 applies. The example shows, that our method can signicantly improve upon standard methods (using {mixing) when applied to GARCH(1,1) sequences. Besides the fact that we do not need any of the smoothness assumptions for the density of the error sequence mentioned in the Introduction, we also get non{unform bounds, and bounds when only p < 3 moments exist. As for the uniform bounds we can explicitly determine the absolute constant in the approximation error. 4.3. Linear processes with dependent innovations. Let faig be a real{valued and absolute summable sequence and dene the linear process Xk = 1X i=􀀀1aiYk􀀀i: (4.5) We are interested in the case where fYkg is a dependent sequence. Invariance principles for the partial sums of linear processes with dependent innovations have been studied by Wu and Min (2005). Proposition 4.5. Let fYkg be a zero{mean sequence in W(Lp; fmng; fang) for which M = supk2Z kYkkp < 1. Let fXkg be dened as in (4.5). Further let m = supk2Z kYk 􀀀 Ykmkp andm = mm + Xjij>mjaij: If mn = o(Bn=n), then fXng 2W(Lp; fmng).
Berry-Esseen bounds for econometric time series 11 Proof. Setting Xkm = Xm i=􀀀maiYk􀀀i;m; we get 4m{dependent approximations for Xk. Repeated application of the Minkowski's inequality gives kXk 􀀀 Xkmkp Xjij>maiYk􀀀ip + Xm i=􀀀mai(Yk􀀀i 􀀀 Yk􀀀i;m)p M Xjij>mjaij + (2m + 1)m = O(m): Example 2. In the econometric literature an important class of linear processes with dependent errors is dened by ARMA(p; q) processes with GARCH{type innovations. I.e. the process fXk; k 2 Zg is given by the relation Xk 􀀀 1Xk􀀀1 􀀀 􀀀 pXk􀀀p = Yk + 1Yk􀀀1 + + qYk􀀀q; (4.6) with some real coecients i, i 2 f1; : : : ; pg and j , j 2 f1; : : : ; qg and it is assumed that fYk; k 2 Zg is some GARCH type process which should not be specied here. If a stationary and causal solution of (4.6) exists, then it can be represented as a linear process Pi0  iYk􀀀i with exponentially decreasing coecients  i (see Brockwell and Davis (1991)). Similar as we just showed for the GARCH(1,1), we proved in Hormann (2008) that for a large class of GARCH models (including EGARCH, AGARCH, threshold models etc.) m{dependent approximations fYkmg to the original sequence fYkg can be obtained, such that kYk 􀀀 Ykmk2 const %m (% < 1): Hence, for ARMA processes with a causal representation and errors specied by the GARCH processes given in Hormann (2008) we get m conste􀀀m for some > 0. If p 2 (2; 3] moments exist, application of Corollary 3.4 gives sup􀀀1<x<1 n(x) = O􀀀(log n)p􀀀1n1􀀀p=2. 4.4. Sums of the form Pfk(2k!). This example serves to demonstrate the applicability of our method outside the time series framework. Let (fk)k1 be a sequence of measurable functions dened on the unit interval, such that R 1 0 fk(!) d! = 0 and R 1 0 jfk(!)jp < 1 for some p 2 (2; 3]. In addition we let ^ fk(!) be the 1{periodic extension to the positive real line, i.e. ^ fk(x) = fk(x 􀀀 bxc). Further we set Sn(!) = Xn k=1 ^ fk(2k!); ! 2 [0; 1); and B2n= R 1 0 S2n(!) d!. Notice that if denotes the Lebesgue measure then we have here n(x) = jf! 2 [0; 1) : Sn(!) xBng 􀀀 (x)j: Under the present setup McLeish (1975a) obtained a Kolmogorov type law of large numbers. For fk = f central and functional central limit theorems have been obtained by Ibragimov (1967) and Billingsley (1968).
12 Siegfried Hormann We dene the modulus of continuity wf of a function f on the unit interval wf () = sup 0s;t<1 js􀀀tj<jf(s) 􀀀 f(t)j; 0 < < 1: Proposition 4.6. Assume that for a sequence (mn)n1 of positive integers we have n = 1 BnXn k=1wfk􀀀2􀀀mn= o(1): Then for suciently large n sup 􀀀1<x<1n(x) 76 (10mn + 1)p􀀀1B􀀀p n Xn k=1 Z 1 0 jfk(!)jp d! + 2 p=(p+1) n and n(x) C(1+jxj)􀀀p (mp􀀀1 n B􀀀p n Xn k=1 Z 1 0 jfk(!)jp d! + 􀀀 􀀀 log n(p+1)=2p=(p+1) n ); where C is an absolute constant. Proof. Let Xk(!) = ^ fk(2k!). Dene the random variable "k(!) equal to the k{th digit in the binary expansion of !. Ambiguity can be avoided by the convention to take terminating expansions whenever possible. Then f"kg is an i.i.d. sequence where "k takes values 0 and 1 with probability 1=2. Obviously we have the representation Xk = fk1Xj=1 "k+j2􀀀j= Mk("k+1; "k+2; : : :): Using a one{sided version of the coupling construction method, we dene m{ dependent approximations Xkm = Mk("k+1; "k+2; : : : ; "k+m; "(k) k+m+1; "(k) k+m+2; : : :): Changing for some ! 2 [0; 1) the digits "k(!) for k > m will give an !0 with j! 􀀀 !0j 2􀀀m. And therefore jXk 􀀀 Xkmj wfk􀀀2􀀀m: Thus ep;n;mn n. Applying Theorems 3.1{3.2 directly would yield a little bit weaker result as in Proposition 4.6. Since the Xkm are constructed via the coupling method we have EjXkmjp = EjXkjp for all k;m 1. Hence we get sharper estimates in (5.7) and (5.8). Example 3. If fk = f, R 1 0 jf(!)jp d! is nite and wf (h) const jhj, > 0, our method yields n(x) C1(1 + jxj)􀀀p(log n)p􀀀1n1􀀀p=2 and sup 􀀀1<x<1n(x) C2(log n)p􀀀1n1􀀀p=2: We notice that under these assumptions Ibragimov (1967) obtained the slightly better uniform bound C1(log n)p=2􀀀1n1􀀀p=2. See also Ladohin and Moskvin (1971).
Berry-Esseen bounds for econometric time series 13 5. Proof In the sequel we let Snm = X1m + + Xnm. Without loss of generality we can assume that EXk = EXkm = 0 for all k;m 1. We set Bnm = E(S2nm) and recall the denition of ep;n;mn in (3.1). Note that if fXkg is in W(Lp; fmng) then it follows that eq;n;mn ! 0 for all 0 < q p. To show our main results we need some preliminary lemmas. Lemma 5.1. For every > 0, every m; n 1 and every x 2 R the following estimate holds: jP(Sn xBn) 􀀀 (x)j A0(x; ) + A1(m; n; ) + maxfA2(m; n; x; ) + A3(m; n; x; );A4(m; n; x; ) + A5(m; n; x; )g; whereA0(x; ) = j(x) 􀀀 􀀀x + j; A1(m; n; ) = P(jSn 􀀀 Snmj > Bn); A2(m; n; x; ) = jP(Snm (x + )Bn) 􀀀 􀀀(x + )Bn=Bnmj; A3(m; n; x; ) = j􀀀(x + Bn=Bnm) 􀀀 􀀀(x + )j; A4(m; n; x; ) = A2(m; n; x;􀀀) and A5(m; n; x; ) = A3(m; n; x;􀀀): Proof. Since fSn xBng fSnm (x + )Bng [ fSnm 􀀀 Sn > Bng we obtain P(Sn xBn) P􀀀Snm (x + )Bn+ P(jSn 􀀀 Snmj > Bn): (5.1) Similarly it follows that P(Sn xBn) P􀀀Snm (x 􀀀 )Bn􀀀 P(jSn 􀀀 Snmj > Bn): By (5.1) and the triangular inequality we get P(Sn xBn) 􀀀 (x) jP􀀀Snm (x + )Bn􀀀 􀀀(x + )j + A0(x; ) + A1(m; n; ): Using again the triangular inequality we can split up the rst term on the right above in A2(m; n; x; )+A3(m; n; x; ). With the same argument we obtain a lower bound. Then A2 has to be replaced with A4 and A3 with A5. The next two Lemmas are special cases of Theorem 2.6 in Chen and Shao (2004) and give uniform and nonuniform Berry{Esseen bounds for m{dependent random variables. Lemma 5.2. Let Z1;Z2; : : : ;Zn be m{dependent random variables with zero mean and nite EjZijp for 2 < p 3. Then sup 􀀀1<x<1n(x) 75(10m + 1)p􀀀1 B􀀀p n Xn i=1 EjZijp: Lemma 5.3. Let Z1;Z2; : : : ;Zn be m{dependent random variables with zero mean and nite EjZijp for 2 < p 3. Then there is an absolute constant c0, such that n(x) c0(1 + jxj)􀀀pmp􀀀1 B􀀀p n Xn i=1 EjZijp:
14 Siegfried Hormann Lemma 5.4. Let fXkg 2W(L2; fmng). Then lim sup n!1 1 e2;n;mn Bn Bnmn 􀀀 1_Bnmn Bn 􀀀 12: Especially we have Bn Bnmn for n ! 1. Proof. Note that jB2n􀀀B2nmnj = EjSn +SnmnjjSn 􀀀Snmnj. Hence by some basic inequalities we infer jB2n􀀀 B2nmnj kSn + Snmnk2kSn 􀀀 Snmnk2 􀀀kSnk2 + kSnmnk2kSn 􀀀 Snmnk2 􀀀2kSnk2 + kSn 􀀀 Snmnk2kSn 􀀀 Snmnk2; where we used kSnmnk2 kSnk2 + kSn 􀀀 Snmnk2. From the denition of ep;n;mn and the Minkowski inequality it follows that kSn 􀀀 Snmnkp ep;n;mnBn: (5.2) Hence jB2n􀀀 B2nmnj (2Bn + e2;n;mnBn)e2;n;mnBn: The latter relation implies that Bn 􀀀 Bnmn Bn Bn 􀀀 Bnmn Bn Bn + Bnmn Bn (2 + e2;n;mn)e2;n;mn: Proof of Theorem 3.2. We use Lemma 5.1 to estimate n(x). Since the bound given there is uniform in its parameters we can use m = mn and = n(x) = ep=(p+1) p;n;mn (1 + jxj): With these values we estimate the terms Ai (i = 1; 2; : : : ; 5) of Lemma 5.1. In order to bound A0(x; n(x)) =(x) 􀀀 􀀀x + n(x); we distinguish two cases. First we assume that 1 + jxj < (􀀀2 log ep;n;mn)1=2. By the mean value theorem it follows that (x) 􀀀 􀀀x + n(x)(2)􀀀1=2n(x) (2)􀀀1=2(1 + jxj)􀀀p(􀀀2 log ep;n;mn)(p+1)=2ep=(p+1) p;n;mn : Now we assume that 1 + jxj (􀀀2 log ep;n;mn)1=2. If sign(x) = 􀀀1 then x + n(x) = 􀀀(1 + jxj)(1 􀀀 ep=(p+1) p;n;mn ) + 1: Hence we can choose an n0 which is independent of the eligible x such that x + n(x) < 0 if n n0. Thus (x) 􀀀 􀀀x + n(x)2􀀀x + n(x)21 􀀀 (1 + jxj)(1 􀀀 ep=(p+1) p;n;mn ) 􀀀 1= bn(x):
Berry-Esseen bounds for econometric time series 15 If sign(x) = 1 we have (x)􀀀􀀀x+n(x)2􀀀1􀀀(x)bn(x): We recall the well know inequality 1 􀀀 (T) (2)􀀀1=2 1T e􀀀T2=2 for all T 1: Our assumptions on x and ep;n;mn ! 0 imply that for each > 0 we can choose an n1 = n1(), such that for all n n1 (1 + jxj)􀀀1 􀀀 ep=(p+1) p;n;mn 􀀀 1 > (1 + jxj)(1 􀀀 )1=2: If is chosen small enough we obtain (x) 􀀀 􀀀x + n(x)(2)􀀀1=2 2 (1 + jxj)(1 􀀀 )1=2 exp 􀀀 (1 + jxj)2(1 􀀀 )=2(1 + jxj)􀀀p(1 + jxj)p􀀀1 exp 􀀀 (1 + jxj)2(1 􀀀 )=2(1 + jxj)􀀀p(􀀀2 log ep;n;mn)(p􀀀1)=2e1􀀀p;n;mn: We chose now < 1=(p+1) and collect our estimates for A0(x; n(x)) . We conclude that for every C > (2)􀀀1=2, A0(x; n(x)) C(1 + jxj)􀀀p(􀀀2 log ep;n;mn)(p+1)=2ep=(p+1) p;n;mn ultimately: (5.3) By the Markov{inequality and (5.2) A1(mn; n; n(x)) = P(jSn 􀀀 Snmnj > n(x)Bn) EjSn 􀀀 Snmnjp(n(x)Bn)􀀀p epp;n;mn􀀀n(x)􀀀p = (1 + jxj)􀀀pep=(p+1) p;n;mn : (5.4) According to Lemma 5.3 we have A2(mn; n; x; n(x)) c0(1 + jHn(x)j)􀀀pmp􀀀1 n B􀀀p nmnXn k=1EjXkmnjp; (5.5) where 1 + jHn(x)j = 1 + (x + n(x))Bn Bnmn 1 + h(1 + jxj)􀀀1 + ep=(p+1) p;n;mn 􀀀 1i Bn Bnmn 1 􀀀 Bn Bnmn + (1 + jxj) Bn Bnmn : By Lemma 5.4 it follows that lim sup n!1 sup x2R 1 + jxj 1 + jHn(x)j 1: (5.6) Note that EjXkmnjp (kXkkp + kXkmn 􀀀 Xkkp)p 2p(kXkkpp+ kXk 􀀀 Xkmnkpp):
16 Siegfried Hormann Since for any real sequence (ak) and for any p 1 the relation Pnk=1 jakjp 􀀀P nk=1 jakjp holds, we conclude from the denition of ep;n;mn Xn k=1EjXkmnjp 2pXn k=1EjXkjp + Xn k=1 kXk 􀀀 Xkmnkpp= 2pXn k=1EjXkjp + epp;n;mnBpn : (5.7) Hence combining (5.5){(5.7) and Lemma 5.4 we get for every C > 2pc0 A2(mn; n; x; n(x)) C􀀀1 + jxj􀀀pmp􀀀1 n B􀀀p n Xn k=1EjXkjp + epp;n;mnultimately: (5.8) Next we estimate A3. By denition we have A3(mn; n; x; n(x)) = 􀀀(x + n(x))Bn=Bnmn􀀀 􀀀x + n(x): (5.9) The mean value theorem and Lemma 5.4 give for 1 + jxj (􀀀2 log ep;n;mn)1=2 􀀀(x+n(x))Bn=Bnmn) 􀀀 􀀀x + n(x)(2)􀀀1=2 x + n(x)Bn Bnmn 􀀀 1const (1 + jxj)􀀀p􀀀 􀀀 log ep;n;mn(p+1)=2e2;n;mn = (1 + jxj)􀀀p o􀀀ep=(p+1) p;n;mn : Essentially the same arguments we used to estimate A0 in case of 1 + jxj (􀀀2 log ep;n;mn)1=2 can be used here, to show that the (5.9) is bounded by (1 + jxj)􀀀p o􀀀ep=(p+1) p;n;mn , for 1 + jxj (􀀀2 log ep;n;mn)1=2. Thus we have A3(mn; n; x; n(x)) = (1 + jxj)􀀀p o􀀀ep=(p+1) p;n;mn : (5.10) It is obvious that the terms A4 and A5 in Lemma 5.1 can be estimated in exactly the same way as A2 and A3. Using the estimates (5.3), (5.4), (5.8) and (5.10), the proof of Theorem 3.2 follows at once from Lemma 5.1. Proof of Theorem 3.1. We can use similar (in fact easier) arguments as in the proof of Theorem 3.2. Again we will employ Lemma 5.1, but now we choose = n = ep=(p+1) p;n;mn . Application of the mean value theorem and the Markov inequality yield sup 􀀀1<x<1A0(x; n) (2)􀀀1=2ep=(p+1) p;n;mn ; (5.11) A1(mn; n; n) ep=(p+1) p;n;mn ; (5.12) By Lemma 5.2 it follows that sup 􀀀1<x<1A2(mn; n; x; n) 75(10mn + 1)p􀀀1B􀀀p nmn Xn k=1EjXkmnjp;
Berry-Esseen bounds for econometric time series 17 Thus by Lemma 5.4 and (5.7) it is clear that sup 􀀀1<x<1A2(mn; n; x; n) 2p 76 (10mn + 1)p􀀀1B􀀀p n Xn k=1EjXkjp + epp;n;mnultimately: (5.13) By the elementary proposition (cf. Petrov (1995, Lemma 5.2)) sup 􀀀1<x<1j(px) 􀀀 (x)j (2e)􀀀1=2 maxfp 􀀀 1; p􀀀1 􀀀 1g we conclude that sup 􀀀1<x<1A3(mn; n; x; n) (2e)􀀀1=2 Bn Bnmn 􀀀 1_ Bnmn Bn 􀀀 1: Thus by Lemma 5.4 we infer that sup 􀀀1<x<1A3(mn; n; x; n) = o􀀀ep=(p+1) p;n;mn : (5.14) The estimates for A4 and A5 are the same as for A2 and A3. Collecting our estimates (5.11){(5.14) and plugging them into Lemma 5.1 nishes the proof. Proof of Theorem 3.3. The proof only requires some simple modications of the proofs of Theorem 3.1{3.2 and will thus be omitted. Proof of Corollary 3.4. We rst show that 1Xk=0 jE(X1Xk+1)j < 1: (5.15) Without loss of generality we can assume that E(Xkm) = 0 for all k 2 Z, m 1. Now write X1Xk+1 = (X1 􀀀 X1m)Xk+1 + X1m(Xk+1 􀀀 Xk+1;m) + X1mXk+1;m: Using stationarity, (3.5) and the fact that X1m and Xk+1;m are independent if m < k, we get for m = k 􀀀 1 that jE(X1Xk+1)j Ej(X1 􀀀 X1;k􀀀1)Xk+1j + EjX1;k􀀀1(Xk+1 􀀀 Xk+1;k􀀀1)j (kX1k2 + kX1;k􀀀1k2)kX1 􀀀 X1;k􀀀1k2 􀀀1 + D1=pkX1kpkX1 􀀀 X1;k􀀀1k2 for large enough k. Next note that Xk 2W(L2; fbH log ncg; fnhg) and stationarity imply that kX1 􀀀 X1mnk2 = o(nh􀀀1). Let tn be such that mtn = bH log tnc = n. Since tn obviously grows exponentially fast, we conclude that kX1 􀀀 X1nk2 converges to zero at an exponential rate, and (5.15) follows. It is also clear now that Bn n1=2. Further we notice that by our assumptions there is an > 0 such that e2=3 2;n;mn = o􀀀n1􀀀p=2􀀀. Hence the proof follows by an application of Theorem 3.3. 
18 Siegfried Hormann References D. W. K. Andrews. Nonstrong mixing autoregressive processes. J. Appl. Probab. 21, 930{934 (1984). D. W. K. Andrews. Laws of large numbers for dependent nonidentically distributed random variables. Econometrica 55, 1465{1471 (1987). A. D. Barbour, R. M. Gerrard and G. Reinert. Iterates of expanding maps. Probab. Theory Relat. Fields 116, 151{180 (2000). A. C. Berry. The accuracy of Gaussian approximation to the sum of independent variables. Trans. Amer. Math. Soc. 49, 122{136 (1941). V. Bentkus, F. Gotze, and A. Tikhomirov. Berry{Esseen bounds for statistics of weakly dependent samples. Bernoulli 3, 329{349 (1997). A. Bikelis. Estimates of the reminder in the central limit theorem. Litovsk. Mat. Sb. 6, 323{346 (1966). A. Birkel. On the convergence rate in the central limit theorem for associated processes. Ann. Probab. 16, 1685{1698 (1988). P. Billingsley. Convergence of Probability Measures. Wiley (1968). E. Bolthausen. Exact convergence rates in some martingale central limit theorems. Ann. Probab. 10, 672{688 (1982). E. Bolthausen. The Berry{Esseen theorem for stronly mixing Harris recurrent Markov chains. Z. Wahrsch. Verw. Gebiete 60, 283{289 (1982). F. Boussama. Ergodicite, melange et estimation dans les modeles GARCH. Doctoral thesis, Universit Paris 7 (1998). R. C. Bradley. Introduction to Strong Mixing Conditions, Vol. I{III. Kendrick Press (2007). P. J. Brockwell and R. A. Davis Time Series: Theory and Methods (2nd ed.) Springer{Verlag (1991). M. Carrasco and X. Chen Mixing and moment properties of various GARCH and stochastic volatility models. Econometric Theory 18, 17{39 (2002). L. Chen and Q. M. Shao. Normal approximation under local dependence. Ann. Probab. 32, 1985{2028 (2004). I. Dewan and B. L. S. Pakasa Rao. Non{uniform and uniform Berry{Esseen type bounds for stationary associated sequences. J. Nonparametr. Stat. 17, 217{235 (2005). P. Diaconis and D. Freedman. Iterated random functions. SIAM Review 41, 45{75 (1999). P. Doukhan. Mixing: Properties and Examples. Springer Lecture Notes (1994). P. Doukhan and S. Louhichi. A new weak dependence condition and applications to moment inequalities. Stoch. Proc. Appl. 84, 313{342 (1999). J-M. Dufour and M. Hallin. Improved Berry-Esseen-Chebyshev bounds with statistical applications. Econometric Theory 8, 223{240 (1992). R. F. Engle. Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom ination. Econometrica 50, 987{1007 (1982). M. El Machkouri and L. Ouchti. Exact convergence rates in the central limit theorem for a class of martingales. Bernoulli 13, 981{999 (2007). C. G. Esseen. Fourier analysis of distribution functions: A mathematical study of the Laplpace{Gaussian law. Acta Math. 77, 1{125 (1945). M. I. Gordin. The central limit theorem for stationary processes. Dokl. Akad. Nauk SSSR 188, 739{741 (1969).
Berry-Esseen bounds for econometric time series 19 A. G. Grin. Renements of the central limit theorem for sums of dependent random variables. In Mathematical structures and modeling. No. 12, 10{17, Omsk. Gos. Univ. (2003). V. Haggan and T. Ozaki. Modelling nonlinear random vibrations using an amplitude-dependent autoregressive time series model. Biometrika 68, 189{196 (1981). P. Hall and C. C. Heyde. Rates of convergence in the martingale central limit theorem. Ann. Probab. 9, 395{404 (1981). L. Heinrich. Nonuniform estimates and asymptotic expansions of the remainder in the central limit theorem for m{dependent random variables. Math. Nachr. 115, 7{20 (1984). S. Hormann. Augmented GARCH sequences: Dependence structure and asymptotics. Bernoulli 14, 543{561 (2008). I. A. Ibragimov. Some limit theorems for stationary processes. Theory Probab. Appl. 7, 349{382 (1962). I. A. Ibragimov. The central limit theorem for sums of functions of independent random variables and sums of the form Pf(2kt). Theory Probab. Appl. 12, 596{607 (1967). V. I. Ladohin and D. A. Moskvin. An estimate for the remainder term in the central limit theorem for sums of functions of independent random variables and sums of the form Pf(t2k). Theory Probab. Appl. 16, 116{125 (1971). D. L. McLeish. A maximal inequality and dependent strong laws. Ann. Probab. 3, 829{839 (1975). D. L. McLeish. Invariance principles for dependent random variables. Z. Wahrsch. Verw. Gebiete 32, 165{178 (1975). D. B. Nelson. Stationarity and Persistence in the GARCH(1,1) Model. Econometric Theory 6, 318{334 (1990). L. Ouchti. On the rate of convergence in the central limit theorem for martingale dierence sequences. Ann. Inst. H. Poincare Probab. Statist. 41, 35{43 (2005). V. V. Petrov. An estimate of the deviation of the distribution function of a sum of independent random variables from the normal law. Soviet Math. Doklady 6, 242{244 (1965). V. V. Petrov. Limit Theorems of Probability Theory. Oxford Science Publications (1995). B. M. Potscher and I. R. Prucha. Dynamic Nonlinear Econometric Models. Springer (1997). M. Priestley. Nonlinear and Nonstationary Time Series Analysis. Academic Press (1988). I. Rinott and V. I. Rotar. Some estimates for the rate of convergence in the CLT for martingales. I. Theory Probab. Appl. 43, 604{619 (1999). E. Rio. Sur le theoreme de Berry{Esseen pour les suites faiblement dependantes. Probab. Theory Relat. Fields 104, 255{282 (1996). M. Rosenblatt. Stationary random processes as shifts of functions of independent random variables. J. Math. Mech. 8, 665{681 (1959). M. Rosenblatt. Independence and dependence. Proc. 4th Berkeley Sympos. Math. Stat. Prob., Vol. II, 431{443 (1961). M. Rosenblatt. Markov Processes. Structure and Asymptotic Behavior. Springer (1971).
20 Siegfried Hormann M. Rosenblatt. Stationary Sequences and Random Fields. Birkhauser (1985). C. Stein. A bound for the error in the normal approximation to the distribution of a sum of dependent random variables. Proc. Sixth Berkeley Symp. Math. Statist. Probab. 2, 583{602 (1972). R. Stine. Nonlinear time series. In S. Kotz, C. Rea, and D. Banks, editors, Ency- clopedia of Statistical Sciences. Wiley (1997). I. Sunklodas. The rate of convergence in the central limit theorem for strongly mixing random variables. Litovsk. Mat. Sb. 24, 174{185 (1984). I. Sunklodas. A lower bound for the rate of convergence in the central limit theorem for m{dependent random elds. Theory. Probab. Appl. 43, 162{169 (1999). A. Tikhomirov. On the convergence rate in the central limit theorem for weakly dependent random variables. Theory Probab. Appl. 25, 790{809 (1980). H. Tong. Non-linear Time Series: A Dynamical System Approach. Oxford University Press (1990). W. B. Wu. Nonlinear system theory: Another look at dependence. Proceedings of the National Academy of Sciences, USA 102, 14150{14154 (2005). W. B. Wu. Strong invariance principles for dependent random variables. Ann. Probab. 35, 2294{2320 (2006). W. B. Wu and W. Min. On linear processes with dependent innovations. Stoch. Process. Appl. 115, 939{958 (2005). W. B. Wu and X. Shao. Limit theorems for iterated random functions. J. Appl. Probab. 41, 425{436 (2004). T. M. Zuparov. The rate of convergence in the central limit theorem for weakly dependent variables. Theory Probab. Appl. 36, 783{792 (1992).