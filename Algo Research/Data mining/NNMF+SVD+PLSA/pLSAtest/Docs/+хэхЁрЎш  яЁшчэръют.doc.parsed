 11. МЕТОДЫ ГЕНЕРАЦИИ ПРИЗНАКОВ
1. Генерация признаков на основе линейных преобразований
В данном разделе рассматриваются способы генерации признаков через линейные  преобразования исходных измерений образов. Целью такой генерации признаков является сокращение информации до "значимой", т.е. надо просто преобразовать исходное множество измерений в новое множество признаков. Обычно задача состоит в выделении низкочастотных компонент, содержащих основную информацию.
1.1. Базисные вектора 
Пусть
 - множество исходных измерений,
 - соответствующий вектор столбец.
Рассмотрим унитарную матрицу . Для действительной матрицы  условие унитарности обозначает, что матрица  ортогональная, т.е.  . Для комплексной матрицы  условие унитарности обозначает, что , где матрица  - транспонированная (сопряженная).
	Пусть
,
где  - строки из транспонированных столбцов  и . Тогда 
.
Вектора  называются базисными векторами. Таким образом, в силу ортогональности  между собой,  - это проекция вектора  на базисные вектора.
	1.2. Случай двумерных образов. 
Пусть ,  - двумерные измерения. Очевидно, что представление его в виде вектора размерности  неэффективно. Альтернативой является преобразование  через базисные матрицы.
	Пусть  и  - унитарные матрицы. Определим матрицу преобразования  в :
.
Учитывая, что  и , имеем
.
Следовательно
 
Пусть 
, где  - вектор-столбец, 
, где  - вектор-строка.
Тогда 
.
Таким образом  есть выражение  в терминах  базисных матриц. Если  - диагональная,  то  - это разложение по базисным матрицам или образам.
Также возможна следующая запись:
.
Тогда 
.
2. Преобразование Карунена-Лоева 
Пусть  - вектор измерений образа. Целью преобразования является построение такого вектора признаков, что
 при .
т.е. чтобы признаки были взаимно некоррелированны.
	Пусть
 - матрица базисных векторов,
 и  - вектора-столбцы.
Будем считать, что
.
Обозначим , тогда
,
где  - симметричная матрица и ее собственные вектора ортогональны.
	Выберем в качестве  собственные вектора матрицы . Тогда  - диагональная матрица, у которой на диагонали стоят собственные значения : ,   . Таким образом
.
	Если  положительно определенная матрица, то собственные значения , .
	Описанное преобразование называется преобразованием Карунена-Лоева. Оно имеет фундаментальное значение, т.к. оно приводит к построению некоррелированных признаков.
2.1. Свойства преобразования Карунена-Лоева
Пусть
 или  - разложение по базисным векторам.
Определим новый -мерный вектор () : 

где  - проекция  на подпространство. Если мы аппроксимируем  с помощью, то ошибка есть (выбираем те векторов,  для которых ошибка минимальна):

.
Тогда очевидно, что выбирать нужно  базисных векторов с максимальными собственными значениями.
	Отметим еще раз соотношение преобразования Карунена-Лоева с методом селекции признаков. В методе селекции признаков в качестве критерия выступали дискриминантные свойства полученного вектора признаков. В преобразовании Карунера-Лоева в качестве критерия выступает наилучшее приближение исходных измерений.
2.2. Применение преобразования Карунена-Лоева к задаче классификации
В данном случае основная концепция заключается в том, что подпространство главных собственных значений может быть использовано для классификации.
	Алгоритм : 
для каждого класса  строим корреляционную матрицу ,
выбираем  главных собственных значений и собственных векторов,
строим соответствующие матрицы , у которых столбцы - значения собственных векторов.
неизвестный (пробный) вектор  классифицируем по правилу  при , т.е. в ближайшее подпространство.
	Если все подпространства одинаковой размерности, то разделяющие поверхности - это гиперплоскости, иначе гиперповерхности второго порядка. Такой классификатор интегрирует все: генерация, селекция, классификация.
1.6. Декомпозиция сингулярных значений 
Пусть задана матрица  ранга . Покажем, что существуют такие унитарные матрицы  и , что
, ,
где  - диагональная матрица с элементами  и  -  ненулевых собственных значений матрицы . Иначе существуют такие унитарные матрицы  и , что преобразованная  путем  есть диагональная матрица. Следовательно
 
где  и  - первые  столбцов матриц  и  соответственно, т.е.  и  - собственные вектора матриц  и  соответственно.
Собственные значения  называются сингулярными значениями матрицы . Преобразование  - преобразование сингулярных значений или спектральное представление .
Если  аппроксимировать следующим образом 
 ,
то  есть сумма  одноранговых матриц и имеет ранг равный . Можно показать, что квадратичная ошибка 

является минимальной для всех -ранговых матриц. Ошибка аппроксимации есть
,
следовательно, и в данном случае нужно выбирать максимальное . 
Таким образом,  есть наилучшая аппроксимация в смысле нормы Фробениуса. Данная аппроксимация напоминает преобразование Карунена-Лоева.
3. Дискретное преобразование Фурье (ДПФ)
Преобразования типа Карунена-Лоева есть результат специальной обработки (оптимизации) применительно к конкретной выборке требует больших вычислительных затрат. Если разложить по некоторому заданному базису, то можно снизить затраты, правда снизив требования к разложению.
3.1. Одномерное дискретное преобразование Фурье 
Пусть  -  исходных измерений. Тогда ДПФ определяется следующим образом:
,
где    и   .
Обратное преобразование есть:
,
где .
Определим
.
Тогда
.
Пусть
,
тогда
,
.
Утверждается, что  - унитарная симметрическая матрица. Пусть  - сопряженная матрица: . Тогда базисные вектора - это столбцы матрицы . Таким образом, имеет место разложение по заданному базису (по определению  - разложение по базисным векторам).
Прямое вычисление
 или 
имеет сложность , однако, специфика структуры матрицы  позволяет строить алгоритмы сложности .
ДПФ можно рассматривать как разложение последовательности  в множество  базисных последовательностей :
,
где 
 - коэффициенты разложения,
а последовательности  ортогональные:

3.2. Двумерные ДПФ 
Пусть ,  - двумерные измерения. Тогда двумерное ДПФ есть:
.
Обратное преобразование:
.
Данную запись компактно можно переписать в следующем виде:
, .
Данное преобразование - это преобразование с базисными матрицами или образами, . Число требуемых операций "в лоб" равно . Учитывая специфическую структуру , существуют методы сложности .
3.3. Дискретное косинусное преобразование (ДКП)
Данное преобразование имеет вид:
, ,
где
, ,
где 
Его можно переписать в векторной форме:
,
где 
и  - действительная матрица, причем .
Двумерное ДПФ определяется так 
 и .
3.4. Дискретное синусное преобразования (ДСП)
Данное преобразование вычисляется аналогично косинусному через матрицу:
, .
Вычислительная сложность затрат на ДКП и ДСП есть .
ДКП и ДСП обладают хорошими "упаковочными" свойствами для большинства изображений в том смысле, что концентрируют основную информацию в небольшом числе коэффициентов. Объясняется это тем, что оба они дают хорошее приближение для большого класса реальных образов, моделируемых случайных сигналов, известные как Марковский процесс 1-ого порядка.
4. Преобразования Адамара и Хаара
Преобразование Адамара и Хаара имеют такие же вычислительные достоинства, как и ДПФ, ДКП, ДСП. Их матрицы состоят из , поэтому они вычисляются через сложения и вычитания без умножений.
4.1. Преобразование Адамара 
Определение. Унитарная матрица Адамара порядка  - это  матрица , где , сгенерированная по следующему итерационному правилу
  ,
где
,
и  обозначает кронекерово произведение двух матриц:
.
Распишем :
.
По аналогии можно выписать все , . Нетрудно установить ортогональность , :
  .
Для вектора  из  образцов пара преобразований есть:
, .
Преобразование Адамара имеет очень хорошие "упаковочные" свойства. Алгоритм для вычисления выделений и сложений достаточно быстрый:   .
4.2. Преобразование Хаара
Начальной точкой для определения преобразования Хаара являются функции Хаара, которые являются непрерывными и определенными на замкнутом сегменте .
Порядок  функций Хаара единственным образом раскладывается через два целых числа  и :
  , , ,
где ,  для  при  или  при .
	Определение. Функции Хаара :
 ,  ;
 

5. Генерация признаков на основе нелинейных преобразований. Выделение текстуры изображений.
Пусть дано изображение или его часть (область). Задача состоит в генерации признаков, которые впоследствии будут использоваться при классификации.
Определение. Цифровое изображение (монохромное) есть результат процесса дискретизации непрерывной функции  в виде двумерного массива , где , . Значение функции  - интенсивность, число градаций  - глубина изображения.
Определение. Генерацией признаков называется эффективное кодирование необходимой для классификации информации, содержащейся в оригинальных (исходных) данных.
5.1. Региональные признаки. Признаки для описания текстуры. 
Дадим не точное определение текстуры.
Определение. Текстурой называется распределение оттенков серого цвета среди пикселов в регионе.
Рассмотрим основные типы характеристик:
тонкие - грубые,
гладкие - резкие (нерегулярные),
однородные - неоднородные.
Отметим, что в основе подхода лежит гипотеза о том, что внутри региона значения интенсивностей описываются одинаково, т.е. одним и тем же распределением вероятностей. 
Пусть интенсивность внутри региона есть случайная величина. Тогда, при условии, что внутри региона характеристики одинаковы, данная случайная величина внутри региона одинаково распределенная, чем обеспечивается свойство однородности в регионе.
Нашей целью является генерация признаков, которые как-то квантуют свойства фрагментов изображения (регионов).
Данные признаки появляются при анализе пространственных соотношений по распределению серых цветов.
5.1.1. Признаки, основанные на статистиках первого порядка. Пусть  - интенсивность случайной величины, представляющая собой значение (уровень интенсивности) серого цвета в регионе. Пусть также  - вероятность, того что интенсивность в регионе равна .
Определение. Гистограммой первого порядка называется величина , равная отношению числа пикселов с уровнем интенсивности  к общему числу пикселов в регионе и обозначается .
Рассмотрим центральный момент:
,
где  - среднее значение интенсивности - первый момент, который в общем случае определяется из формулы:
 
 при .
Среди центральных моментов наиболее часто используются
 - дисперсия  ,
 - ассиметрия,
 - эксцесс.
В качестве признаков, основанных на статистиках первого порядка, также может использоваться абсолютный момент:
 
 и энтропия:
,
которая определяет меру равномерности распределения. Чем энтропия выше, тем распределение равномернее.
5.1.2. Признаки, основанные на статистиках второго порядка. Матрицы сочетаний. Пусть  - относительное расстояние между пикселами,  - ориентация. Тогда можем ввести метрику следующим образом:
,
причем пикселы рассматриваются в парах.
Рассмотрим соседство для четырех пикселей. Пусть , т.е у нас имеется горизонтальное, вертикальное, диагональное и антидиагональное соседство.
Обозначим через  совместную плоскость. Рассмотрим .  - вероятность того, что точки, расположенная на горизонтали  имеют интенсивности  и , равные отношению числа пар пикселов с расстоянием  и значением и  к общему числу пикселов в регионе.
	Аналогично считается  для ;  для ;  для . Каждый такой массив называют матрицей сочетаний или матрицей пространственной зависимости.
	Рассмотрим конкретный пример матрицы . Пусть , т.е. уровни интенсивности изменяются от 0 до 3. Пусть также матрица  задана следующим образом:
.
Т.к. просмотр происходит в обе стороны, то общее количество пар равно 24.
Рассмотрим  и . . Очевидно, что матрица  является симметрической.

Для  и  матрица  выглядит следующим образом:

Существуют следующие основные виды признаков, основанные на статистиках второго порядка:
Угловой момент второго порядка:  - мера гладкости изображения. При малой вариации , а при больших вариациях (например при  увеличении) контраста .
Контраст (по заданной паре):  - мера локальной дисперсии серого.
Момент обратной разности: . Момент обратной разности имеет большое значение для слабоконтрастных изображений.
Энтропия:  - мера равномерности. Энтропия связана с фиксированной ориентацией и фиксированным расстоянием.
6. Признаки формы и размера 
Рассмотрим методы генерации признаков, описывающих структуру. Существует два основных пути описания формы:
Полное описание формы в регенеративной манере (например, признаки Фурье). По такому описанию полностью можно восстановить образ.
Не восстановительное описание формы (дескриптивные признаки). По такому описанию можно отличить заданную форму от других, но не полностью восстановить образ.
6.1. Признаки Фурье
Отметим, что полное описание позволяет восстанавливать границу образа. Частичное же описание дает признаки для распознавания. Нас интересует вопрос о зависимости изменения признаков от преобразований.
Пусть , где , - координаты последовательных точек границы;  - комплексные числа. Для  точек  определим ДФП ( DFT ):
, ,
где  - Фурье-описание границы.
	Рассмотрим, как изменяется  при сдвиге, повороте, масштабировании и сдвиге начальной точки.
Сдвиг описывается следующим образом: ,  и . Тогда 
, где .
При  , т.к.
.
При  , т.к. 

Поворот описывается следующим соотношением: . Следовательно, , т.е. поворот не меняет модулей, а именно .
Масштабирование описывается следующим соотношением: . Следовательно, . Т.к.
 и ,
то масштабирование не меняет соотношения
.
Сдвиг начальной точки определяется следующим образом: . Следовательно
,
т.е. сдвиг начальной точки сохраняет модули: .
6.2. Цепной код
Определение. Цепным кодом называется кодирование (запоминание) последовательности поворота вектора по пикселям на границе описываемой области - маршрута обхода.
Из построенного цепного кода конструируются следующие признаки:
относительная доля каждого направления,
относительная доля разных сочетаний кривизны.
Недостатком представления изображения цепным кодом является появления шума. Способом борьбы с данным недостатком является использование более мелкой (точной) сетки.
6.4. Геометрические свойства фигуры
Пусть  - периметр фигуры,  - площадь фигуры. Рассмотрим следующие свойства: некруглость фигуры и энергию изгиба.
6.4.1. Некруглость фигуры определяется по следующей формуле:
.
Рассмотрим два крайних значения для данного свойства. Наиболее лучшее (наибольшая "круглость") значение должно быть для круга, оно равно 
.
Наиболее худший вариант (наименьшая "круглость") наблюдается у квадрата. Соответствующее значение равно
.
6.4.2. Энергия изгиба. Пусть задано  точек фигуры. Тогда Энергия изгиба описывается следующей формулой:
,
где  и .  характеризует изменение угла в вершине.
6.5. Скелетизация
	Определение. Скелетизацией называется построение скелета, описывающего форму фигуры.
	Определение. Скелетом называется множество всех центров вписанных в фигуру максимальных окружностей.
 MAT  ( Medial Area Transform ) определяется как скелет плюс функция ширины фигуры.
 
